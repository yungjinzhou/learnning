## 网络协议学习



### 学习网络协议的必要性



#### 协议三要素：

语法、语义、顺序

#### 经常见到的网络协议

![1634653296698](.\1634653296698.png)



#### 浏览器从发送请求到目标地址的过程

1. 输入网址后，本机首先首先DNS(HTTPDNS)查到ip地址；

2. 然后HTTP(s)协议加要发送的内容，到传输层；
3. socket(TCP/UDP)传输层，传输层封装完毕后交给网络层(IP协议)；
4. 在IP协议里会有源IP地址和目标IP地址，然后发送到网关（系统启动时，DHCP协议配置IP地址和默认网关）；
5. 通过ARP协议，找到MAC地址，到了数据链路层；
6. 网关往往是一个路由器，路由器里记录的有路由表，通过路由协议找到对应的远端地址；
7.  然后是ARP协议，找到MAC地址，找到服务器，然后给TCP层，到应用层，访问相应的内容。

### 协议分层的含义



当然网络包的格式很复杂，这个程序也很复杂。复杂的程序都要分层，这是程序设计的要求。

 ![img](.\5c00f6e610f533d17fb4ad7decacc776.jpg) 



### ifconfig包含的信息及协议



#### 无类型域间选路（CIDR）

于是有了一个折中的方式叫作无类型域间选路，简称 CIDR。这种方式打破了原来设计的几类地址的做法，将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号。从哪里分呢？你如果注意观察的话可以看到，10.100.122.2/24，这个 IP 地址中有一个斜杠，斜杠后面有个数字 24。这种地址表示形式，就是 CIDR。后面 24 的意思是，32 位中，前 24 位是网络号，后 8 位是主机号。

伴随着 CIDR 存在的，一个是广播地址，10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到。另一个是子网掩码，255.255.255.0。

将子网掩码和 IP 地址进行 AND 计算。前面三个 255，转成二进制都是 1。1 和任何数值取 AND，都是原来数值，因而前三个数不变，为 10.100.122。后面一个 0，转换成二进制是 0，0 和任何数值取 AND，都是 0，因而最后一个数变为 0，合起来就是 10.100.122.0。这就是网络号。将子网掩码和 IP 地址按位计算 AND，就可得到网络号。



 **解析16.158.165.91/22 这个 CIDR**

/22 不是 8 的整数倍，不好办，只能先变成二进制来看。16.158 的部分不会动，它占了前 16 位。中间的 165，变为二进制为‭10100101‬。除了前面的 16 位，还剩 6 位。所以，这 8 位中前 6 位是网络号，16.158.<101001>，而 <01>.91 是机器号。

第一个地址是 16.158.<101001><00>.1，即 16.158.164.1。子网掩码是 255.255.<111111><00>.0，即 255.255.252.0。广播地址为 16.158.<101001><11>.255，即 16.158.167.255。

#### 公有IP地址和私有IP地址

 ![img](.\df90239efec6e35880b9abe55089ffa9.jpg) 

#### lo

lo 全称是 loopback，又称环回接口，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。

#### MAC

MAC 地址在 IP 地址的上一行是 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff，这个被称为 MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示。

MAC 地址更像是身份证，是一个唯一的标识。

#### 网络设备的状态标识

解析完了 MAC 地址，我们再来看 <BROADCAST,MULTICAST,UP,LOWER_UP> 是干什么的？这个叫做 net_device flags，网络设备的状态标识。

UP 表示网卡处于启动的状态；BROADCAST 表示这个网卡有广播地址，可以发送广播包；MULTICAST 表示网卡可以发送多播包；LOWER_UP 表示 L1 是启动的，也即网线插着呢。

MTU1500 是指最大传输单元 MTU 为 1500，这是以太网的默认值。

MTU 是二层 MAC 层的概念。MAC 层有 MAC 的头，以太网规定正文部分不允许超过 1500 个字节。正文里面有 IP 的头、TCP 的头、HTTP 的头。如果放不下，就需要分片来传输。

#### 分片传输/排队规则

qdisc pfifo_fast 是什么意思呢？**qdisc** 全称是 **queueing discipline**，中文叫排队规则。内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的 qdisc（排队规则）把数据包加入队列。

1. 最简单的 qdisc 是 **pfifo**，它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。

2. **pfifo_fast** 稍微复杂一些，它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。

   三个波段（**band**）的优先级也不相同。band 0 的优先级最高，band 2 的最低。如果 band 0 里面有数据包，系统就不会处理 band 1 里面的数据包，band 1 和 band 2 之间也是一样。

数据包是按照服务类型（Type of Service，**TOS**）被分配到三个波段（band）里面的。TOS 是 IP 头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的。



### DHCP和PXE

#### 手动配置IP地址

```
# 使用net-tools
$ sudo ifconfig eth1 10.0.0.1/24
$ sudo ifconfig eth1 up


# iproute2
$ sudo ip addr add 10.0.0.1/24 dev eth1
$ sudo ip link set up eth1
```



**Linux默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。**



你看着它有自己的源IP地址16.158.23.6，也有目标IP地址192.168.1.6，但是包发不出去，这是因为MAC层还没填。

自己的MAC地址自己知道，这个容易。

Linux首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗？只有是一个网段的，它才会发送ARP请求，获取MAC地址。

 **不同系统的配置文件格式不同，但是无非就是CIDR、子网掩码、广播地址和网关地址**。 





#### 动态主机配置协议（DHCP）

 **动态主机配置协议（Dynamic Host Configuration Protocol）**，简称**DHCP**。 

 功能：他只需要配置一段共享的IP地址。每一台新接入的机器都通过DHCP协议，来这个共享的IP地址里申请，然后自动配置好就可以了。等人走了，或者用完了，还回去，这样其他的机器也能用。 



#### DHCP的工作方式

当一台机器新加入一个网络的时候，会使用IP地址0.0.0.0发送了一个广播包，目的IP地址为255.255.255.255。广播包封装了UDP，UDP封装了BOOTP。其实DHCP是BOOTP的增强版

这一步，我们称为**DHCP Discover。**

在这个广播包里面，新人大声喊：我是新来的（Boot request），我的MAC地址是这个，我还没有IP，谁能给租给我个IP地址！

格式就像这样：

 ![img](.\企业微信截图_16348035476530.png) 

如果一个网络管理员在网络里面配置了**DHCP Server**的话，他就相当于这些IP的管理员。当一台机器带着自己的MAC地址加入一个网络的时候，MAC是它唯一的身份，如果连这个都重复了，就没办法配置了。

只有MAC唯一，IP管理员才能知道这是一个新人，需要租给它一个IP地址，这个过程我们称为**DHCP Offer**。同时，DHCP Server为此客户保留为它提供的IP地址，从而不会为其他DHCP客户分配此IP地址。

DHCP Offer的格式就像这样，里面有给新人分配的地址。

 ![img](.\企业微信截图_16348037502738.png) 





DHCP Server仍然使用广播地址作为目的地址，因为，此时请求分配IP的新人还没有自己的IP。DHCP Server回复一个可用的IP。除此之外，服务器还发送了子网掩码、网关和IP地址租用期等信息。

如果有多个DHCP Server，这台新机器会收到多个IP地址，它会选择其中一个DHCP Offer，一般是最先到达的那个，并且会向网络发送一个DHCP Request广播数据包，包中包含客户端的MAC地址、接受的租约中的IP地址、提供此租约的DHCP服务器地址等，并告诉所有DHCP Server它将接受哪一台服务器提供的IP地址，告诉其他DHCP服务器，谢谢你们的接纳，并请求撤销它们提供的IP地址，以便提供给下一个IP租用请求者。

 ![img](.\企业微信截图_16348041347848.png) 



此时，由于还没有得到DHCP Server的最后确认，客户端仍然使用0.0.0.0为源IP地址、255.255.255.255为目标地址进行广播。在BOOTP里面，接受某个DHCP Server的分配的IP。

当DHCP Server接收到客户机的DHCP request之后，会广播返回给客户机一个DHCP ACK消息包，表明已经接受客户机的选择，并将这一IP地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。

 ![img](.\企业微信截图_16348042145242.png) 

最终租约达成的时候，还是需要广播一下，让大家都知道。



#### IP地址的收回和续租

客户机会在租期过去50%的时候，直接向为其提供IP地址的DHCP Server发送DHCP request消息包。户机接收到该服务器回应的DHCP ACK消息包，会根据包中所提供的新的租期以及其他已经更新的TCP/IP参数，更新自己的配置。这样，IP租用更新就完成了。



#### 预启动执行环境（PXE）

首先，启动BIOS。这是一个特别小的小系统，只能干特别小的一件事情。其实就是读取硬盘的MBR启动扇区，将GRUB启动起来；然后将权力交给GRUB，GRUB加载内核、加载作为根文件系统的initramfs文件；然后将权力交给内核；最后内核启动，初始化整个操作系统。

那我们安装操作系统的过程，只能插在BIOS启动之后了。因为没安装系统之前，连启动扇区都没有。因而这个过程叫做预启动执行环境（Pre-boot Execution Environment），简称PXE。

PXE协议分为客户端和服务器端，由于还没有操作系统，只能先把客户端放在BIOS里面。当计算机启动时，BIOS把PXE客户端调入内存里面，就可以连接到服务端做一些操作了。
首先，PXE客户端自己也需要有个IP地址。因为PXE的客户端启动起来，就可以发送一个DHCP的请求，让DHCP Server给它分配一个地址。PXE客户端有了自己的地址，那它怎么知道PXE服务器在哪里呢？

按照上面的原理，默认的DHCP Server是需要配置的，无非是我们配置IP的时候所需要的IP地址段、子网掩码、网关地址、租期等。如果想使用PXE，则需要配置next-server，指向PXE服务器的地址，另外要配置初始启动文件flename。
这样PXE客户端启动之后，发送DHCP请求之后，除了能得到一个IP地址，还可以知道PXE服务器在哪里，也可以知道如何从PXE服务器上下载某个文件，去初始化操作系统。

#### 解析PXE的工作过程

首先，启动PXE客户端。第一步是通过DHCP协议告诉DHCP Server租给它一个IP地址，同时也给它PXE服务器的地址、启动文件pxelinux.0。

其次，PXE客户端知道要去PXE服务器下载这个文件后，就可以初始化机器。于是便开始下载，下载的时候使用的是TFTP协议。所以PXE服务器上，往往还需要有一个TFTP服务器。PXE客户端向TFTP服务器请求下载这个文件。
然后，PXE客户端收到这个文件后，就开始执行这个文件。这个文件会指示PXE客户端，向TFTP服务器请求计算机的配置信息pxelinux.cfg。TFTP服务器会给PXE客户端一个配置文件，里面会说内核在哪
里、initramfs在哪里。PXE客户端会请求这些文件。
最后，启动Linux内核。一旦启动了操作系统，以后就啥都好办了。

![img](.\企业微信截图_16348050913205.png) 





### 从物理层到mac层

#### 物理层

有一个叫作Hub的东西，也就是集线器。这种设备有多个口，可以将宿舍里的多台电脑连接起来。但是，和交换机不同，它完全在物理层工作。它会将自己收到的每一个字节，都复制到其他端口上去。

#### 数据链路层

MAC层是用来解决多路访问的堵车问题的；

MAC的全称是Medium AccessControl，即媒体访问控制。其实就是控制在往媒体上发数据的时候，谁先发、谁后发的问题。防止发生混乱。

这种过程学名叫**多路访问**。

多路访问有三种方式：

方式一：分多个车道。每个车一个车道，你走你的，我走我的。这在计算机网络里叫作**信道划分**；
方式二：今天单号出行，明天双号出行，轮着来。这在计算机网络里叫作**轮流协议**；
方式三：不管三七二十一，有事儿先出门，发现特堵，就回去。错过高峰再出。我们叫作**随机接入协议**。著名的以太网，用的就是这个方式。

接下来要解决第一个问题：发给谁，谁接收？这里用到一个物理地址，叫作链路层地址。但是因为第二层主要解决媒体接入控制的问题，所以它常被称为MAC地址。
解决第一个问题就牵扯到第二层的网络包格式。对于以太网，第二层的最开始，就是目标的MAC地址和源的MAC地址。

![img](.\企业微信截图_16348061212322.png) 

接下来是类型，大部分的类型是IP数据包，然后IP里面包含TCP、UDP，以及HTTP等，这都是里层封装的事情。
有了这个目标MAC地址，数据包在链路上广播，MAC的网卡才能发现，这个包是给它的。MAC的网卡把包收进来，然后打开IP包，发现IP地址也是自己的，再打开TCP包，发现端口是自己，也就是80，而nginx就是监听80。

于是将请求提交给nginx，nginx返回一个网页。然后将网页需要发回请求的机器。然后层层封装，最后到MAC层。因为来的时候有源MAC地址，返回的时候，源MAC就变成了目标MAC，再返给请求的机器。

对于以太网，第二层的最后面是**CRC**，也就是**循环冗余检测**。通过XOR异或的算法，来计算整个包是否在发送的过程中出现了错误，主要解决第三个问题。

#### ARP协议

这里还有一个没有解决的问题，当源机器知道目标机器的时候，可以将目标地址放入包里面，如果不知道呢？一个广播的网络里面接入了N台机器，我怎么知道每个MAC地址是谁呢？这就是**ARP**协议，也就是**已知IP地址，求MAC地址的协议**。

发送一个广播包，谁是这个IP谁来回答。具体询问和回答的报文就像下面这样：

![img](.\企业微信截图_16348065269645.png) 

为了避免每次都用ARP请求，机器本地也会进行ARP缓存。当然机器会不断地上线下线，IP也可能会变，所以ARP的MAC地址缓存过一段时间就会过期。



#### 局域网



这就需要一个能把MAC头拿下来，检查一下目标MAC地址，然后根据策略转发的设备，按第二节课中讲过的，这个设备显然是个二层设备，我们称为**交换机**。

交换机是有MAC地址学习能力的。

交换机会记住，MAC1是来自一个明确的口。以后有包的目的地址是MAC1的，直接发送到这个口就可以了。
当交换机作为一个关卡一样，过了一段时间之后，就有了整个网络的一个结构了，这个时候，基本上不用广播了，全部可以准确转发。当然，每个机器的IP地址会变，所在的口也会变，因而交换机上的学习的结果，我们称为转发表，是有一个过期时间的。



### 交换机与VLAN



#### 拓扑结构形成

 ![img](.\企业微信截图_16349696284295.png) 



##### 两个交换机3个局域网的情形

当机器1要访问机器4
机器1 发起广播，机器2和交换机A都收到广播；
交换机会转发广播包到除了来的方向上之外的所有网口，所以机器3和交换机B都会收到；
交换机B将广播包发送给局域网三，机器4和机器5收到广播信息；
机器4响应，并回复MAC地址；
ARP请求成功



#### 环路问题

 ![img](.\企业微信截图_16349700931926.png) 



环路问题一般是STP协议来解决的，通过协议将图(环)生成树，解决

STP协议及相关概念



在数据结构中，有一个方法叫作最小生成树。有环的我们常称为图。将图中的环破了，就生成了树。在
计算机网络中，生成树的算法叫作STP，全称Spanning Tree Protocol。

Root Bridge: 根交换机

Designated Bridges：指定交换机（可以理解为指定了连接的根交换机的交换机）

Bridge Protocol Data Units：网桥协议数据单元（可以理解为特定的规则、环境）

Priority Vector: 优先级向量（可以理解为自身的优先级别，值越小越优先）





#### 解决广播问题和安全问题

##### 物理隔离

使用不同的交换机达到隔离的效果。

##### 虚拟隔离

就是VLAN(虚拟局域网)

 ![img](.\企业微信截图_16349713953268.png) 



需要在原来的二层头加TAG，里面有个VLAN ID，一共12位，可以划分4096个VLAN。当然需要支持vlan的交换机。

当这个交换机把二层的头取下来的时候，就能够识别这个VLANID。这样只有相同VLAN的包，才会互相转发，不同VLAN的包，是看不到的。这样广播问题和安全问题就都能够解决了。



#### 交换机与交换机连接

对于支持VLAN的交换机，有一种口叫作**Trunk**口。它可以转发属于任何VLAN的口。交换机之间可以通过这种口相互连接。



### ICMP协议与ping



ping是基于ICMP协议工作的。ICMP全称Internet Control Message Protocol，就是互联网控制报文协议。这里面的关键词是“控制”，

ICMP报文是封装在IP包里面的。因为传输指令的时候，肯定需要源地址和目标地址。



 ![img](.\企业微信截图_16349722182228.png) 

ICMP报文有很多的类型，不同的类型有不同的代码。最常用的类型是主动请求为8，主动请求的应答为0。



#### 查询报文类型

常用的ping就是查询报文，是一种主动请求，并且获得主动应答的ICMP协议。所以，ping发的包也是符合ICMP协议格式的，只不过它在后面增加了自己的格式。

对ping的主动请求，进行网络抓包，称为ICMP ECHO REQUEST。同理主动请求的回复，称为ICMP ECHO EPLY。比起原生的ICMP，这里面多了两个字段，一个是标识符。

 ![img](.\企业微信截图_16349726238036.png) 

ICMP数据包内包含多个字段。最重要的是两个，第一个是类型字段，对于请求数据包而言该字段为 8；另外一个是顺序号，主要用于区分连续ping的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加1。为了能够计算往返时间RTT，它会在报文的数据部分插入发送时间。

在选项数据中，ping还会存放发送请求的时间值，来计算往返时间，说明路程的长短。



#### 差错报文类型

终点不可达为3，源抑制为4，超时为11，重定向为5。

第一种终点不可达：包括网络不可达、主机不可达、协议不可达、端口不可达、分片设置不一致等；
第二种是源站抑制，也就是让源站放慢发送速度。
第三种是时间超时，也就是超过网络包的生存时间还是没到。
第四种是路由重定向，也就是让下次发给另一个路由器。

差错报文的结构相对复杂一些。除了前面还是IP，ICMP的前8字节不变，后面则跟上出错的那个IP包的IP头和IP正文的前8个字节。

有一个程序Traceroute ，它会使用ICMP的规则，故意制造一些能够产生错误的场景。

**Traceroute**的第一个作用就是故意设置特殊的TTL，来追踪去往目的地时沿途经过的路由器。

Traceroute 程序会发送一份UDP数据报给某个目的IP地址主机，但它会选择一个不可能的值作为UDP端口号（大于30000）。当该数据报到达时，将使目的主机的 UDP模块产生一份“端口不可达”错误ICMP报文。如果数据报没有到达，则可能是超时。

Traceroute还有一个作用是故意设置不分片，从而确定路径的MTU。要做的工作首先是发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口MTU相等。如果中间遇到窄的关口会被卡住，会发送ICMP网络差错包，类型为“需要进行分片但设置了不分片位”。每次收到ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。



### 网关



#### MAC 和IP头细节

 ![img](.\企业微信截图_16349747357444.png) 

> 在MAC头里面，先是目标MAC地址，然后是源MAC地址，然后有一个协议类型，用来说明里面是IP协
> 议。IP头里面的版本号，目前主流的还是IPv4，服务类型TOS在第三节讲ip addr命令的时候讲过，TTL在第7节讲ICMP协议的时候讲过。另外，还有8位标识协议。这里到了下一层的协议，也就是，是TCP还是UDP。最重要的就是源IP和目标IP。先是源IP地址，然后是目标IP地址。



当一个机器访问另外一台机器时：

首先判断是否处于同一网段（根据CIDR和子网掩码），

- 如果同一网段，直接将源地址和目标地址放入IP头中，然后通过ARP获得MAC地址，将源MAC和目的MAC放入MAC头中，发出去就可以了。
- 如果不同网段，这就需要发往默认网关Gateway。Gateway的地址一定是和源IP地址是一个网段的。

#### 网关概念

网关往往是一个路由器，是一个三层转发的设备。路由器是一台设备，它有五个网口或者网卡，分别连着五个局域网。每个网口的IP地址都和局域网的IP地址相同的网段，每个网口都是它连接的那个局域网的网关。

#### 路由策略

分为静态路由和动态路由

静态路由：其实就是在路由器上，配置一条一条规则。



#### 转发网关和NAT网关

MAC地址是一个局域网内才有效的地址。因而，MAC地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于IP地址是否改变。不改变IP地址的网关，我们称为转发网关；改变IP地址的网关，我们称为NAT网关。



##### 转发网关

 ![img](.\企业微信截图_16349762596469.png) 

服务器A要访问服务器B。首先判断192.168.4.101和本机不是一个网段的，因而需要先发给网关。网关已经静态配置好了，是192.168.1.1。发送ARP获取网关的MAC地址，然后发送包。包的内容是这样的：

```
源MAC：服务器A的MAC
目标MAC：192.168.1.1这个网口的MAC
源IP：192.168.1.101
目标IP：192.168.4.101
```


包到达192.168.1.1这个网口，发现MAC一致，将包收进来。

在路由器A中配置了静态路由之后，要想访问192.168.4.0/24，要从192.168.56.1这个口出去，下一跳
为192.168.56.2。

匹配上了这条路由，要从192.168.56.1这个口发出去，发给192.168.56.2，
路由器A发送ARP获取192.168.56.2的MAC地址，然后发送包。包的内容是这样的：

```
源MAC：192.168.56.1的MAC地址
目标MAC：192.168.56.2的MAC地址
源IP：192.168.1.101
目标IP：192.168.4.101
```

包到达192.168.56.2这个网口，发现MAC一致，将包收进来。
在路由器B中配置了静态路由，要想访问192.168.4.0/24，要从192.168.4.1这个口出去，没有下一跳了。

于是，匹配上了这条路由，要从192.168.4.1这个口发出去，发给192.168.4.101。
路由器B发送ARP获取192.168.4.101的MAC地址，然后发送包。包的内容是这样的：

```
源MAC：192.168.4.1的MAC地址
目标MAC：192.168.4.101的MAC地址
源IP：192.168.1.101
目标IP：192.168.4.101
```

包到达服务器B，MAC地址匹配，将包收进来。

通过这个过程可以看出，**每到一个新的局域网，MAC都是要变的，但是IP地址都不变。在IP头里面，不会保存任何网关的IP地址。**所谓的**下一跳是，某个IP要将这个IP地址转换为MAC放入MAC头。**



##### NAT网关

 ![img](.\企业微信截图_16349767373695.png) 

首先，目标服务器B在国际上要有一个国际的身份，我们给它一个192.168.56.2。在网关B上，我们记下
来，国际身份192.168.56.2对应国内身份192.168.1.101。凡是要访问192.168.56.2，都转成192.168.1.101。

源服务器A要访问目标服务器B，要指定的目标地址为192.168.56.2。服务器A需要发给网关192.168.1.1。发送ARP获取网关的MAC地址，然后发送包。包的内容是这样的：

```
源MAC：服务器A的MAC
目标MAC：192.168.1.1这个网口的MAC
源IP：192.168.1.101
目标IP：192.168.56.2
```

包到达192.168.1.1这个网口，发现MAC一致，将包收进来。
在路由器A中配置了静态路由：要想访问192.168.56.2/24，要从192.168.56.1这个口出去，发给192.168.56.2。
路由器A发送ARP获取192.168.56.2的MAC地址。当网络包发送到中间的局域网的时候，服务器A也需要有个国际身份，因而在国际上，源IP地址也不能用192.168.1.101，需要改成192.168.56.1。发送包的内容是这样的：

```
源MAC：192.168.56.1的MAC地址
目标MAC：192.168.56.2的MAC地址
源IP：192.168.56.1
目标IP：192.168.56.2
```

包到达192.168.56.2这个网口，发现MAC一致，将包收进来。
路由器B是一个NAT网关，它上面配置了，要访问国际身份192.168.56.2对应国内身份192.168.1.101，于是改为访问192.168.1.101。
在路由器B中配置了静态路由：要想访问192.168.1.0/24，要从192.168.1.1这个口出去发给192.168.1.101。
路由器B发送ARP获取192.168.1.101的MAC地址，然后发送包。内容是这样的：

```
源MAC：192.168.1.1的MAC地址
目标MAC：192.168.1.101的MAC地址
源IP：192.168.56.1
目标IP：192.168.1.101
```

包到达服务器B，MAC地址匹配，将包收进来。
从服务器B接收的包可以看出，源IP为服务器A的国际身份，因而发送返回包的时候，也发给这个国际身
份，由路由器A做NAT，转换为国内身份。

从这个过程可以看出**，IP地址也会变。这个过程用英文说就是Network Address Translation，简**
**称NAT。**



### 路由



#### 路由表

路由器就是一台网络设备，它有多张网卡。当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。这个转发信息库通常被称为**路由表**。

路由表中规则包含信息：

- 目的网络
- 出口设备
- 下一跳网关

#### 配置(静态)路由表

##### 根据ip地址配置路由

```
ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0
```

就说明要去10.176.48.0/20这目标网络，要从eth0端口出去，经过10.173.32.1。

##### 策略路由

在真实的复杂的网络环境中，除了可以根据目的ip地址配置路由外，还可以根据多个参数来配置
路由，这就称为策略路由。

##### 根据路由表

```
ip rule add from 192.168.1.0/24 table 10
ip rule add from 192.168.2.0/24 table 20
```

表示从192.168.1.10/24这个网段来的，使用table 10中的路由表，而从192.168.2.0/24网段来的，使
用table20的路由表。

##### 根据权重

```
ip route add default scope global nexthop via 100.100.100.1 weight 1 nexthop via 200.200.200.1 weight 2
```

下一跳有两个地方，分别是100.100.100.1和200.200.200.1，权重分别为1比2。



##### 较复杂的配置例子



![1634978803246](.\1634978803246.png)

路由配置结果

```
$ ip route lis table main
60.190.27.189/30 dev eth3 proto kernel scope link src 60.190.27.190
183.134.188.1 dev eth2 proto kernel scope link src 183.134.189.34
192.168.1.0/24 dev eth1 proto kernel scope link src 192.168.1.1
127.0.0.0/8 dev lo scope link
default via 183.134.188.1 dev eth2
```

当路由这样配置的时候，就告诉这个路由器如下的规则：
如果去运营商二，就走eth3；
如果去运营商一呢，就走eth2；
如果访问内网，就走eth1；
如果所有的规则都匹配不上，默认走运营商一，也即走快的网络。

添加一个表，chao

```
# echo 200 chao >> /etc/iproute2/rt_tables


# 添加一条规则
# ip rule add from 192.168.1.101 table chao
# ip rule ls
0: from all lookup local
32765: from 10.0.0.10 lookup chao
32766: from all lookup main
32767: from all lookup default
```

设定规则为：从192.168.1.101来的包都查看个chao这个新的路由表。

在chao路由表中添加规则

```
# ip route add default via 60.190.27.189 dev eth3 table chao
# ip route fush cache
```

默认192.168.1.101的路由走慢的



#### 动态路由

使用动态路由路由器，可以根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。

最短路径常用的有两种方法，一种是Bellman-Ford算法，一种是Dijkstra算法。在计算机网络中基本也是用这两种方法计算的。

##### 距离矢量路由算法

第一大类的算法称为距离矢量路由（distance vector routing）。它是基于Bellman-Ford算法的。

这种算法的基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。

由此可以看出，每个路由器都是知道全局信息的。那这个信息如何更新呢？每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。

每个路由器根据新收集的信息，计算和其他路由器的距离，比如自己的一个邻居距离目标路由器的距离是M，而自己距离邻居是x，则自己距离目标路由器是x+M。

第一个问题就是好消息传得快，坏消息传得慢。

- 如果有个路由器加入了这个网络，它的邻居就能很快发现它，然后将消息广播出去。要不了多久，整个网络就都知道了。但是一旦一个路由器挂了，挂的消息是没有广播的。当每个路由器发现原来的道路到不了这个路由器的时候，感觉不到它已经挂了，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器是真的挂了。

这种算法的第二个问题是，每次发送的时候，要发送整个全局路由表。

所以上面的两个问题，限制了距离矢量路由的网络规模。

###### **基于距离矢量路由算法的BGP**

外网的路由协议，也即国家之间的，我们称为外网路由协议（**Border GatewayProtocol，简称BGP**）。

每个数据中心都设置自己的Policy。例如，哪些外部的IP可以让内部知晓，哪些内部的IP可以让外部知晓，哪些可以通过，哪些不能通过。
在网络世界，这一个个国家成为自治系统AS（Autonomous System）。自治系统分几种类型。

- Stub AS：对外只有一个连接。这类AS不会传输其他AS的包。例如，个人或者小公司的网络。
- Multihomed AS：可能有多个连接连到其他的AS，但是大多拒绝帮其他的AS传输包。例如一些大公
  司的网络。
- Transit AS ：有多个连接连到其他的AS，并且可以帮助其他的AS传输包。例如主干网。

**每个自治系统都有边界路由器**，通过它和外面的世界建立联系。

**BGP又分为两类，eBGP和iBGP。**

自治系统间，边界路由器之间使用**eBGP**广播路由。

内部网络也需要访问其他的自治系统。边界路由器如何将BGP学习到的路由导入到内部网络呢？就是通过运行**iBGP**，使得内部的路由器能够找到到达外网目的地的最好的边界路由器。
BGP协议使用的算法是路径矢量路由协议（path-vector protocol）。它是距离矢量路由协议的升级版。
前面说了距离矢量路由协议的缺点。其中一个是收敛慢。在BGP里面，除了下一跳hop之外，还包括了自治系统AS的路径，从而可以避免坏消息传的慢的问题，也即上面所描述的，B知道C原来能够到达A，是因为通过自己，一旦自己都到达不了A了，就不用假设C还能到达A了。
另外，在路径中将一个自治系统看成一个整体，不区分自治系统内部的路由器，这样自治系统的数目是非常有限的。就算是发送全局信息，也是没有问题的。



##### 链路状态路由算法

第二大类算法是链路状态路由（link state routing），基于Dijkstra算法。

这种算法的基本思路是：当一个路由器启动的时候，首先是发现邻居，向邻居say hello，邻居都回复。然后计算和邻居的距离，发送一个echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用Dijkstra算法，找到两点之间的最短路径。
不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和CPU利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。

###### 基于链路状态路由算法的OSPF

**OSPF**（Open Shortest Path First，开放式最短路径优先）就是这样一个基于链路状态路由协议，广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为**内部网关协**
**议（Interior Gateway Protocol，简称IGP**）。



### UDP协议

#### UDP特点

UDP继承了IP包的特性，不保证不丢失，不保证按顺序到达。
UDP继承了IP的特性，基于数据报的，一个一个地发，一个一个地收。
UDP没有拥塞控制；
UDP是无状态服务，它不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也
可以传给任何人数据，甚至可以同时传给多个人数据。

当发送的UDP包到达目标机器后，发现MAC地址匹配，于是就取下来，将剩下的包传给处理IP层的代码。把IP头取下来，发现目标IP匹配，在IP头里面有个8位协议，这里会存放数据里面到底是TCP还是UDP，当然这里是UDP。

#### UDP包头格式

![img](.\企业微信截图_16349820919903.png) 

#### UDP使用场景

第一，需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用。（比如监控数据）
第二，不需要一对一沟通，建立连接，而是可以广播的应用。
第三，需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前
的时候。

### TCP协议



#### 特点

所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。
TCP提供可靠交付。通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。
TCP是面向字节流的。发送的时候发的是一个流，没头没尾。IP包可不是一个流，而是一个个的IP包。之所以变成了流，这也是TCP自己的状态维护做的事情。
TCP是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。
TCP其实是一个有状态服务。



#### TCP包头格式

![img](.\企业微信截图_16349825165439.png) 

- 首先，源端口号和目标端口号是不可少的，这一点和UDP是一样的。如果没有这两个端口号。数据就不
  知道应该发给哪个应用。
- 接下来是包的序号。为了**解决乱序**的问题。
- 还应该有的就是确认序号。这个可以解决**不丢包**的问题。
- TCP是靠谱的协议，对于TCP层面上，会努力保证**可靠**性（重传等机制）。
- 接下来有一些状态位。例如SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接
  等。TCP是**面向连接**的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变
  更。
- 还有一个重要的就是窗口大小。TCP要做**流量控制**，通信双方各声明一个窗口，标识自己当前能够的处
  理能力。
- TCP还会做**拥塞控制**，控制发送的速度。



#### 三次握手



 ![img](.\企业微信截图_16350669667909.png) 

一开始，客户端和服务端都处于CLOSED状态。先是服务端主动监听某个端口，处于LISTEN状态。然后客户端主动发起连接SYN，之后处于SYN-SENT状态。服务端收到发起的连接，返回SYN，并且ACK客户端的SYN，之后处于SYN-RCVD状态。客户端收到服务端发送的SYN和ACK之后，发送ACK的ACK，之后处于ESTABLISHED状态，因为它一发一收成功了。服务端收到ACK的ACK之后，处于ESTABLISHED状态，因为它也一发一收了。



#### 四次挥手



![img](.\企业微信截图_16350673531207.png) 



断开的时候，我们可以看到，当客户端主动发送断开请求后，就进入FIN_WAIT_1的状态，服务端收到消息后，回复ack，就进入CLOSE_WAIT的状态。
客户端收到服务端的ack，就进入FIN_WAIT_2的状态，如果这个时候服务端强制断开了，则客户端将永远在这个状态。TCP协议里面并没有对这个状态的处理，但是Linux有，可以调整tcp_fn_timeout这个参数，设置一个超时时间。
如果服务端没有断开，处理完所有数据后，发送了FIN ACK的请求到达客户端时，客户端收到后发送ACK后，从FIN_WAIT_2状态结束，按说客户端可以断开了，但是最后的这个ACK万一服务端收不到呢？则服务端会重新发一个FIN ACK，这个时候客户端已经断开了的话，服务端就再也收不到ACK了，因而TCP协议要求客户端最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果服务端没收到ACK的话，“FIN ACK会重发的，客户端会重新发一个ACK并且足够时间到达服务端。
客户端直接断开还有一个问题是，客户端的端口就直接空出来了，但是服务端不知道，原来发过的很多包很可能还在路上，如果客户端的端口被一个新的应用占用了，这个新的应用会收到上个连接中服务端发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来服务端发送的所有的包都死翘翘，再空出端口来。
等待的时间设为2MSL，MSL是Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为TCP报文基于是IP协议的，而IP头中有一个TTL域，是IP数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。协议规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。
还有一个异常情况就是，服务端超过了2MSL的时间，依然没有收到它发的FIN的ACK，怎么办呢？按照TCP的原理，服务端当然还会重发FIN，这个时候客户端再收到这个包之后，就直接发送RST，服务端就知道客户端早断开连接了。



#### TCP状态机

 ![img](.\企业微信截图_16350682615524.png) 





#### 顺序性

TCP协议使用的也是同样的模式。为了保证顺序性，每一个包都有一个ID。在建立连接的时候，会商定
起始的ID是什么，然后按照ID一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应
答也不是一个一个来的，而是会应答某个之前的ID，表示都收到了，这种模式称为**累计确认或者累计应**
**答（cumulative acknowledgment）**。

为了记录所有发送的包和接收的包，TCP也需要发送端和接收端分别都有缓存来保存这些记录。**发送端**
**的缓存**里是按照包的ID一个个排列，根据处理的情况分成四个部分。

 ![img](.\企业微信截图_16352085506251.png) 

第一部分：发送了并且已经确认的。
第二部分：发送了并且尚未确认的。
第三部分：没有发送，但是已经等待发送的。
第四部分：没有发送，并且暂时还不会发送的。

在TCP里，**接收端会给发送端报一个窗口的大小，叫Advertised window**。这个窗口的大小应该等于上面的第二部分加上第三部分。超过这个窗口的，接收端做不过来，就不能发送了。

对于**接收端**来讲，它的**缓存**里记录的内容要简单一些。

第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的。
第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。
第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。
对应的数据结构就像这样。

![img](.\企业微信截图_16352087636698.png) ﻿
MaxRcvBuffer：最大缓存的量；
LastByteRead之后是已经接收了，但是还没被应用层读取的；
NextByteExpected是第一部分和第二部分的分界线。

其中第二部分里面，由于**收到**的包**可能不是顺序**的，会出现空挡**，只有和第一部分连续的，可以马上进**
**行回复**，中间空着的部分需要等待，哪怕后面的已经来了。

#### 确认与重发的机制

一种方法就是**超时重试**，也即对每一个发送了，但是没有ACK的包，都有设一个定时器，超过了一定的
时间，就重新尝试。

估计往返时间，需要TCP通过采样RTT的时间，然后进行加权平均，算出一个值，而且这个值还是要不
断变化的，因为网络状况不断的变化。除了采样RTT，还要采样RTT的波动范围，计算出一个估计的超
时时间。由于重传时间是不断变化的，我们称为自适应重传算法（Adaptive Retransmission
Algorithm）。

**有需要重传的时候，TCP的策略是超时间隔加倍。**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。

**有一个可以快速重传的机制**，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个没有收到包序号的前一个包的冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。

**还有一种方式称为Selective Acknowledgment （SACK）。**这种方式需要在TCP头里加一个SACK的
东西，可以将缓存的地图发送给发送方。

#### 流量控制问题

发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。

#### 拥塞控制问题

拥塞控制的问题，也是通过窗口的大小来控制的，前面的**滑动窗口rwnd**是怕发送方把接收方缓存塞满，而**拥塞窗口cwnd**，是怕把网络塞满。

这里有一个公式 **LastByteSent - LastByteAcked <= min {cwnd, rwnd}** ，**是拥塞窗口和滑动窗口共同控制发送的速度**。

**TCP的拥塞控制主要来避免两种现象，包丢失和超时重传。**

一条TCP连接开始，cwnd设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认cwnd加一，两个确认cwnd加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认cwnd加一，四个确认cwnd加四，于是一次能够发送八个。可以看出这是指数性的增长。

有一个值ssthresh为65535个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满，再慢下来。每收到一个确认后，cwnd增加1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加1/8，八个确认一共cwnd增加1，于是一次能够发送九个，变成了线性增长。

但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子
降低倒水的速度，等待溢出的水慢慢渗下去。

拥塞的一种表现形式是丢包，需要超时重传，这个时候，将sshresh设为cwnd/2，将cwnd设为1，重新
开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度
一下子停了下来，会造成网络卡顿。
前面我们讲过快速重传算法。当接收端发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发
送端就会快速的重传，不必等待超时再重传。TCP认为这种情况不严重，因为大部分没丢，只丢了一小
部分，cwnd减半为cwnd/2，然后sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，
也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。

##### 包丢失和超时重传的问题

- 第一个问题是丢包并不代表着通道满了。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。

- 第二个问题是TCP的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实TCP只要填满管道就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了**TCP BBR拥塞算法**。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的  达到高带宽和低时延的平衡。



### 基于TCP和UDP协议的Socket编程



Socket编程进行的是端到端的通信，往往意识不到中间经过多少局域网，多少路由器，因而能够设置的参数，也只能是端到端协议之上网络层和传输层的。
在网络层，Socket函数需要指定到底是IPv4还是IPv6，分别对应设置为AF_INET和AF_INET6。另外，还要指定到底是TCP还是UDP。
TCP协议是基于数据流的，所以设置为SOCK_STREAM，而UDP是基于数据报的，因而设置为SOCK_DGRAM。



#### 基于TCP协议的Socket程序函数调用过程

1. TCP的服务端要先监听一个端口，一般是先调用bind函数，给这个Socket赋予一个IP地址和端口。
2. 当服务端有了IP和端口号，就可以调用listen函数进行监听。在TCP的状态图里面，有一个listen状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。
3. **在内核中，为每个Socket维护两个队列。**
   - 一个是已经建立了连接的队列，这时候连接三次- 握手已经完毕，处于established状态；
   - 一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于syn_rcvd的状态。

4. 接下来，服务端调用accept函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。
5. 在服务端等待的时候，客户端可以通过connect函数发起连接。先在参数中指明要连接的IP地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。
6. 一旦握手成功，服务端的accept就会返回另一个Socket。

> 这是一个经常考的知识点，**就是监听的Socket和真正用来传数据的Socket是两个，一个叫作监听Socket，一个叫作已连接Socket。**

7. 连接建立成功之后，双方开始通过read和write函数来读写数据，就像往一个文件流里面写东西一样。



这个图就是基于TCP协议的Socket程序函数调用过程。

 ![img](.\企业微信截图_16354697365533.png) 

说TCP的Socket就是一个**文件流**，是非常准确的。因为，Socket在Linux中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。
**在内核中，Socket是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构task_struct**，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。

这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个inode，只不过Socket对应的inode不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。在这个inode中，指向了Socket在内核中的Socket结构。

在这个结构里面，主要的是两个队列，一个是发送队列，一个是接收队列。在这两个队列里面保存的是一个缓存sk_buff。这个缓存里面能够看到完整的包的结构。

 ![img](.\企业微信截图_16354698147560.png) 





#### 基于UDP协议的Socket程序函数调用过程

UDP是没有连接的，所以不需要三次握手，也就不需要调用listen和connect，但是，UDP的的交互仍然需要IP和端口号，因而也需要bind。UDP是没有维护连接状态的，因而不需要每对连接建立一组Socket，而是只要有一个Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用sendto和recvfrom，都可以传入IP地址和端口。

 ![img](.\企业微信截图_16354699355596.png) 

#### 最大连接数限制及解决方法

服务端最大并发TCP连接数远不能达到理论上限。首先主要是**文件描述符限制**，按照上面的原理，Socket都是文件，所以首先要通过ulimit配置文件描述符的数目；**另一个限制是内存**，按上面的数据结构，每个TCP连接都要占用一定内存，操作系统是有限的。

##### 多进程

在Linux下，**创建子进程使用fork函数**。通过名字可以看出，这是在父进程的基础上完全拷贝一个子进程。在Linux内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程。显然，复制的时候在调用fork，复制完毕之后，父进程和子进程都会记录当前刚刚执行完fork。这两个进程刚复制完时候，几乎一模一样，**只是根据fork的返回值来区分到底是父进程，还是子进程。如果返回值是0，则是子进程；如果返回值是其他的整数，就是父进程。**

![img](.\企业微信截图_16354700676766.png) 

因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为accept创建的已连接Socket也是一个文件描述符，同样也会被子进程获得。

接下来，子进程就可以通过这个已连接Socket和客户端进行互通了，当通信完毕之后，就可以退出进程，那父进程如何知道子进程干完了项目，要退出呢？还记得fork返回的时候，如果是整数就是父进程吗？这个整数就是子进程的ID，父进程可以通过这个ID查看子进程是否完成项目，是否需要退出。



##### 多线程

在Linux下，通过pthread_create创建一个线程，也是调用do_fork。不同的是，虽然新的线程在task列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一个引用而已。

![img](.\企业微信截图_16354702572644.png) 

新的线程也可以通过已连接Socket处理请求，从而达到并发处理的目的。

##### C10K问题

一台机器要维护1万个连接，就要创建1万个进程或者线程，那么操作系统是无法承受的。

##### select（IO多路复用）

IO多路复用，一个线程维护多个Socket。

调用select函数来监听文件描述符集合是否有变化。一旦有变化，就会**依次查看每个文件描述符**。那些发生变化的文件描述符在fd_set对应的位都设为1，表示Socket可读或者可写，从而可以进行读写操作，然后再调用select，接着盯着下一轮的变化。

##### epoll（IO多路复用）

epoll，它在内核中的实现不是通过轮询的方式，而是通过注册callback函数的方式，当某个**文件描述符发送变化**的时候，就会**主动通知**。

 ![img](.\企业微信截图_16354704618667.png) 

假设进程打开了Socket m, n, x等多个文件描述符，现在需要通过epoll来监听是否这些Socket都有事件发生。其中**epoll_create创建一个epoll对象**，也是一个文件，也对应一个文件描述符，同样也对应着**打开文件列表中的一项。**在这**项里面有一个红黑树**，在红黑树里，要保存这个epoll要监听的所有Socket。
**当epoll_ctl添加一个Socket的时候，其实是加入这个红黑树**，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的Socket的事件列表中。当一个Socket来了一个事件的时候，可以从这个列表中得到epoll对象，并调用**call back通知**它。
这种通知方式使得监听的Socket数据增加的时候，效率不会大幅度降低，能够同时监听的Socket的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，**epoll被称为解决C10K问题的利器**。

### HTTP协议

#### 请求结构

HTTP的报文大概分为三大部分。第一部分是请求行，第二部分是请求的首部，第三部分才是请求的正文实体。

 ![img](.\企业微信截图_1635473356972.png) 

##### 第一部分：请求行

顾名思义，**GET**就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。其实也有很多其他的格式，比如说返回一个JSON字符串，到底要返回什么，是由服务器端的实现决定的。=

另外一种类型叫做**POST**。它需要主动告诉服务端一些信息，而非获取。

还有一种类型叫**PUT**，就是向指定资源位置上传最新内容。但是，HTTP的服务器往往是不允许上传文件的，所以PUT和POST就都变成了要传给服务器东西的方法。

再有一种常见的就是**DELETE**。这个顾名思义就是用来删除资源的。

##### 第二部分：首部字段、

请求行下面就是我们的首部字段。首部是key value，通过冒号分隔。这里面，往往保存了一些非常重要的字段。

Accept-Charset，表示客户端可以接受的字符集。防止传过来的是另外的字符集，从而导致出现乱码。
再如，Content-Type是指正文的格式。例如，我们进行POST的请求，如果正文是JSON，那么我们就应该将这个值设置为JSON。

这里需要重点说一下的就是缓存。

在HTTP头里面**，Cache-control**是用来控制缓存的。当客户端发送的请求中包含max-age指令时，如果判定缓存层中，资源的缓存时间数值比指定时间的数值小，那么客户端可以接受缓存的资源；当指定max-age值为0，那么缓存层通常需要将请求转发给应用集群。

**If-Modified-Since**也是一个关于缓存的。也就是说，如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回“304 Not Modifed”的响应，那客户端就不用下载了，也会节省带宽。

#### 返回结构

 ![img](.\企业微信截图_16354736408271.png) 

状态码会反应HTTP请求的结果。

在返回的头部里面也会有Content-Type，表示返回的是HTML，还是JSON。

Retry-After表示，告诉客户端应该在多长时间以后再次尝试一下。“503错误”是说“服务暂时不再和这个值配合使用”。

#### HTTP 2.0

- HTTP 2.0会对HTTP的**头进行一定的压缩**，将原来每次都要携带的大量key value在两端建立一个索引表，对相同的头只发送索引表中的索引。
- HTTP 2.0协议**将一个TCP的连接中，切分成多个流**，每个流都有自己的ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。
- HTTP 2.0还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。
  - 常见的帧有Header帧，用于传输Header内容，并且会开启一个新的流。
  - 再就是Data帧，用来传输正文实体。多个Data帧属于同一个流。
   >通过这两种机制，HTTP 2.0的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。



#### QUIC协议

Google的QUIC协议，基于UDP。

**机制一：自定义连接机制**
我们都知道，一条TCP连接是由四元组标识的，分别是源 IP、源端口、目的 IP、目的端口。一旦一个元素发生变化时，就需要断开重连，重新连接。在移动互联情况下，当手机信号不稳定或者在WIFI和 移动网络切换时，都会导致重连，从而进行再次的三次握手，导致一定的时延。
这在TCP是没有办法的，但是基于UDP，就可以在QUIC自己的逻辑里面维护连接的机制，不再以四元组标识，而是以一个64位的随机数作为ID来标识，而且UDP是无连接的，所以当IP或者端口变化的时候，只要ID不变，就不需要重新建立连接。
**机制二：自定义重传机制**
前面我们讲过，TCP为了保证可靠性，通过使用序号和应答机制，来解决顺序问题和丢包问题。任何一个序号的包发过去，都要在一定的时间内得到应答，否则一旦超时，就会重发这个序号的包。

QUIC也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。例如，发送一个包，序号是100，发现没有返回；再次发送的时候，序号就是101了；如果返回的ACK 100，就是对第一个包的响应。如果返回ACK 101就是对第二个包的响应，RTT计算相对准确。

QUIC定义了一个offset概念。QUIC既然是面向连接的，也就像TCP一样，是一个数据流，发送的数据在这个数据流里面有个偏移量offset，可以通过offset查看数据发送到了哪里，这样只要这个offset的包没有来，就要重发；如果来了，按照offset拼接，还是能够拼成一个流。

**机制三：无阻塞的多路复用**
有了自定义的连接和重传机制，我们就可以解决上面HTTP 2.0的多路复用问题。
同HTTP 2.0一样，同一条QUIC连接上可以创建多个stream，来发送多个 HTTP 请求。但是，QUIC是基于UDP的，一个连接上的多个stream之间没有依赖。这样，假如stream2丢了一个UDP包，后面跟着stream3的一个UDP包，虽然stream2的那个包需要重传，但是stream3的包无需等待，就可以发给用户。
**机制四：自定义流量控制**
TCP的流量控制是通过滑动窗口协议。QUIC的流量控制也是通过window_update，来告诉对端它可以接受的字节数。但是QUIC的窗口是适应自己的多路复用机制的，不但在一个连接上控制窗口，还在一个连接中的每个stream控制窗口。

QUIC的ACK是基于offset的，每个offset的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空挡会等待到来或者重发即可，而窗口的起始位置为当前收到的最大offset，从这个offset到当前的stream所能容纳的最大缓存，是真正的窗口大小。显然，这样更加准确。

![img](.\企业微信截图_16354745953386.png) 

### HTTPS协议



当然一般的思路就是加密。加密分为两种方式一种是对称加密，一种是非对称加密。

在**对称加密算法**中，加密和解密使用的密钥是相同的。也就是说，加密和解密使用的是同一个密钥。因此，对称加密算法要保证安全性的话，密钥要做好保密。只能让使用的人知道，不能对外公开。（密钥相互传输有问题）

在**非对称加密算法**中，加密使用的密钥和解密使用的密钥是不相同的。一把是作为公开的公钥，另一把是作为谁都不能给的私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。（私钥安全性及真伪问题）

因为对称加密算法相比非对称加密算法来说，效率要高得多，性能也好，所以交互的场景下多用对称加密。



#### 数字证书

个由权威部门颁发的称为**证书**（Certificate）
证书里面：

- 当然应该有公钥，这是最重要的；
- 还有证书的所有者；
- 另外还有证书的发布机构和证书的有效期。

生成证书需要发起一个证书请求，然后将这个请求发给一个权威机构去认证，这个权威机构我们称为**CA**（ Certificate Authority）。
  将这个请求发给权威机构，权威机构会给这个证书卡一个章，我们称为**签名算法。**只有用只掌握在权威机构手里的东西签名了才行，这就是CA的私钥。
**签名算法**：一般是对信息做一个Hash计算，得到一个Hash值，这个过程是不可逆的，也就是说无法通过Hash值得出原来的信息内容。在把信息发送出去时，把这个Hash值加密后，作为一个签名和信息一起发出去。
**签名后证书的内容**：

- 这里面有个Issuer，也即证书是谁颁发的；
- Subject，就是证书颁发给谁；
- Validity是证书期限；
- Publickey是公钥内容；
- Signature Algorithm是签名算法。

#### HTTPS的工作模式





![img](.\7042f5c3d9e3437d5b0b30b30f43c802.jpg)

当你登录一个外卖网站的时候，由于是HTTPS，客户端会发送Client Hello消息到服务器，以明文传输TLS版本信息、加密套件候选列表、压缩算法候选列表等信息。另外，还会有一个随机数，在协商对称密钥的时候使用。
然后，外卖网站返回Server Hello消息, 告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等，还有一个随机数，用于后续的密钥协商。
然后，外卖网站会给你一个服务器端的证书，然后说：“Server Hello Done，我这里就这些信息了。”
你当然不相信这个证书，于是你从自己信任的CA仓库中，拿CA的证书里面的公钥去解密外卖网站的证书。如果能够成功，则说明外卖网站是可信的。这个过程中，你可能会不断往上追溯CA、CA的CA、CA的CA的CA，反正直到一个授信的CA，就可以了。
证书验证完毕之后，觉得这个外卖网站可信，于是客户端计算产生随机数字Pre-master，发送Client Key Exchange，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。
到目前为止，无论是客户端还是服务器，都有了三个随机数，分别是：自己的、对端的，以及刚生成的Pre-Master随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。
有了对称密钥，客户端就可以说：“Change Cipher Spec，咱们以后都采用协商的通信密钥和加密算法进行加密通信了。”
然后发送一个Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。
同样，服务器也可以发送Change Cipher Spec，说：“没问题，咱们以后都采用协商的通信密钥和加密算法进行加密通信了”，并且也发送Encrypted Handshake Message的消息试试。当双方握手结束之后，就可以通过对称密钥进行加密传输了。
这个过程除了加密解密之外，其他的过程和HTTP是一样的，过程也非常复杂。
上面的过程只包含了HTTPS的单向认证，也即客户端验证服务端的证书，是大部分的场景，也可以在更
加严格安全要求的情况下，启用双向认证，双方互相验证证书。





### 流媒体协议(未完待续)

每一张图片，我们称为一**帧**。只要每秒钟帧的数据足够多，也即播放得足够快。比如每秒30帧，以人的眼睛的敏感程度，是看不出这是一张张独立的图片的，这就是我们常说的**帧率**（FPS）。

每一张图片，都是由像素组成的，假设为1024*768（这个像素数不算多）。每个像素由RGB组成，每个8位，共24位。这个数据量实在是太大，根本没办法存储和传输。

人们想到了编码，就是看如何用尽量少的Bit数保存视频，使播放的时候画面看起来仍然很精美。编码是一个压缩的过程。

之所以能够对视频流中的图片进行压缩，因为视频和图片有这样一些特点。
1. 空间冗余：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，
没必要每个像素都完整地保存，可以隔几个保存一个，中间的用算法计算出来。
2. 时间冗余：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根
据已有的图片进行预测和推断。
3. 视觉冗余：人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数
据。
4. 编码冗余：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似霍夫曼
编码（Huffman Coding）的思路。



编码过程

![img](.\433a51e15d0ed50e313454ceccd61cb4.jpg)



视频编码的两大流派

- 流派一：**ITU**（International Telecommunications Union ）的**VCEG**（Video Coding Experts Group），这个称为国际电联下的VCEG。既然是电信，可想而知，他们最初做视频编码，主要侧重传输。名词系列二，就是这个组织制定的标准。
- 流派二：**ISO**（International Standards Organization）的**MPEG**（Moving Picture Experts Group），这个是ISO旗下的MPEG，本来是做视频存储的。例如，编码后保存在VCD和DVD中。当然后来也慢慢侧重视频传输了。名词系列三，就是这个组织制定的标准。

后来，**ITU-T**（国际电信联盟电信标准化部门，ITU Telecommunication Standardization Sector ）与**MPEG****联合制定**了**H.264/MPEG-4 AVC** ，这才是我们这一节要重点关注的。

经过编码之后，生动活泼的一帧一帧的图像，就变成了一串串让人看不懂的二进制，这个二进制可以放在一个文件里面，按照一定的格式保存起来，这就是名词系列一。

当然，这个二进制也可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。
网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的**服务端来接收**这些网络包，从而得到里面的视频流，这个过程称为**接流**。
服务端接到视频流之后，可以对视频流进行一定的处理，例如转码，也即从一个编码格式，转成另一种格式。因为观众使用的客户端千差万别，要保证他们都能看到直播。
流处理完毕之后，就可以等待观众的客户端来请求这些视频流。观众的**客户端请求**的过程称为**拉流**。
如果有非常多的观众，同时看一个视频直播，那都从一个服务器上拉流，压力太大了，因而需要一个视频的**分发**网络，将视频**预先加载**到就近的**边缘节点**，这样大部分观众看的视频，是从边缘节点拉取的，就能降低服务器的压力。

当观众的客户端将视频流拉下来之后，就需要进行解码，也即通过上述过程的逆过程，将一串串看不懂的二进制，再转变成一帧帧生动的图片，在客户端播放出来。
整个直播过程，可以用这个的图来描述。

![img](.\e4d4b538c434ec0eade37028a34391f8.jpg)



### P2P协议(待续)


但是无论是HTTP的方式，还是FTP的方式，都有一个比较大的缺点，就是难以解决单一服务器的带宽压力， 因为它们使用的都是传统的客户端服务器的方式。
P2P就是peer-to-peer。资源开始并不集中地存储在某些设备上，而是分散地存储在多台设备上。这些设备我们姑且称为peer。
想要下载一个文件的时候，你只要得到那些已经存在了文件的peer，并和这些peer之间，建立点对点的连接，而不需要到中心服务器上，就可以就近下载文件。一旦下载了文件，你也就成为peer中的一员，你旁边的那些机器，也可能会选择从你这里下载文件，所以当你使用P2P软件的时候，例如BitTorrent ，往往能够看到，既有下载流量，也有上传的流量，也即你自己也加入了这个P2P的网络，自己从别人那里下载，同时也提供给其他人下载。可以想象，这种方式，参与的人越多，下载速度越快，一切完美。





### DNS协议

DNS服务器，一定要设置成高可用、高并发和分布式的。
DNS可以做内部负载均衡，还可以做全局负载均衡。

![img](.\企业微信截图_16361148135963.png)

**根DNS服务器** ：返回顶级域DNS服务器的IP地址
**顶级域DNS服务器**：返回权威DNS服务器的IP地址
**权威DNS服务器** ：返回相应主机的IP地址



#### DNS解析流程

1. 电脑客户端会发出一个DNS请求，查询www.163.com的IP，并发给本地域名服务器 (本地DNS)。本地DNS由你的网络服务商（ISP），如电信、移动等自动分配，它通常就在你网络服务商的某个机房；
2. 本地DNS收到来自客户端的请求。这台服务器上缓存了一张域名与之对应IP地址的大表格。如果能找到 www.163.com，它直接就返回IP地址。如果没有，本地DNS会去请求根域名服务器；
3. 根DNS收到来自本地DNS的请求，发现后缀是 .com，这个域名是由.com区域管理，返回它的顶级域名服务器的地址；
4. 本地DNS转向请求顶级域名服务器(比如 .com、.net、 .org这些一级域名)，它负责管理二级域名（比如 163.com）；
5. 顶级域名服务器返回 www.163.com 区域的权威DNS服务器的地址；
6. 本地DNS转向请求权威DNS服务器（163.com的权威DNS服务器，它是域名解析结果的原出处）；
7. 权限DNS服务器查询后将对应的IP地址X.X.X.X告诉本地DNS；
8. 本地DNS再将IP地址返回客户端，客户端和目标建立连接。

![img](.\企业微信截图_1636199418635.png)



#### HTTPDNS

HTTPNDS其实就是，不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商。当客户端需要DNS解析的时候，直接通过HTTP协议进行请求这个服务器集群，得到就近的地址。

> 这就相当于每家基于HTTP协议，自己实现自己的域名解析，自己做一个自己的地址簿，而不使用统一的地址簿。但是默认的域名解析都是走DNS的，因而使用HTTPDNS需要绕过默认的DNS路径，就不能使用默认的客户端。使用HTTPDNS的，往往是手机应用，需要在手机端嵌入支持HTTPDNS的客户端SDK。

![img](.\企业微信截图_16362004622471.png)

### CDN

分布在各个地方的各个数据中心的节点，就称为**边缘节点**。由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中，这样就会在边缘节点之上。有**区域节点**，规模就要更大，缓存的数据会更多，命中的概率也就更大。在区域节点之上是**中心节点**，规模更大，缓存数据更多。如果还不命中，就只好回**源站**访问了。

![img](.\企业微信截图_16362008682439.png)

这就是CDN的分发系统的架构。CDN系统的缓存，也是一层一层的，能不访问后端真正的源，就不打扰它。

#### 客户端到边缘节点访问流程

![img](.\企业微信截图_16362021538318.png)

如上图，有了CDN之后。在web.com这个权威DNS服务器上，会设置一个CNAME别名，指向另外一个域名 www.web.cdn.com，返回给本地DNS服务器。
当本地DNS服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是web.com的权威DNS服务器了，而是web.cdn.com的权威DNS服务器，这是CDN自己的权威DNS服务器。在这个服务器上，还是会设置一个CNAME，指向另外一个域名，也即CDN网络的全局负载均衡器。
接下来，本地DNS服务器去请求CDN的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：

- 根据用户IP地址，判断哪一台服务器距用户最近；
- 用户所处的运营商；
- 根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需的内容；
- 查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。

基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的IP地址。
本地DNS服务器缓存这个IP地址，然后将IP返回给客户端，客户端去访问这个边缘节点，下载资源。缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。

#### CDN缓存内容

CDN最擅长的是缓存静态数据，除此之外还可以缓存流媒体数据，这时候要注意使用防盗链。

##### 静态数据

对于静态页面来讲，内容的分发往往采取拉取的方式，也即当发现未命中的时候，再去上一级进行拉取。但是，流媒体数据量大，如果出现回源，压力会比较大，所以往往采取主动推送的模式，将热点数据主动推送到边缘节点。

##### 流媒体数据

对于流媒体来讲，很多CDN还提供预处理服务，也即文件在分发之前，经过一定的处理。

- 例如将视频转换为不同的码流，以适应不同的网络带宽的用户需求；
- 再如对视频进行分片，降低存储压力，也使得客户端可以选择使用不同的码率加载不同的分片。这就是我们常见的，“我要看超清、标清、流畅等”。

对于流媒体CDN来讲，有个关键的问题是**防盗链**问题。

###### 防盗链

- 最**常用**也最简单的方法就是**HTTP头的refer字段**， 当浏览器发送请求的时候，一般会带上referer，告诉服务器是从哪个页面链接过来的，服务器基于此可以获得一些信息用于处理。如果refer信息不是来自本站，就阻止访问或者跳到其它链接。refer的机制相对比较容易破解，所以还需要配合其他的机制。

- 一种常用的机制是**时间戳防盗链**。使用CDN的管理员可以在配置界面上，和CDN厂商约定一个加密字符串。
  客户端取出当前的时间戳，要访问的资源及其路径，连同加密字符串进行签名算法得到一个字符串，然后生成一个下载链接，带上这个签名字符串和截止时间戳去访问CDN。
  在CDN服务端，根据取出过期时间，和当前 CDN 节点时间进行比较，确认请求是否过期。然后CDN服务端有了资源及路径，时间戳，以及约定的加密字符串，根据相同的签名算法计算签名，如果匹配则一致，访问合法，才会将资源返回给客户。

##### 动态数据

有关生鲜的缓存就是非常麻烦的事情，这对应着就是动态的数据，比较难以缓存。现在也有动态CDN，主要有两种模式。

- 一种为生鲜超市模式，也即边缘计算的模式。既然数据是动态生成的，所以数据的逻辑计算和存储，也相应的放在边缘的节点。其中定时从源数据那里同步存储的数据，然后在边缘进行计算得到结果。就像对生鲜的烹饪是动态的，没办法事先做好缓存，因而将生鲜超市放在你家旁边，既能够送货上门，也能够现场烹饪，也是边缘计算的一种体现。
- 另一种是冷链运输模式，也即路径优化的模式。数据不是在边缘计算生成的，而是在源站生成的，但是数据的下发则可以通过CDN的网络，对路径进行优化。因为CDN节点较多，能够找到离源站很近的边缘节点，也能找到离用户很近的边缘节点。中间的链路完全由CDN来规划，选择一个更加可靠的路径，使用类似专线的方式进行访问。



### 数据中心

数据中心分为三层。服务器连接到接入层，然后是汇聚层，再然后是核心层，最外面是边界路由器和安全设备。

数据中心的入口和出口也是路由器，由于在数据中心的边界，就像在一个国家的边境，称为**边界路由器（Border Router）**。为了高可用，边界路由器会有多个。

既然是路由器，就需要跑路由协议，数据中心往往就是路由协议中的**自治区域（AS）**。数据中心里面的机器要想访问外面的网站，数据中心里面也是有对外提供服务的机器，都可以通过**BGP**协议，获取内外互通的路由信息。这就是我们常听到的**多线BGP**的概念。

这些交换机往往是放在机架顶端的，所以经常称为**TOR（Top Of Rack）交换机**。这一层的交换机常常称为**接入层**（Access Layer）。

当一个机架放不下的时候，就需要多个机架，还需要有交换机将多个机架连接在一起。这些交换机对性能的要求更高，带宽也更大。这些交换机称为**汇聚层交换机（Aggregation Layer）**。

数据中心里面的每一个连接都是需要考虑高可用的。所以，需要至少两个网卡、两个网线插到TOR交换机上，但是两个网卡要工作得像一张网卡一样，这就是常说的**网卡绑定（bond）**。

这就需要服务器和交换机都支持一种协议**LACP（Link Aggregation Control Protocol）**。它们互相通信，将多个网卡聚合称为一个网卡，多个网线聚合成一个网线，在网线之间可以进行负载均衡，也可以为了高可用作准备。

 ![img](.\企业微信截图_16365052239322.png) 

网卡有了高可用保证，但交换机还有问题。因而T **OR交换 机也需要高可用**，同理接入层和汇聚层的连接也需要高可用性，也不能单线连着。
最传统的方法是，部署两个接入交换机、两个汇聚交换机。服务器和两个接入交换机都连接，接入交换机和两个汇聚都连接，当然这样会形成环，所以需要启用**STP协议**，去除环，但是这样两个**汇聚就只能一主一备**了。STP协议里我们学过，只有一条路会起作用。

交换机有一种技术叫作**堆叠**，所以另一种方法是，将多个交换机形成一个逻辑的交换机，服务器通过多根线分配连到多个接入层交换机上，而接入层交换机多根线分别连接到多个交换机上，并且通过**堆叠的私有协议**，**形成双活**的连接方式。

 ![img](.\企业微信截图_16365054677003.png) 

汇聚层将大量的计算节点相互连接在一起，形成一个集群。在这个集群里面，服务器之间通过二层互通，这个区域常称为一个POD（Point Of Delivery），有时候也称为一个**可用区（AvailableZone）**。
当节点数目再多的时候，一个可用区放不下，需要将多个可用区连在一起，连接多个可用区的交换机称为**核心交换机**。

 ![img](.\企业微信截图_16365056498738.png) 

不同的可用区在不同的二层网络，需要分配不同的网段。汇聚和核心之间通过三层网络互通的，二层都不在一个广播域里面，不会存在二层环路的问题。三层有环是没有问题的，只要通过路由协议选择最佳的路径就可以了。

 ![img](.\企业微信截图_16365057299147.png) 

但是随着数据中心里面的机器越来越多，尤其是有了云计算、大数据，集群规模非常大，而且都要求在一个二层网络里面。这就**需要二层互连从汇聚层上升为核心层**，也即在核心以下，全部是二层互连，全部在一个广播域里面，这就是常说的**大二层**。

 ![img](.\企业微信截图_16365057755272.png) 

如果大二层横向流量不大，核心交换机数目不多，可以做堆叠，但是如果横向流量很大，仅仅堆叠满足不了，就需要部署多组核心交换机，而且要和汇聚层进行全互连。由于堆叠只解决一个核心交换机组内的无环问题，而组之间全互连，还需要其他机制进行解决。
如果是STP，那部署多组核心无法扩大横向流量的能力，因为还是只有一组起作用。
于是大二层就引入了**TRILL（Transparent Interconnection of Lots of Link ）**，即**多链接透明互联协议**。它的基本思想是，二层环有问题，三层环没有问题，那就把三层的路由能力模拟在二层实现。**运行TRILL协议的交换机称为RBridge，是具有路由转发特性的网桥设备，只不过这个路由是根据MAC地址来的，不是根据IP来的。**
Rbridage之间通过链路状态协议运作。记得这个路由协议吗？通过它可以学习整个大二层的拓扑，知道访问哪个MAC应该从哪个网桥走；还可以计算最短的路径，也可以通过等价的路由进行负载均衡和高可用性。

 ![img](.\企业微信截图_16365059451271.png) 

这是一个典型的**三层网络结构**。这里的三层不是指IP层，而是**指接入层、汇聚层、核心层三层**。这种模式非常有利于外部流量请求到内部应用。这个类型的流量，是从外到内或者从内到外，对应到上面那张图里，就是从上到下，从下到上，上北下南，所以**称为南北流量**。

但是随着云计算和大数据的发展，节点之间的交互越来越多，例如大数据计算经常要在不同的节点将数据拷贝来拷贝去，这样需要经过交换机，使得数据从左到右，从右到左，左西右东，所以称为东西流量。

为了解决东西流量的问题，演进出了**叶脊网络（Spine/Leaf）**。
**叶子交换机（leaf），直接连接物理服务器。**L2/L3网络的分界点在叶子交换机上，**叶子交换机之上是三层网络**。
**脊交换机（spine switch），相当于核心交换机。**叶脊之间通过ECMP动态选择多条路径。脊交换机现在只是为叶子交换机提供一个弹性的L3路由网络。南北流量可以不用直接从脊交换机发出，而是通过与leaf交换机并行的交换机，再接到边界路由器出去。

 ![img](.\企业微信截图_16365060321877.png) 

传统的三层网络架构是垂直的结构，而**叶脊网络架构是扁平的结构，更易于水平扩展**。



### VPN

需要将多个数据中心连接起来，或者需要办公室和数据中心连接起来的方法：

- 第一种方式是走公网，但是公网太不安全，你的隐私可能会被别人偷窥；
- 第二种方式是租用专线的方式把它们连起来，这是土豪的做法，需要花很多钱；
- 第三种方式是用VPN来连接，这种方法比较折中，安全又不贵。

 ![img](.\企业微信截图_16365071701992.png) 



#### vpn概念

**VPN**，全名**Virtual Private Network**，**虚拟专用网**，就是利用开放的公众网络，建立专用数据传输通道，将远程的分支机构、移动办公人员等连接起来。

VPN通过**隧道技术**在公众网络上仿真一条点到点的专线，是通过利用一种协议来传输另外一种协议的技 术，这里面涉及三种协议：**乘客协议、隧道协议和承载协议**。

我们以IPsec协议为例来说明。

 ![img](.\企业微信截图_16365074764368.png) 



#### IPsec VPN

**IPsec VPN**是**基于IP协议的安全隧道协议**，为了保证在公网上面信息的安全，因而采取了一定的机制保证安全性。

- 机制一：**私密性**，防止信息泄漏给未经授权的个人，通过加密把数据从明文变成无法读懂的密文，从而确保数据的私密性。采取**对称加密**(处理数据量大)和**因特网密钥交换**（**IKE**，Internet Key Exchange）协议（解决交换密钥问题）。
- 机制二：**完整性**，数据没有被非法篡改，通过对数据进行hash运算，产生类似于指纹的数据摘要，以保证数据的完整性。
- 机制三：**真实性**，数据确实是由特定的对端发出，通过身份认证可以保证数据的真实性。
  - 第一种方法就是预共享密钥；
  - 另外一种方法就是用数字签名来验证。使用私钥进行签名。

基于以上三个特性，组成了**IPsec VPN的协议簇**。这个协议簇内容比较丰富。

 ![img](.\企业微信截图_16365101271391.png) 

在这个协议簇里面，**有两种协议**，这两种协议的区别在于封装网络包的格式不一样。

- 一种协议称为**AH（Authentication Header**），只能进行数据摘要 ，不能实现数据加密。
- 还有一种**ESP（Encapsulating Security Payload）**，能够进行数据加密和数据摘要。

在这个协议簇里面，还有**两类算法**，分别是**加密算法**和**摘要算法**。
 这个协议簇还包含**两大组件**：

- 一个用于VPN的双方要进行**对称密钥的交换**的**IKE组件**；
- 一个是VPN的**双方要对连接进行维护**的**SA（Security Association）组件**。



##### IPsec VPN的建立过程

第一个阶段，**建立IKE自己的SA**。在这个阶段，通过DH（Diffe-Hellman）算法计算出一个对称密钥K。

 ![img](.\企业微信截图_16365115963622.png) 



接下来是第二个阶段，**建立IPsec SA**。在这个SA里面，双方会生成一个随机的对称密钥M，由K加密传给对方，然后使用M进行双方接下来通信的数据。对称密钥M是有过期时间的，会过一段时间，重新生成一次，从而防止被破解。

IPsec SA里面有以下内容：

- SPI（Security Parameter Index），用于标识不同的连接；
- 双方商量好的加密算法、哈希算法和封装模式；
- 生存周期，超过这个周期，就需要重新生成一个IPsec SA，重新生成对称密钥。

 ![img](.\企业微信截图_16365116669656.png) 

两个阶段建立的图示。



 有了IPsec VPN之后，客户端发送的明文的IP包，都会被加上ESP头和IP头，在公网上传输，由于加密，可以保证不被窃取，到了对端后，去掉ESP的头，进行解密。![img](.\企业微信截图_16365118367120.png) 

左面是原始的IP包，在IP头里面，会指定上一层的协议为TCP。ESP要对IP包进行封装，因而IP头里面的上一层协议为ESP。在ESP的正文里面，ESP的头部有双方商讨好的SPI，以及这次传输的序列号。

这种点对点的基于IP的VPN，能满足互通的要求，但是速度往往比较慢，这是由底层IP协议的特性决定的。IP不是面向连接的，是尽力而为的协议，每个IP包自由选择路径，到每一个路由器，都自己去找下一跳，丢了就丢了，是靠上一层TCP的重发来保证可靠性。

和IP对应的另一种技术称为**ATM**。这种协议和IP协议的不同在于，它是面向连接的。你可以说TCP也是面向连接的啊。这两个不同，ATM和IP是一个层次的，和TCP不是一个层次的。

好处是不需要每次都查路由表的，虚拟路径已经建立，打上了标签，后续的包傻傻的跟着走就是了，坏处是一旦虚拟路径上的某个路由器坏了，则这个连接就断了，什么也发不过去了，因为其他的包还会按照原来的路径走。

#### 多协议标签交换MPLS

是多协议标签交换（MPLS，**Multi-Protocol Label Switchin**g）。MPLS的格式如图所示，在原始的IP头之外，多了MPLS的头，里面可以打标签。

有了标签，还需要设备认这个标签，并且能够根据这个标签转发，这种能够转发标签的路由器称为标签交换路由器（LSR，Label Switching Router）。

这种路由器会有两个表格，一个就是传统的FIB，也即路由表，另一个就是LFIB，标签转发表。有了这两个表，既可以进行普通的路由转发，也可以进行基于标签的转发。

 ![img](.\企业微信截图_1636512219678.png) 

这里我们区分MPLS区域和非MPLS区域。在MPLS区域中间，使用标签进行转发，非MPLS区域，使用普通路由转发，在边缘节点上，需要有能力将对于普通路由的转发，变成对于标签的转发。

这样一个通过标签转换而建立的路径称为LSP，标签交换路径。在一条LSP上，沿数据包传送的方向，



相邻的LSR分别叫上游LSR（upstream LSR）和下游LSR（downstream LSR）。
有了标签，转发是很简单的事，但是如何生成标签，却是MPLS中最难修炼的部分。在MPLS秘笈中，这部分被称为LDP（Label Distribution Protocol），是一个动态的生成标签的协议。
其实LDP与IP帮派中的路由协议十分相像，通过LSR的交互，互相告知去哪里应该打哪个标签，称为标签分发，往往是从下游开始的。

![1636512725156](.\1636512725156.png)

如果有一个边缘节点发现自己的路由表中出现了新的目的地址，它就要给别人说，我能到达一条新的路径了。
如果此边缘节点存在上游LSR，并且尚有可供分配的标签，则该节点为新的路径分配标签，并向上游发出标签映射消息，其中包含分配的标签等信息。
收到标签映射消息的LSR记录相应的标签映射信息，在其标签转发表中增加相应的条目。此LSR为它的上游LSR分配标签，并继续向上游LSR发送标签映射消息。
当入口LSR收到标签映射消息时，在标签转发表中增加相应的条目。这时，就完成了LSP的建立。有了标签，转发轻松多了。





####  MPLS VPN![img](.\企业微信截图_16365127679481.png) 



在MPLS VPN中，网络中的路由器分成以下几类：

- PE（Provider Edge）：运营商网络与客户网络相连的边缘网络设备；
- CE（Customer Edge）：客户网络与PE相连接的边缘设备；
- P（Provider）：这里特指运营商网络中除PE之外的其他运营商网络设备。

PE路由器之间使用特殊的MP-BGP来发布VPN路由，在相互沟通的消息中，在一般32位IPv4的地址之前加上一个客户标示的区分符用于客户地址的区分，这种称为VPN-IPv4地址族，这样PE路由器会收到如下的消息，机构A的192.168.101.0/24应该往这面走，机构B的192.168.101.0/24则应该去另外一个方向。

在PE上，可以通过VRF（VPN Routing&Forwarding Instance）建立每个客户一个路由表，与其它VPN客户路由和普通路由相互区分。可以理解为专属于客户的小路由器。
远端PE通过MP-BGP协议把业务路由放到近端PE，近端PE根据不同的客户选择出相关客户的业务路由放到相应的VRF路由表中。

VPN报文转发采用两层标签方式：

- 第一层（外层）标签在骨干网内部进行交换，指示从PE到对端PE的一条LSP。VPN报文利用这层标签，可以沿LSP到达对端PE；
- 第二层（内层）标签在从对端PE到达CE时使用，在PE上，通过查找VRF表项，指示报文应被送到哪个VPN用户，或者更具体一些，到达哪一个CE。这样，对端PE根据内层标签可以找到转发报文的接口。

![img](.\企业微信截图_16365128901829.png) 



我们来举一个例子，看MPLS VPN的包发送过程。
1. 机构A和机构B都发出一个目的地址为192.168.101.0/24的IP报文，分别由各自的CE将报文发送
至PE。
2. PE会根据报文到达的接口及目的地址查找VPN实例表项VRF，匹配后将报文转发出去，同时打上内
层和外层两个标签。假设通过MP-BGP配置的路由，两个报文在骨干网走相同的路径。
3. MPLS网络利用报文的外层标签，将报文传送到出口PE，报文在到达出口PE 2前一跳时已经被剥离
外层标签，仅含内层标签。
4. 出口PE根据内层标签和目的地址查找VPN实例表项VRF，确定报文的出接口，将报文转发至各自
的CE。
5. CE根据正常的IP转发过程将报文传送到目的地。



### 移动网络(待补充)



### 虚拟网络

#### 虚拟网卡的原理

![img](.\企业微信截图_16365155253330.png) 



首先，虚拟机要有一张网卡。对于**qemu-kvm**来说，这是通过Linux上的一种**TUN/TAP**技术来实现的。
虚拟机是物理机上跑着的一个软件。这个软件可以像其他应用打开文件一样，打开一个称  为TUN/TAP的Char Dev（字符设备文件）。打开了这个字符设备文件之后，在物理机上就能看到一张虚拟TAP网卡。
虚拟化软件会将打开的这个文件，在虚拟机里面虚拟出一张网卡，让虚拟机里面的应用觉得它们真有一张网卡。于是，所有的网络包都往这里发。
当然，网络包会到虚拟化软件这里。它会将网络包转换成为文件流，写入字符设备，就像写一个文件一样。内核中TUN/TAP字符设备驱动会收到这个写入的文件流，交给TUN/TAP的虚拟网卡驱动。这个驱动将文件流再次转成网络包，交给TCP/IP协议栈，最终从虚拟TAP网卡发出来，成为标准的网络包。
就这样，几经转手，数据终于从虚拟机里面，发到了虚拟机外面。

#### 虚拟网卡连接到云中

在接入之前，我们先来看，云计算中的网络都需要注意哪些点。
共享；隔离；互通；灵活。

##### 共享与互通问题

在物理机上，应该有一个虚拟的交换机，在Linux上有一个命令叫作brctl，可以创建虚拟的网桥brctladdbr br0。创建出来以后，将两个虚拟机的虚拟网卡，都连接到虚拟网桥brctl addif br0 tap0上，这样将两个虚拟机配置相同的子网网段，两台虚拟机就能够相互通信了。

```
# 创建网桥br0
brctl  addbr br0
# 将虚拟网卡tap0连接到虚拟网桥br0
brctl addif br0 tap0
```

**host-only**的网络对应的，其实就是上面两个虚拟机连到一个br0虚拟网桥上，而且不考虑访问外部的场景，只要虚拟机之间能够相互访问就可以了。

如果要访问外部，往往有两种方式。
一种方式称为**桥接**。如果在桌面虚拟化软件上选择桥接网络，则在你的笔记本电脑上，就会形成下面的结构。
相当于将物理机和虚拟机放在同一个网桥上，相当于这个网桥上有三台机器，是一个网段的

 ![img](.\企业微信截图_163652608628.png)  

另外一种方式称为**NAT**。

![img](.\企业微信截图_16365262197804.png) 

虚拟机要想访问物理机的时候，需要将地址NAT成为物理机的地址。

除此之外，它还会在你的笔记本电脑里内置一个**DHCP服务器**，为笔记本电脑上的虚拟机动态分配IP地址。因为**虚拟机的网络自成体系，需要进行IP管理**。为什么桥接方式不需要呢？因为桥接将网络打平了，虚拟机的IP地址应该由物理网络的DHCP服务器分配。

##### 隔离问题

好在brctl创建的网桥也是支持VLAN功能的，可以设置两个虚拟机的tag，这样在这个虚拟网桥上，两个虚拟机是不互通的。

有一个命令**vconfig**，可以基于物理网卡eth0创建带VLAN的虚拟网卡，所有从这个虚拟网卡出去的包，都带这个VLAN，如果这样，跨物理机的互通和隔离就可以通过这个网卡来实现。

 ![img](.\dfc95f72325ab13c2f9551cfccc073e0.jpg) 

 首先为每个用户分配不同的VLAN，例如有一个用户VLAN 10，一个用户VLAN 20。在一台物理机上，基于物理网卡，为每个用户用vconfig创建一个带VLAN的网卡。不同的用户使用不同的虚拟网桥，带VLAN的虚拟网卡也连接到虚拟网桥上。 

 不同的用户由于网桥不通，不能相互通信，一旦出了网桥，由于VLAN不同，也不会将包转发到另一个网桥上。另外，出了物理机，也是带着VLAN ID的。只要物理交换机也是支持VLAN的，到达另一台物理机的时候，VLAN ID依然在，它只会将包转发给相同VLAN的网卡和网桥，所以跨物理机，不同的VLAN也不会相互通信。 

### 软件定义网络（SDN）

 ![img](.\企业微信截图_16365291154946.png) 

**控制与转发分离**：转发平面就是一个个虚拟或者物理的网络设备。控制平面就是统一的控制中心;
**控制平面与转发平面之间的开放接口**：控制器向上提供接口，被应用层调用。控制器向下调用接口，来控制网络设备。这里经常使用两个名词，前面这个接口称为北向接口，后面这个接口称为南向接口;
**逻辑上的集中控制**：逻辑上集中的控制平面可以控制多个转发面设备，也就是控制整个物理网络，因而可以获得全局的网络状态视图，并根据该全局网络状态视图实现对网络的优化控制。

#### OpenFlow和OpenvSwitch

OpenFlow是SDN控制器和网络设备之间互通的南向接口协议，**OpenvSwitch用于创建软件的虚拟交换机**。**OpenvSwitch是支持OpenFlow协议**的，当然也有一些硬件交换机也支持OpenFlow协议。它们都可以被统一的SDN控制器管理，从而实现物理机和虚拟机的网络连通。

![img](.\企业微信截图_16365302979100.png) 

SDN控制器是通过OpenFlow协议控制网络

![img](.\企业微信截图_16365318292017.png) 

在**OpenvSwitch**里面，有一个**流表规则**，任何通过这个交换机的包，都会经过这些规则进行处理，从而接收、转发、放弃。
**流表**其实就是一个个表格，每个表格好多行，每行都是一条规则。每条规则都有优先级，先看高优先级的规则，再看低优先级的规则。

通过这些表格，OpenvSwitch可以对收到的网络包随意处理。

 ![img](.\企业微信截图_16365320512216.png) 
**OpenvSwitch**有本地的命令行可以进行配置，能够实验咱们前面讲过的一些功能。我们可以通过OpenvSwitch的命令创建一个虚拟交换机。然后可以将多个虚拟端口port添加到这个虚拟交换机上。

```
# ovs创建虚拟交换机
ovs-vsctl add-br ubuntu_br
```

#### OpenvSwitch实现VLAN的功能

OpenvSwitch中端口port分两种：

- 第一类是**access port**：
  - 这个端口配置tag，从这个端口进来的包会被打上这个tag；
  - 如果网络包本身带有的VLAN ID等于tag，则会从这个port发出；
  - 从access port发出的包不带VLAN ID。

- 第二类是**trunk port**：
  - 这个port不配置tag，配置trunks；
  - 如果trunks为空，则所有的VLAN都trunk，也就意味着对于所有VLAN的包，本身带什么VLAN ID，就是携带者什么VLAN ID，如果没有设置VLAN，就属于VLAN 0，全部允许通过；
  - 如果trunks不为空，则仅仅带着这些VLAN ID的包通过。



我们通过以下命令创建如下的环境：

```
ovs-vsctl add-port ubuntu_br frs_br
ovs-vsctl add-port ubuntu_br second_br
ovs-vsctl add-port ubuntu_br third_br
ovs-vsctl set Port vnet0 tag=101
ovs-vsctl set Port vnet1 tag=102
ovs-vsctl set Port vnet2 tag=103
ovs-vsctl set Port frs_br tag=103
ovs-vsctl clear Port second_br tag
ovs-vsctl set Port third_br trunks=101,102 
```

另外要配置禁止MAC地址学习。

```
ovs-vsctl set bridge ubuntu_br food-vlans=101,102,103 
```

 ![img](.\企业微信截图_16365338102017.png)   

>1. 从192.168.100.102来 ping 192.168.100.103，然后用tcpdump进行抓包。frst_if收到包了，从frst_br出来的包头是没有VLAN ID 的。second_ if也收到包 了，由于second_br是trunk port，因而出来的包头是有VLAN ID的，third_if收不到包。
>2. 从192.168.100.100来ping 192.168.100.105, 则second_if和third_if可以收到包，当然ping不通，因为third_if不属于某个VLAN。frst_if是收不到包的。second_if能够收到包，而且包头里面是VLANID=101。third_if也能收到包，而且包头里面是VLAN ID=101。
>3. 从192.168.100.101来ping 192.168.100.104， 则second_if和third_if可以收到包。frst_if是收不到包的。second_br能够收到包，而且包头里面是VLAN ID=102。third_if也能收到包，而且包头里面是VLAN ID=102。
>   通过这个例子，我们可以看到，通过OpenvSwitch，不用买一个支持VLAN的交换机，你也能学习VLAN的工作模式了。

#### OpenvSwitch模拟网卡绑定，连接交换机

在OpenvSwitch里面，有个**bond_mode**，可以设置为以下三个值：

- active-backup：一个连接是active，其他的是backup，当active失效的时候，backup顶上；
- balance-slb：流量安装源MAC和output VLAN进行负载均衡；
- balance-tcp：必须在支持LACP协议的情况下才可以，可根据L2, L3, L4进行负载均衡。

 ![img](.\企业微信截图_16365340867465.png) 

```
# 使用下面的命令，建立bond连接
ovs-vsctl add-bond br0 bond0 frs_br second_br
ovs-vsctl add-bond br1 bond1 frs_if second_if
ovs-vsctl set Port bond0 lacp=active
ovs-vsctl set Port bond1 lacp=active
```

> 默认情况下bond_mode是active-backup模式，一开始active的是frst_br和frst_if。
> 这个时候我们从192.168.100.100 ping 192.168.100.102，以及从192.168.100.101 ping 192.168.100.103的时
> 候，tcpdump可以看到所有的包都是从frst_if通过。
> 如果把frst_if设成down，则包的走向会变，发现second_if开始有流量，对于192.168.100.100和192.168.100.101似乎没有收到影响。



```
ovs-vsctl set Port bond0 bond_mode=balance-slb
ovs-vsctl set Port bond1 bond_mode=balance-slb
```

> 如果我们通过以上命令，把bond_mode设为balance-slb。然后我们同时在192.168.100.100 ping 192.168.100.102，在192.168.100.101 ping 192.168.100.103，我们通过tcpdump发现包已经被分流了。



##### OpenvSwitch的架构图

 ![img](.\企业微信截图_1636535318321.png) 

OpenvSwitch包含很多的模块，在**用户态**有两个重要的**进程**，也有两个重要的命令行工具。

- 第一个进程是**OVSDB进程**。**ovs-vsctl命令行**会和这个进程通信，去创建虚拟交换机，创建端口，  端口添加到虚拟交换机上，OVSDB会将这些拓扑信息保存在一个本地的文件中。
- 另一个进程是**vswitchd进程**。**ovs-ofctl命令行**会和这个进程通信，去下发流表规则，规则里面会规定如何对网络包进行处理，vswitchd会将流表放在用户态Flow Table 中。

在**内核态**，OpenvSwitch有内核模块OpenvSwitch.ko，对应图中的**Datapath**部分。在网卡上注册一个函数，每当有网络包到达网卡的时候，这个函数就会被调用。在内核的这个函数里面，会拿到网络包，将各个层次的重要信息拿出来。

在内核中，有一个**内核态Flow Table** 。接下来内核模块在这个内核流表中匹配规则，如果匹配上了，则执行操作、修改包，或者转发或者放弃。如果内核没有匹配上，则需要进入用户态**，用户态和内核态之间通过Linux的一个机制Netlink相互通信。**
内核通过**upcall**，告知用户态进程vswitchd在用户态Flow Table里面去匹配规则，这里面的规则是全量的流表规则，而内核Flow Table里面的只是为了快速处理，保留了部分规则，内核里面的规则过一阵就会过期。
当在用户态匹配到了流表规则之后，就在用户态执行操作，同时将这个匹配成功的流表通过**reinject**下发到内核，从而接下来的包都能在内核找到这个规则。
这里调用openfow协议的，是本地的命令行工具，也可以是远程的SDN控制器，一个重要的SDN控制器是OpenDaylight。

#### 在云计算中使用OpenvSwitch

![img](.\企业微信截图_16365366683268.png) 

首先，由于OpenvSwitch本身就是支持VLAN的，所有的虚拟机都可以放在一个网桥br0上，通过不同的用户配置不同的tag，就能够实现隔离。例如上面的图，用户A的虚拟机都在br0上，用户B的虚拟机都在br1上，有了OpenvSwitch，就可以都放在br0上，只是设置了不同的tag。
另外，还可以创建一个虚拟交换机br1，将物理网络和虚拟网络进行隔离。物理网络有物理网络的VLAN规划，虚拟机在一台物理机上，所有的VLAN都是从1开始的。由于一台机器上的虚拟机不会超过4096个，所以VLAN在一台物理机上如果从1开始，肯定够用了。

例如在图中，上面的物理机里面，用户A被分配的tag是1，用户B被分配的tag是2，而在下面的物理机里面，用户A被分配的tag是7，用户B被分配的tag是6。
如果物理机之间的通信和隔离还是通过VLAN的话，需要将虚拟机的VLAN和物理环境的VLAN对应起来，但为了灵活性，不一定一致，这样可以实现分别管理物理机的网络和虚拟机的网络。好在OpenvSwitch可以对包的内容进行修改。例如通过匹配dl_vlan，然后执行mod_vlan_vid来改进进出出物理机的网络包。
尽管租户多了，物理环境的VLAN还是不够用，但是有了OpenvSwitch的映射，将物理和虚拟解耦，从而可以让物理环境使用其他技术，而不影响虚拟机环境，这个我们后面再讲。

### 网络安全

#### 安全策略

云中的安全策略的常用方式是，使用iptables的规则，请记住它的五个阶段**，PREROUTING、INPUT、FORWARD、OUTPUT、POSTROUTING**。

对于公有云上的虚拟机，只要通过安全措施守护好这个唯一的入口就可以了。采用的方式常常是用**ACL**（Access Control List，**访问控制列表**）来控制IP和端口。

在云平台上，这些规则的集合常称为**安全组**。

在Linux内核中，有一个框架叫**Netfilter**。它可以在这些节点插入hook函数。这些函数可以截获数据包，对数据包进行干预。例如做一定的修改，然后决策是否接着交给TCP/IP协议栈处理；或者可以交回给协议栈，那就是ACCEPT；或者过滤掉，不再传输，就是DROP；还有就是QUEUE，发送给某个用户态进程处理。

一个著名的实现，就是**内核模块ip_tables**。它在这五个节点上埋下函数，从而可以根据规则进行包的处理。按功能可分为四大类：**连接跟踪（conntrack）、数据包的过滤（fliter）、网络地址转换（nat）和数据包的修改（mangle）**。其中连接跟踪是基础功能，被其他功能所依赖。其他三个可以实现包的过滤、修改和网络地址转换。

iptables分为四种表，raw、mangle、nat、flter。其中**安全策略主要在filter表中实现**，而**虚拟网络和物理网络地址的转换主要在nat表中实现**。

在用户态，还有一个你肯定知道的客户端程序iptables，用命令行来干预内核的规则。**内核的功能对应iptables的命令行来讲，就是表和链的概念。**

#### iptables的filter功能

![img](.\企业微信截图_16366118351250.png) 

**iptables的表分为四种：raw–>mangle–>nat–>flter。**这四个优先级依次降低，raw不常用，所以主要功能都在其他三种表里实现。每个表可以设置多个链。

- **filter**表处理过滤功能，主要包含三个链：
  - **INPUT**链：过滤所有目标地址是本机的数据包；
  - **FORWARD**链：过滤所有路过本机的数据包；
  - **OUTPUT**链：过滤所有由本机产生的数据包。

- **nat**表主要是处理网络地址转换，可以进行**Snat（改变数据包的源地址）**、**Dnat（改变数据包的目标地 址）**，包含三个链：
  - **PREROUTING**链：可以在数据包到达防火墙时改变目标地址；
  - **OUTPUT**链：可以改变本地产生的数据包的目标地址；
  - **POSTROUTING**链：在数据包离开防火墙时改变数据包的源地址。

- **mangle**表主要是修改数据包，包含：
  - **PREROUTING**链；
  - **INPUT**链；
  - **FORWARD**链；
  - **OUTPUT**链；
  - **POSTROUTING**链。

将iptables的表和链加入到上面的过程图中，就形成了下面的图和过程。

![img](.\企业微信截图_16366118982840.png) 

1. 数据包进入的时候，先进mangle表的PREROUTING链。在这里可以根据需要，改变数据包头内容之后，进入nat表的PREROUTING链，在这里可以根据需要做Dnat，也就是目标地址转换。
2. 进入路由判断，要判断是进入本地的还是转发的。
3. 如果是进入本地的，就进入INPUT链，之后按条件过滤限制进入。
4. 之后进入本机，再进入OUTPUT链，按条件过滤限制出去，离开本地。
5. 如果是转发就进入FORWARD链，根据条件过滤限制转发。
6. 之后进入POSTROUTING链，这里可以做Snat，离开网络接口。

#### iptables命令

```
# 拒绝所有
iptables -t flter -A INPUT -s 0.0.0.0/0.0.0.0 -d X.X.X.X -j DROP
# 打开22端口
iptables -I INPUT -s 0.0.0.0/0.0.0.0 -d X.X.X.X -p tcp --dport 22 -j ACCEPT
# 打开80端口供web服务使用
iptables -A INPUT -s 0.0.0.0/0.0.0.0 -d X.X.X.X -p tcp --dport 80 -j ACCEPT

# 源地址转换(Snat)
iptables -t nat -A -s 私网IP -j Snat --to-source 外网IP
# 目的地址转换(Dnat)
iptables -t nat -A -PREROUTING -d 外网IP -j Dnat --to-destination 私网IP
```

在云平台上，一般允许一个或者多个虚拟机属于某个安全组，而属于不同安全组的虚拟机之间的访问以及外网访问虚拟机，都需要通过安全组进行过滤。

 ![img](.\企业微信截图_16366132372640.png) 

两个VM都通过tap网卡连接到一个网桥上，但是网桥是二层的，两个VM之间是可以随意互通的，因而需要有一个地方统一配置这些iptables规则。

可以多加一个网桥，在这个网桥上配置iptables规则，将在用户在界面上配置的规则，放到这个网桥上。然后在每台机器上跑一个Agent，将用户配置的安全组变成iptables规则，配置在这个网桥上。

#### iptables的nat功能

在设计云平台的时候，我们想让虚拟机之间的网络和物理网络进行隔离，但是虚拟机毕竟还是要通过物理网和外界通信的，因而需要在出物理网的时候，做一次网络地址转换，也即nat，这个就可以用iptables来做。
我们学过，IP头里面包含源IP地址和目标IP地址，这两种IP地址都可以转换成其他地址。转换源IP地址的，我们称为Snat；转换目标IP地址的，我们称为Dnat。

##### MASQUERADE（地址伪装）

这种Snat是一种特殊的**Snat**，MASQUERADE（地址伪装）。

这种方式下，所有的虚拟机共享一个机房网和公网的IP地址，所有从外网网口出去的，都转换成为这个IP地址。
在返回时，就需要Netfilter的连接跟踪（**conntrack**）功能了。对于TCP协议来讲，肯定是上来先建立一个连接，可以用“源/目的IP+源/目的端口”唯一标识一条连接，这个连接会放在conntrack表里面。当时是这台机器去请求163网站的，虽然源地址已经Snat成公网IP地址了，但是conntrack表里面还是有这个连接的记录的。当163网站返回数据的时候，会找到记录，从而找到正确的私网IP地址。

### 网络QoS

在云平台上，也有这种现象，好在有一种流量控制的技术，可以实现**QoS（Quality of Service）**，从而保障大多数用户的服务质量。

 ![img](.\企业微信截图_16366176275232.png) 

对于控制一台机器的网络的QoS，分两个方向，一个是入方向，一个是出方向。
其实我们能控制的只有出方向，通过Shaping，将出的流量控制成自己想要的模样。而进入的方向是无法控制的，只能通过Policy将包丢弃。

#### 控制网络的QoS的方式

在Linux下，可以通过TC控制网络的QoS，主要就是通过队列的方式。

##### 无类别排队规则

第一大类称为**无类别排队规则（Classless Queuing Disciplines）**，这是一种不把网络包分类的技术。

 ![img](H:\code\learnning\openstack-stein-mugnum\企业微信截图_16366163482602.png) 

**pfifo_fast**分为三个先入先出的队列，称为三个Band。根据网络包里面TOS，看这个包到底应该进入哪个队列。TOS总共四位，每一位表示的意思不同，总共十六种类型。
通过命令行`tc qdisc show dev eth0`，可以输出结果priomap，也是十六个数字。在0到2之间，和TOS的十六种类型对应起来，表示不同的TOS对应的不同的队列。**其中Band 0优先级最高，发送完毕后才轮到Band 1发送，最后才是Band 2。**

##### 随机公平队列

另外一种无类别队列规则叫作**随机公平队列（Stochastic Fair Queuing）**。

 ![img](.\企业微信截图_16366164608946.png) 

**会建立很多的FIFO的队列，TCP Session会计算hash值，通过hash值分配到某个队列。**在队列的另一端，网络包会通过轮询策略从各个队列中取出发送。这样不会有一个Session占据所有的流量。当然如果两个Session的hash是一样的，会共享一个队列，也有可能互相影响。hash函数会经常改变，从而session不会总是相互影响。

##### 令牌桶规则

还有一种无类别队列规则称为**令牌桶规则（TBF，Token Bucket Filte** ）。

 ![img](.\企业微信截图_16366165174081.png) 

**所有的网络包排成队列进行发送，但不是到了队头就能发送，而是需要拿到令牌才能发送。**
令牌根据设定的速度生成，所以即便队列很长，也是按照一定的速度进行发送的。
当没有包在队列中的时候，令牌还是以既定的速度生成，但是不是无限累积的，而是放满了桶为止。设置桶的大小为了避免下面的情况：当长时间没有网络包发送的时候，积累了大量的令牌，突然来了大量的网络包，每个都能得到令牌，造成瞬间流量大增。

##### 基于类别的队列规则

另外一大类是**基于类别的队列规则（Classful Queuing Disciplines）**，其中典型的为**分层令牌桶规则（HTB**， Hierarchical Token Bucket ）。

 ![img](.\企业微信截图_16366167059361.png) 

**使用TC可以为某个网卡eth0创建一个HTB的队列规则，需要付给它一个句柄为（1:）**。
这是整棵树的根节点，接下来会有分支。例如图中有三个分支，句柄分别为（:10）、（:11）、（:12）。最后的参数default 12，表示默认发送给1:12，也即发送给第三个分支。

```
tc qdisc add dev eth0 root handle 1: htb default 12
```

**对于这个网卡，需要规定发送的速度。**一般有两个速度可以配置，一个是**rate**，表示一般情况下的速度；一个是**ceil**，表示最高情况下的速度。对于根节点来讲，这两个速度是一样的，于是创建一个root class，速度为（rate=100kbps，ceil=100kbps）。

```
tc class add dev eth0 parent 1: classid 1:1 htb rate 100kbps ceil 100kbps
```

接下来要创建分支，也即创建几个子class。每个子class统一有两个速度。三个分支分别为（rate=30kbps，ceil=100kbps）、（rate=10kbps，ceil=100kbps）、（rate=60kbps，ceil=100kbps）。

```
tc class add dev eth0 parent 1:1 classid 1:10 htb rate 30kbps ceil 100kbps
tc class add dev eth0 parent 1:1 classid 1:11 htb rate 10kbps ceil 100kbps
tc class add dev eth0 parent 1:1 classid 1:12 htb rate 60kbps ceil 100kbps
```

你会发现三个rate加起来，是整个网卡允许的最大速度。
**HTB有个很好的特性，同一个root class下的子类可以相互借流量，如果不直接在队列规则下面创建一个root class，而是直接创建三个class，它们之间是不能相互借流量的。**借流量的策略，可以使得当前不使用这个分支的流量的时候，可以借给另一个分支，从而不浪费带宽，使带宽发挥最大的作用。
最后，创建叶子队列规则，分别为fifo和sfq。

```
tc qdisc add dev eth0 parent 1:10 handle 20: pfifo limit 5
tc qdisc add dev eth0 parent 1:11 handle 30: pfifo limit 5
tc qdisc add dev eth0 parent 1:12 handle 40: sfq perturb 10
```

基于这个队列规则，我们还可以通过TC设定发送规则：从1.2.3.4来的，发送给port 80的包，从第一个分支1:10走；其他从1.2.3.4发送来的包从第二个分支1:11走；其他的走默认分支。

```
tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32 match ip src 1.2.3.4 match ip dport 80 0xffff flowid 1:10
tc filter add dev eth0 protocol ip parent 1:0 prio 1 u32 match ip src 1.2.3.4 flowid 1:11
```

#### 控制QoS

##### **OpenvSwitch支持两种：**

**对于进入的流量，可以设置策略Ingress policy；**

```
ovs-vsctl set Interface tap0 ingress_policing_rate=100000
ovs-vsctl set Interface tap0 ingress_policing_burs=10000
```
**对于发出的流量，可以设置QoS规则Egress shaping，支持HTB。**

![img](.\企业微信截图_16366185503849.png)

首先，在port上可以创建QoS规则，一个QoS规则可以有多个队列Queue。

 ![img](.\企业微信截图_1636618601441.png) 

```
ovs-vsctl set port first_br qos=@newqos -- --id=@newqos create qos type=linux-htb other-config:max-rate=10000000 queues=0=@q0,1=@q1,2=@q2 -- --id=@q0 create queue other-config:min-rate=3000000 other-config:max-rate=10000000 -- --id=@q1 create queue other-config:min-rate=1000000 other-config:max-rate=10000000 -- --id=@q2 create queue other-config:min-rate=6000000 other-config:max-rate=10000000
```

上面的命令创建了一个QoS规则，对应三个Queue。min-rate就是上面的rate，max-rate就是上面的ceil。通过交换机的网络包，要通过流表规则，匹配后进入不同的队列。然后我们就可以添加流表规则Flow(**first_br是br0上的port 5**)。

```
ovs-ofctl add-flow br0 "in_port=6 nw_src=192.168.100.100 actions=enqueue:5:0"
ovs-ofctl add-flow br0 "in_port=7 nw_src=192.168.100.101 actions=enqueue:5:1"
ovs-ofctl add-flow br0 "in_port=8 nw_src=192.168.100.102 actions=enqueue:5:2"
```

接下来，我们单独测试从192.168.100.100，192.168.100.101，192.168.100.102到192.168.100.103的带宽的
时候，每个都是能够打满带宽的。

- 如果三个一起测试，一起狂发网络包，会发现是按照3:1:6的比例进行的，正是根据配置的队列的带宽比例分配的。 
- 如果192.168.100.100和192.168.100.101一起测试，发现带宽占用比例为3:1，但是占满了总的流量，也即
  没有发包的192.168.100.102有60%的带宽被借用了。
- 如果192.168.100.100和192.168.100.102一起测试，发现带宽占用比例为1:2。如果192.168.100.101和192.168.100.102一起测试，发现带宽占用比例为1:6。

###  云中网络的隔离GRE、VXLAN

 底层的**物理网络**设备组成的网络我们称为**Underlay网络**，而用于**虚拟机和云中的这些技术组成的网络**称为**Overlay**网络，这是一种基于物理网络的虚拟化网络实现。

#### GRE

第一个技术是GRE，全称**Generic Routing Encapsulation**，它是**一种IP-over-IP的隧道技术**。它将IP包封装在GRE包里，外面加上IP头，在隧道的一端封装数据包，并在通路上进行传输，到另外一端的时候解封装。你可以认为Tunnel 是一个虚拟的、点对点的连接。

![img](.\企业微信截图_1636681769535.png) 

从这个图中可以看到，在GRE头中，前32位是一定会有的，后面的都是可选的。在前4位标识位里面，有个很重要的key字段，是一个32位的字段，里面存放的往往就是用于区分用户的Tunnel ID 。
下面的格式类型专门用于网络虚拟化的GRE包头格式，称为**NVGRE**，也给网络ID号24位，也完全够用了。
除此之外，**GRE还需要有一个地方来封装和解封装GRE的包，这个地方往往是路由器或者有路由功能的Linux机器**。
使用GRE隧道，传输的过程就像下面这张图。这里面有两个网段、两个路由器，中间要通过GRE隧道进行通信。当隧道建立之后，会多出两个Tunnel 端口，用于封包、解封包。

![img](.\企业微信截图_16366819615589.png) 

1. 主机A在左边的网络，IP地址为192.168.1.102，它想要访问主机B，主机B在右边的网络，IP地址为192.168.2.115。于是发送一个包，源地址为192.168.1.102，目标地址为192.168.2.115。因为要跨网 段访问，于是根据默认的default路由表规则，要发给默认的网关192.168.1.1，也即左边的路由器。
2. 根据路由表，从左边的路由器，去192.168.2.0/24这个网段，应该走一条GRE的隧道，从隧道一端的网卡Tunnel0 进入隧道。
3. 在Tunnel 隧道的端点进行包的封装，在内部的IP头之外加上GRE头。对于NVGRE来讲，是在MAC头之外加上GRE头，然后加上外部的IP地址，也即路由器的外网IP地址。源IP地址为172.17.10.10，目标IP地址为172.16.11.10，然后从E1的物理网卡发送到公共网络里。
4. 在公共网络里面，沿着路由器一跳一跳地走，全部都按照外部的公网IP地址进行。
5. 当网络包到达对端路由器的时候，也要到达对端的Tunnel0 ，然后开始解封装，将外层的IP头取下来，然后根据里面的网络包，根据路由表，从E3口转发出去到达服务器B。

##### GRE的不足

- 首先是**Tunnel的数量问题**。GRE是一种点对点隧道，如果有三个网络，就需要在每两个网络之间建立一个隧道。如果网络数目增多，这样隧道的数目会呈指数性增长。

- 其次，**GRE不支持组播**，因此一个网络中的一个虚机发出一个广播帧后，GRE会将其广播到所有与该节点有隧道连接的节点。
- 另外一个问题是目前还是有**很多防火墙和三层网络设备无法解析GRE**，因此它们无法对GRE封装包做合适地过滤和负载均衡。

#### VxLAN

**第二种Overlay的技术称为VXLAN。**和三层外面再套三层的GRE不同，VXLAN则是从二层外面就套了一个VXLAN的头，这里面包含的VXLAN ID为24位，也够用了。在VXLAN头外面还封装了UDP、IP，以及外层的MAC头。

![img](.\企业微信截图_16366828291678.png) 

VXLAN作为扩展性协议，也需要一个地方对VXLAN的包进行封装和解封装，实现这个功能的点称为**VTEP（VXLAN Tunnel Endpoint）**。

**VTEP**相当于虚拟机网络的管家。每台物理机上都可以有一个VTEP。每个虚拟机启动的时候，都需要向这个VTEP管家注册，每个VTEP都知道自己上面注册了多少个虚拟机。当虚拟机要跨VTEP进行通信的时候，需要通过VTEP代理进行，由VTEP进行包的封装和解封装。
和GRE端到端的隧道不同，**VXLAN不是点对点的，而是支持通过组播的来定位目标机器的，**而非一定是这一端发出，另一端接收。

##### VxLAN工作流程

虚拟机1、2、3属于云中同一个用户的虚拟机，因而需要分配相同的VXLAN ID=101。在云的界面上，就可以知道它们的IP地址，于是可以在虚拟机1上ping虚拟机2。

当一个**VTEP启动**的时候，它们都需要通过**IGMP**协议。

 ![img](.\企业微信截图_16366968503062.png) 

虚拟机1发现，它不知道虚拟机2的MAC地址，因而包没办法发出去，于是要发送ARP广播。

![img](.\企业微信截图_16366967681317.png) 

1. ARP请求到达VTEP1的时候，将ARP请求封装在VXLAN里面，组播出去。
2. VTEP2和VTEP3都收到了消息，因而都会解开VXLAN包看，里面是一个ARP。
3. VTEP2在本地广播，收到虚拟机2回的MAC地址。通过这次通信，VTEP2记录了虚拟机1与VTEP1关系。
4. VTEP2将ARP的回复封装在VXLAN里面，直接发回给VTEP1。
5. VTEP1解开ARP回复的VXLAN的包，发给虚拟机1。通过这次通信，VTEP1记录虚拟机2与VTEP2。
6. 虚拟机1发给虚拟机2的包到达VTEP1，于是将包封装在VXLAN里面，外层加上VTEP1和VTEP2的IP地址，发送出去。
7. 网络包到达VTEP2之后，VTEP2解开VXLAN封装，将包转发给虚拟机2。
8. 虚拟机2回复的包，到达VTEP2的时候，将包封装在VXLAN里面，外层加上VTEP1和VTEP2的IP地址，也发送出去。
9. 网络包到达VTEP1之后，VTEP1解开VXLAN封装，将包转发给虚拟机1。

#### 结合openvswitch的隧道拓扑

**OpenvSwitch可以作为Tunnel Endpoint ，通过设置流表的规则，将虚拟机网络和物理机网络进行隔离、转换。**

**OpenvSwitch支持三类隧道：GRE、VXLAN、IPsec_GRE。**在使用OpenvSwitch的时候，虚拟交换机就相当于GRE和VXLAN封装的端点。


我们模拟创建一个如下的**网络拓扑结构**，来看隧道应该如何工作。

![img](.\企业微信截图_16366975424049.png) 

三台物理机，每台上都有两台虚拟机，分别属于两个不同的用户，因而VLAN tag都得打地不一样，这样才不能相互通信。但是不同物理机上的相同用户，是可以通过隧道相互通信的，因而通过GRE隧道可以连接到一起。
接下来，所有的Flow Table 规则都设置在br1上，每个br1都有三个网卡，其中网卡1是对内的，网卡2和3是对外的。
下面我们具体来看**Flow Table 的设计**。

 ![img](.\企业微信截图_16366975915702.png) 

1.Table 0是所有流量的入口，所有进入br1的流量，分为两种流量，一个是进入物理机的流量，一个是从物理机发出的流量。

从port 1进来的，都是发出去的流量，全部由Table 1处理。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1 in_port=1 actions=resubmit(,1)"
```

从port 2、3进来的，都是进入物理机的流量，全部由Table 3处理。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1 in_port=2 actions=resubmit(,3)"
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1 in_port=3 actions=resubmit(,3)"
```

如果都没匹配上，就默认丢弃。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=0 actions=drop"
```

2.Table 1用于处理所有出去的网络包，分为两种情况，一种是单播，一种是多播。

对于单播，由Table 20处理。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1 table=1 dl_dst=00:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,20)"
```

对于多播，由Table 21处理。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1 table=1 dl_dst=01:00:00:00:00:00/01:00:00:00:00:00 actions=resubmit(,21)"
```

3.Table 2是紧接着Table1的，如果既不是单播，也不是多播，就默认丢弃。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=0 table=2 actions=drop"
```

4.Table 3用于处理所有进来的网络包，需要将隧道Tunnel ID转换为VLAN ID。

如果匹配不上Tunnel ID，就默认丢弃。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=0 table=3 actions=drop"
```

如果匹配上了Tunnel ID，就转换为相应的VLAN ID，然后跳到Table 10。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1 table=3 tun_id=0x1 actions=mod_vlan_vid:1,resubmit(,10)"
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1 table=3 tun_id=0x2 actions=mod_vlan_vid:2,resubmit(,10)"
```

5.对于进来的包，Table 10会进行MAC地址学习。这是一个二层交换机应该做的事情，学习完了之后，再从port 1发出去。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1 table=10  actions=learn(table=20,priority=1,hard_timeout=300,NXM_OF_VLAN_TCI[0..11],NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],load:0->NXM_OF_VLAN_TCI[],load:NXM_NX_TUN_ID[]->NXM_NX_TUN_ID[],output:NXM_OF_IN_PORT[]),output:1"
```

Table 10是用来学习MAC地址的，学习的结果放在Table 20里面。Table20被称为MAC learning table。

NXM_OF_VLAN_TCI是VLAN tag。在MAC learning table中，每一个entry都仅仅是针对某一个VLAN来说的，不同VLAN的learning table是分开的。在学习结果的entry中，会标出这个entry是针对哪个VLAN的。

NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[]表示，当前包里面的MAC Source Address会被放在学习结果的entry里的dl_dst里。这是因为每个交换机都是通过进入的网络包来学习的。某个MAC从某个port进来，交换机就应该记住，以后发往这个MAC的包都要从这个port出去，因而源MAC地址就被放在了目标MAC地址里面，因为这是为了发送才这么做的。

load:0->NXM_OF_VLAN_TCI[]是说，在Table20中，将包从物理机发送出去的时候，VLAN tag设为0，所以学习完了之后，Table 20中会有actions=strip_vlan。

load:NXM_NX_TUN_ID[]->NXM_NX_TUN_ID[]的意思是，在Table 20中，将包从物理机发出去的时候，设置Tunnel ID，进来的时候是多少，发送的时候就是多少，所以学习完了之后，Table 20中会有set_tunnel。

output:NXM_OF_IN_PORT[]是发送给哪个port。例如是从port 2进来的，那学习完了之后，Table 20中会有output:2。

![img](.\4dc0fe34819ee02a53a97c89811747dd.jpg)

所以如图所示，通过左边的MAC地址学习规则，学习到的结果就像右边的一样，这个结果会被放在Table 20里面。

6.Table 20是MAC Address Learning Table。如果不为空，就按照规则处理；如果为空，就说明没有进行过MAC地址学习，只好进行广播了，因而要交给Table 21处理。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=0 table=20 actions=resubmit(,21)"
```

7.Table 21用于处理多播的包。

如果匹配不上VLAN ID，就默认丢弃。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=0 table=21 actions=drop"
```

如果匹配上了VLAN ID，就将VLAN ID转换为Tunnel ID，从两个网卡port 2和port 3都发出去，进行多播。

```
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1table=21dl_vlan=1 actions=strip_vlan,set_tunnel:0x1,output:2,output:3"
ovs-ofctl add-flow br1 "hard_timeout=0 idle_timeout=0 priority=1table=21dl_vlan=2 actions=strip_vlan,set_tunnel:0x2,output:2,output:3"
```

### 容器网络

封闭的环境主要使用了两种技术，一种是**看起来是隔离的技术**，称为**namespace**，也即每个namespace中的应用看到的是不同的 IP地址、用户空间、程号等。

另一种是**用起来是隔离的技术**，称为**cgroup**，也即明明整台机器有很多的 CPU、内存，而一个应用只能用其中的一部分。

#### 命名空间（namespace）

网络的namespace由ip netns命令操作。它可以创建、删除、查询namespace。

在图里画的这条虚线，这个就是通过namespace实现的。

![img](.\1a5d299c2eb5480eda93a8f8e3b3ca1a.jpg)

我们创建一个routerns，于是一个独立的网络空间就产生了。你可以在里面尽情设置自己的规则。

```
ip netns add routerns
```

既然是路由器，肯定要能转发嘛，因而forward开关要打开。

```
ip netns exec routerns sysctl -w net.ipv4.ip_forward=1
```

exec的意思就是进入这个网络空间做点事情。初始化一下iptables，因为这里面要配置NAT规则。

```
ip netns exec routerns iptables-save -c 
ip netns exec routerns iptables-restore -c
```

路由器需要有一张网卡连到br0上，因而要创建一个网卡。

```
ovs-vsctl -- add-port br0 taprouter -- set Interface taprouter type=internal -- set Interface taprouter external-ids:iface-status=active -- set Interface taprouter external-ids:attached-mac=fa:16:3e:84:6e:cc
```

这个网络创建完了，但是是在namespace外面的，如何进去呢？可以通过这个命令：

```
ip link set taprouter netns routerns
```

要给这个网卡配置一个IP地址，当然应该是虚拟机网络的网关地址。例如虚拟机私网网段为192.168.1.0/24，网关的地址往往为192.168.1.1。

```
ip netns exec routerns ip -4 addr add 192.168.1.1/24 brd 192.168.1.255 scope global dev taprouter
```

为了访问外网，还需要另一个网卡连在外网网桥br-ex上，并且塞在namespace里面。

```
ovs-vsctl -- add-port br-ex taprouterex -- set Interface taprouterex type=internal -- set Interface taprouterex external-ids:iface-status=active -- set Interface taprouterex external-ids:attached-mac=fa:16:3e:68:12:c0
ip link set taprouterex netns routerns
```

我们还需要为这个网卡分配一个地址，这个地址应该和物理外网网络在一个网段。假设物理外网为16.158.1.0/24，可以分配一个外网地址16.158.1.100/24。

```
ip netns exec routerns ip -4 addr add 16.158.1.100/24 brd 16.158.1.255 scope global dev taprouterex
```

接下来，既然是路由器，就需要配置路由表，路由表是这样的：

```
ip netns exec routerns route -n
Kernel IP routing table
Destination   Gateway     Genmask     Flags Metric Ref  Use Iface
0.0.0.0     16.158.1.1  0.0.0.0     UG  0   0    0 taprouterex
192.168.1.0    0.0.0.0     255.255.255.0  U   0   0    0 taprouter
16.158.1.0  0.0.0.0     255.255.255.0  U   0   0    0 taprouterex
```

路由表中的默认路由是去物理外网的，去192.168.1.0/24也即虚拟机私网，走下面的网卡，去16.158.1.0/24也即物理外网，走上面的网卡。

我们在前面的章节讲过，如果要在虚拟机里面提供服务，提供给外网的客户端访问，客户端需要访问外网IP3，会在外网网口NAT称为虚拟机私网IP。这个NAT规则要在这个namespace里面配置。

```
ip netns exec routerns iptables -t nat -nvL
Chain PREROUTING
target  prot opt  in  out  source  destination
DNAT  all  --  *  *  0.0.0.0/0 16.158.1.103 to:192.168.1.3
Chain POSTROUTING
target  prot opt  in  out  source   destination
SNAT  all  --  *  *  192.168.1.3  0.0.0.0/0 to:16.158.1.103
```

这里面有两个规则，一个是SNAT，将虚拟机的私网IP 192.168.1.3 NAT成物理外网IP 16.158.1.103。一个是DNAT，将物理外网IP 16.158.1.103 NAT成虚拟机私网IP 192.168.1.3。

至此为止，基于网络namespace的路由器实现完毕。

#### 机制网络（cgroup）

我们再来看打包的另一个机制网络cgroup。

**cgroup全称control groups**，是Linux内核提供的一种可以限制、隔离进程使用的资源机制。

cgroup能控制哪些资源呢？它有很多子系统：

- CPU子系统使用调度程序为进程控制CPU的访问；
- cpuset，如果是多核心的CPU，这个子系统会为进程分配单独的CPU和内存；
- memory子系统，设置进程的内存限制以及产生内存资源报告；
- blkio子系统，设置限制每个块设备的输入输出控制；
- net_cls，这个子系统使用等级识别符（classid）标记网络数据包，可允许Linux 流量控制程序（tc）识别从具体cgroup中生成的数据包。



#### 容器网络融入物理网络

如果你使用docker run运行一个容器，你应该能看到这样一个拓扑结构。

![img](.\20e87bc215b9d049a4a504d775d26dd2.jpg)

如果你用brctl查看docker0网桥，你会发现它上面连着一些网卡。

在虚拟机场景下，有一个虚拟化软件，通过TUN/TAP设备虚拟一个网卡给虚拟机，但是容器场景下并没有虚拟化软件，在Linux下**，可以创建一对veth pair的网卡**，从一边发送包，另一边就能收到。

我们首先通过这个命令创建这么一对。

```
ip link add name veth1 mtu 1500 type veth peer name veth2 mtu 1500
```

其中一边可以打到docker0网桥上。

```
ip link set veth1 master testbr    
ip link set veth1 up
```

那另一端如何放到容器里呢？

一个容器的启动会对应一个namespace，我们要先找到这个namespace。对于docker来讲，pid就是namespace的名字，可以通过这个命令获取。

```
docker inspect '--format={{ .State.Pid }}' test
```

假设结果为12065，这个就是namespace名字。

默认Docker创建的网络namespace不在默认路径下 ，ip netns看不到，所以需要ln软链接一下。链接完毕以后，我们就可以通过ip netns命令操作了。

```
rm -f /var/run/netns/12065    
ln -s /proc/12065/ns/net /var/run/netns/12065
```

然后，我们就可以将另一端veth2塞到namespace里面。

```
ip link set veth2 netns 12065
```

然后，将容器内的网卡重命名。

```
ip netns exec 12065 ip link set veth2 name eth0
```

然后，给容器内网卡设置ip地址。

```
ip netns exec 12065 ip addr add 172.17.0.2/24 dev eth0    
ip netns exec 12065 ip link set eth0 up
```

一台机器内部容器的互相访问没有问题了，那如何访问外网呢？

就是虚拟机里面的桥接模式和NAT模式。Docker默认使用NAT模式。NAT模式分为SNAT和DNAT，如果是容器内部访问外部，就需要通过SNAT。

从容器内部的客户端访问外部网络中的服务器。

![img](.\5452971c96e8fea33c3f873860e25c93.jpg)

在宿主机上，有这么一条iptables规则：

```
-A POSTROUTING -s 172.17.0.0/16 ! -o docker0 -j MASQUERADE
```

所有从容器内部发出来的包，都要做地址伪装，将源IP地址，转换为物理网卡的IP地址。如果有多个容器，所有的容器共享一个外网的IP地址，但是在conntrack表中，记录下这个出去的连接。

当服务器返回结果的时候，到达物理机，会根据conntrack表中的规则，取出原来的私网IP，通过DNAT将地址转换为私网IP地址，通过网桥docker0实现对内的访问。

如果在容器内部属于一个服务，例如部署一个网站，提供给外部进行访问，需要通过Docker的端口映射技术，将容器内部的端口映射到物理机上来。

例如容器内部监听80端口，可以通Docker run命令中的参数-p 10080:80，将物理机上的10080端口和容器的80端口映射起来， 当外部的客户端访问这个网站的时候，通过访问物理机的10080端口，就能访问到容器内的80端口了。

![img](.\49bb6b2a30fe76b124182980da935ebb.jpg)

Docker有两种方式，一种是通过一个进程**docker-proxy**的方式，监听10080，转换为80端口。

```
/usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 10080 -container-ip 172.17.0.2 -container-port 80
```

另外一种方式是通过**DNAT**方式，在-A PREROUTING阶段加一个规则，将到端口10080的DNAT称为容器的私有网络。

```
-A DOCKER -p tcp -m tcp --dport 10080 -j DNAT --to-destination 172.17.0.2:80
```

如此就可以实现容器和物理网络之间的互通了。



### 容器网络之flannel

Flannel有一个非常好的模式，就是给不同的物理机设置不同网段，这一点和虚拟机的Overlay的模式完全不一样。

#### flannel使用UDP实现overlay

**这里我要说Flannel使用UDP实现Overlay网络的方案，因为不想在flanneld之间建立两两连接，而UDP没有连接的概念，任何一台机器都能发给另一台。**

![img](.\01ee306698c7dd6207e80fea0a8238c8.jpg)

1. 在物理机A上的容器A里面，能看到的容器的IP地址是172.17.8.2/24，里面设置了默认的路由规则default via 172.17.8.1 dev eth0。

2. 如果容器A要访问172.17.9.2，就会发往这个默认的网关172.17.8.1。172.17.8.1就是物理机上面docker0网桥的IP地址，这台物理机上的所有容器都是连接到这个网桥的。

3. 在物理机上面，查看路由策略，会有这样一条172.17.0.0/24 via 172.17.0.0 dev flannel.1，也就是说发往172.17.9.2的网络包会被转发到flannel.1这个网卡。

4. 在每台物理机上，都会跑一个flanneld进程，这个进程打开一个/dev/net/tun字符设备的时候，就出现了这个网卡。所有发到flannel.1这个网卡的包都会被flanneld进程读进去，接下来flanneld要对网络包进行处理。

5. 物理机A上的flanneld会将网络包封装在UDP包里面，然后外层加上物理机A和物理机B的IP地址，发送给物理机B上的flanneld。

6. 物理机B上的flanneld收到包之后，解开UDP的包，将里面的网络包拿出来，从物理机B的flannel.1网卡发出去。

7. 在物理机B上，有路由规则172.17.9.0/24 dev docker0 proto kernel scope link src 172.17.9.1。

8. 将包发给docker0，docker0将包转给容器B。通信成功。

上面的过程连通性没有问题，但是由于全部在用户态，所以性能差了一些。

跨物理机的连通性问题，在虚拟机那里有成熟的方案，就是VXLAN，那**能不能Flannel也用VXLAN呢**？

#### flannel用VxLAN

如果使用VXLAN，要建立一个VXLAN的**VTEP**。可以通过**netlink**通知内核建立一个VTEP的网卡flannel.1。在我们讲OpenvSwitch的时候提过，**netlink是一种用户态和内核态通信的机制**。
当网络包从物理机A上的容器A发送给物理机B上的容器B，在容器A里面通过默认路由到达物理机A上的docker0网卡，然后根据路由规则，在物理机A上，将包转发给flannel.1。这个时候flannel.1就是一个VXLAN的VTEP了，它将网络包进行封装。
内部的MAC地址这样写：源为物理机A的flannel.1的MAC地址，目标为物理机B的flannel.1的MAC地址，在外面加上VXLAN的头。
外层的IP地址这样写：源为物理机A的IP地址，目标为物理机B的IP地址，外面加上物理机的MAC地址。
这样就能通过VXLAN将包转发到另一台机器，从物理机B的flannel.1上解包，变成内部的网络包，通过物理机B上的路由转发到docker0，然后转发到容器B里面。通信成功。
![img](.\a568cb08c615b351e871bd981541a201.jpg)

### 容器网络之Calico

**Calico网络的大概思路**，**即不走Overlay网络，不引入另外的网络性能损耗，而是将转发全部用三层网络的路由转发来实现**

#### Calico网络的转发细节

![img](.\e59559ad7b46b9811553b6b0a85e8e7d.jpg)

容器A1的IP地址为172.17.8.2/32，这里注意，不是/24，而是/32，将容器A1作为一个单点的局域网了。

容器A1里面的默认路由，Calico配置得比较有技巧。

```
default via 169.254.1.1 dev eth0 
169.254.1.1 dev eth0 scope link 
```

这个IP地址**169.254.1.1是默认的网关**，但是整个拓扑图中没有一张网卡是这个地址。那如何到达这个地址呢？

前面我们讲网关的原理的时候说过，当一台机器要访问网关的时候，首先会通过ARP获得网关的MAC地址，然后将目标MAC变为网关的MAC，而**网关的IP地址不会在任何网络包头里面出现**，也就是说，没有人在乎这个地址具体是什么，只要能找到对应的MAC，响应ARP就可以了。

ARP本地有缓存，通过ip neigh命令可以查看。

```
169.254.1.1 dev eth0 lladdr ee:ee:ee:ee:ee:ee STALE
```

这个MAC地址是Calico硬塞进去的，但是没有关系，它能响应ARP，于是发出的包的目标MAC就是这个MAC地址。

在物理机A上查看所有网卡的MAC地址的时候，我们会发现veth1就是这个MAC地址。所以容器A1里发出的网络包，第一跳就是这个veth1这个网卡，也就到达了物理机A这个路由器。

在物理机A上有三条路由规则，分别是去两个本机的容器的路由，以及去172.17.9.0/24，下一跳为物理机B。

```
172.17.8.2 dev veth1 scope link 
172.17.8.3 dev veth2 scope link 
172.17.9.0/24 via 192.168.100.101 dev eth0 proto bird onlink
```

同理，物理机B上也有三条路由规则，分别是去两个本机的容器的路由，以及去172.17.8.0/24，下一跳为物理机A。

```
172.17.9.2 dev veth1 scope link 
172.17.9.3 dev veth2 scope link 
172.17.8.0/24 via 192.168.100.100 dev eth0 proto bird onlink
```

在这里，物理机化身为路由器，通过路由器上的路由规则，将包转发到目的地。在这个过程中，没有隧道封装解封装，仅仅是单纯的路由转发，性能会好很多。但是，这种模式也有很多问题。

#### Calico的架构

##### 路由配置组件Felix

如果只有两台机器，每台机器只有两个容器，而且保持不变。我手动配置一下，倒也没啥问题。但是如果容器不断地创建、删除，节点不断地加入、退出，情况就会变得非常复杂。

![img](.\f29027cca71f3dfbba8c2f1a35c29331.jpg)

就像图中，有三台物理机，两两之间都需要配置路由，每台物理机上对外的路由就有两条。如果有六台物理机，则每台物理机上对外的路由就有五条。新加入一个节点，需要通知每一台物理机添加一条路由。

这还是在物理机之间，一台物理机上，每创建一个容器，也需要多配置一条指向这个容器的路由。如此复杂，肯定不能手动配置，**需要每台物理机上有一个agent，当创建和删除容器的时候，自动做这件事情。这个agent在Calico中称为Felix。**

##### 路由广播组件BGP Speaker

当Felix配置了路由之后，接下来的问题就是，如何将路由信息，也即将“如何到达我这个节点，访问我这个节点上的容器”这些信息，广播出去。

路由协议就是将“我能到哪里，如何能到我”的信息广播给全网传出去，从而客户端可以一跳一跳地访问目标地址的。路由协议有很多种，**Calico使用的是BGP协议**。

**在Calico中，每个Node上运行一个软件BIRD，作为BGP的客户端，或者叫作BGP Speaker，将“如何到达我这个Node，访问我这个Node上的容器”的路由信息广播出去。**所有Node上的BGP Speaker 都互相建立连接，就形成了全互连的情况，这样每当路由有所变化的时候，所有节点就都能够收到了。

##### 安全策略组件（Network Policy）

**Calico中还实现了灵活配置网络策略Network Policy，可以灵活配置两个容器通或者不通。**

![img](.\1a0ba797b9a0f0e32c9e561b97955917.jpg)

虚拟机中的安全组，是用iptables实现的。Calico中也是用iptables实现的。这个图里的内容是iptables在内核处理网络包的过程中可以嵌入的处理点。Calico也是在这些点上设置相应的规则。

![img](.\d27a1bf22f9b70696ca13abb6a655d15.jpg)

当网络包进入物理机上的时候，进入PREOUTING规则，这里面有一个规则是cali-fip-dnat，这是实现浮动IP（Floating IP）的场景，主要将外网的IP地址dnat为容器内的IP地址。在虚拟机场景下，路由器的网络namespace里面有一个外网网卡上，也设置过这样一个DNAT规则。

接下来可以根据路由判断，是到本地的，还是要转发出去的。

如果是本地的，走INPUT规则，里面有个规则是cali-wl-to-host，wl的意思是workload，也即容器，也即这是用来判断从容器发到物理机的网络包是否符合规则的。这里面内嵌一个规则cali-from-wl-dispatch，也是匹配从容器来的包。如果有两个容器，则会有两个容器网卡，这里面内嵌有详细的规则“cali-fw-cali网卡1”和“cali-fw-cali网卡2”，fw就是from workload，也就是匹配从容器1来的网络包和从容器2来的网络包。

如果是转发出去的，走FORWARD规则，里面有个规则cali-FORWARD。这里面分两种情况，一种是从容器里面发出来，转发到外面的；另一种是从外面发进来，转发到容器里面的。

第一种情况匹配的规则仍然是cali-from-wl-dispatch，也即from workload。第二种情况匹配的规则是cali-to-wl-dispatch，也即to workload。如果有两个容器，则会有两个容器网卡，在这里面内嵌有详细的规则“cali-tw-cali网卡1”和“cali-tw-cali网卡2”，tw就是to workload，也就是匹配发往容器1的网络包和发送到容器2的网络包。

接下来是匹配OUTPUT规则，里面有cali-OUTPUT。接下来是POSTROUTING规则，里面有一个规则是cali-fip-snat，也即发出去的时候，将容器网络IP转换为浮动IP地址。在虚拟机场景下，路由器的网络namespace里面有一个外网网卡上，也设置过这样一个SNAT规则。

至此为止，Calico的所有组件基本凑齐。来看看我汇总的图。

![img](.\df8d92d84af55369055738283339d6b2.jpg)



##### 全连接复杂性与规模问题（BGP Route Reflector）

这里面还存在问题，就是BGP全连接的复杂性问题。

你看刚才的例子里只有六个节点，BGP的互连已经如此复杂，如果节点数据再多，这种全互连的模式肯定不行，到时候都成蜘蛛网了。于是多出了一个**组件BGP Route Reflector**，它也是用BIRD实现的。有了它，BGP Speaker就不用全互连了，而是都直连它，它负责将全网的路由信息广播出去。

可是问题来了，规模大了，大家都连它，它受得了吗？这个BGP Router Reflector会不会成为瓶颈呢？

所以，肯定不能让一个BGP Router Reflector管理所有的路由分发，而是应该**有多个BGP Router Reflector，每个BGP Router Reflector管一部分**。

BGP Router Reflector有点儿像数据中心的边界路由器。**服务器和BGP Router Reflector之间使用的是数据中心内部的路由协议iBGP，BGP Router Reflector之间使用的是数据中心之间的路由协议eBGP。**

![img](.\f7e9467901ccb4b7e8039c53314244ff.jpg)

这个图中，一个机架上有多台机器，每台机器上面启动多个容器，每台机器上都有可以到达这些容器的路由。每台机器上都启动一个BGP Speaker，然后将这些路由规则上报到这个Rack上接入交换机的BGP Route Reflector，将这些路由通过iBGP协议告知到接入交换机的三层路由功能。

在接入交换机之间也建立BGP连接，相互告知路由，因而一个Rack里面的路由可以告知另一个Rack。有多个核心或者汇聚交换机将接入交换机连接起来，如果核心和汇聚起二层互通的作用，则接入和接入之间之间交换路由即可。如果核心和汇聚交换机起三层路由的作用，则路由需要通过核心或者汇聚交换机进行告知。

##### 跨网段访问问题（IPIP模式）

上面的Calico模式还有一个问题，就是跨网段问题，这里的跨网段是指物理机跨网段。

前面我们说的那些逻辑成立的条件，是我们假设物理机可以作为路由器进行使用。例如物理机A要告诉物理机B，你要访问172.17.8.0/24，下一跳是我192.168.100.100；同理，物理机B要告诉物理机A，你要访问172.17.9.0/24，下一跳是我192.168.100.101。

之所以能够这样，是因为物理机A和物理机B是同一个网段的，是连接在同一个交换机上的。那如果物理机A和物理机B不是在同一个网段呢？

![img](.\88a1817b32c3c364fbbdf50b05d49e84.jpg)

例如，物理机A的网段是192.168.100.100/24，物理机B的网段是192.168.200.101/24，这样两台机器就不能通过二层交换机连接起来了，需要在中间放一台路由器，做一次路由转发，才能跨网段访问。

本来物理机A要告诉物理机B，你要访问172.17.8.0/24，下一跳是我192.168.100.100的，但是中间多了一台路由器，下一跳不是我了，而是中间的这台路由器了，这台路由器的再下一跳，才是我。这样之前的逻辑就不成立了。

我们看刚才那张图的下半部分。物理机B上的容器要访问物理机A上的容器，第一跳就是物理机B，IP为192.168.200.101，第二跳是中间的物理路由器右面的网口，IP为192.168.200.1，第三跳才是物理机A，IP为192.168.100.100。

这是咱们通过拓扑图看到的，关键问题是，在系统中物理机A如何告诉物理机B，怎么让它才能到我这里？物理机A根本不可能知道从物理机B出来之后的下一跳是谁，况且现在只是中间隔着一个路由器这种简单的情况，如果隔着多个路由器呢？谁能把这一串的路径告诉物理机B呢？

我们能想到的第一种方式是，让中间所有的路由器都来适配Calico。本来它们互相告知路由，只互相告知物理机的，现在还要告知容器的网段。这在大部分情况下，是不可能的。

第二种方式，还是在物理机A和物理机B之间打一个隧道，这个隧道有两个端点，在端点上进行封装，将容器的IP作为乘客协议放在隧道里面，而物理主机的IP放在外面作为承载协议。这样不管外层的IP通过传统的物理网络，走多少跳到达目标物理机，从隧道两端看起来，物理机A的下一跳就是物理机B，这样前面的逻辑才能成立。

这就是**Calico的IPIP模式**。使用了IPIP模式之后，在物理机A上，我们能看到这样的路由表：

```
172.17.8.2 dev veth1 scope link 
172.17.8.3 dev veth2 scope link 
172.17.9.0/24 via 192.168.200.101 dev tun0 proto bird onlink
```

这和原来模式的区别在于，下一跳不再是同一个网段的物理机B了，IP为192.168.200.101，并且不是从eth0跳，而是建立一个隧道的端点tun0，从这里才是下一跳。

如果我们在容器A1里面的172.17.8.2，去ping容器B1里面的172.17.9.2，首先会到物理机A。在物理机A上根据上面的规则，会转发给tun0，并在这里对包做封装：

- 内层源IP为172.17.8.2；
- 内层目标IP为172.17.9.2；
- 外层源IP为192.168.100.100；
- 外层目标IP为192.168.200.101。

将这个包从eth0发出去，在物理网络上会使用外层的IP进行路由，最终到达物理机B。在物理机B上，tun0会解封装，将内层的源IP和目标IP拿出来，转发给相应的容器。



























