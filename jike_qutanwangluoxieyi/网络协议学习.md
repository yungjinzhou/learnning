## 网络协议学习



### 学习网络协议的必要性



#### 协议三要素：

语法、语义、顺序

#### 经常见到的网络协议

![1634653296698](.\1634653296698.png)



#### 浏览器从发送请求到目标地址的过程

1. 输入网址后，本机首先首先DNS(HTTPDNS)查到ip地址；

2. 然后HTTP(s)协议加要发送的内容，到传输层；
3. socket(TCP/UDP)传输层，传输层封装完毕后交给网络层(IP协议)；
4. 在IP协议里会有源IP地址和目标IP地址，然后发送到网关（系统启动时，DHCP协议配置IP地址和默认网关）；
5. 通过ARP协议，找到MAC地址，到了数据链路层；
6. 网关往往是一个路由器，路由器里记录的有路由表，通过路由协议找到对应的远端地址；
7.  然后是ARP协议，找到MAC地址，找到服务器，然后给TCP层，到应用层，访问相应的内容。

### 协议分层的含义



当然网络包的格式很复杂，这个程序也很复杂。复杂的程序都要分层，这是程序设计的要求。

 ![img](.\5c00f6e610f533d17fb4ad7decacc776.jpg) 



### ifconfig包含的信息及协议



#### 无类型域间选路（CIDR）

于是有了一个折中的方式叫作无类型域间选路，简称 CIDR。这种方式打破了原来设计的几类地址的做法，将 32 位的 IP 地址一分为二，前面是网络号，后面是主机号。从哪里分呢？你如果注意观察的话可以看到，10.100.122.2/24，这个 IP 地址中有一个斜杠，斜杠后面有个数字 24。这种地址表示形式，就是 CIDR。后面 24 的意思是，32 位中，前 24 位是网络号，后 8 位是主机号。

伴随着 CIDR 存在的，一个是广播地址，10.100.122.255。如果发送这个地址，所有 10.100.122 网络里面的机器都可以收到。另一个是子网掩码，255.255.255.0。

将子网掩码和 IP 地址进行 AND 计算。前面三个 255，转成二进制都是 1。1 和任何数值取 AND，都是原来数值，因而前三个数不变，为 10.100.122。后面一个 0，转换成二进制是 0，0 和任何数值取 AND，都是 0，因而最后一个数变为 0，合起来就是 10.100.122.0。这就是网络号。将子网掩码和 IP 地址按位计算 AND，就可得到网络号。



 **解析16.158.165.91/22 这个 CIDR**

/22 不是 8 的整数倍，不好办，只能先变成二进制来看。16.158 的部分不会动，它占了前 16 位。中间的 165，变为二进制为‭10100101‬。除了前面的 16 位，还剩 6 位。所以，这 8 位中前 6 位是网络号，16.158.<101001>，而 <01>.91 是机器号。

第一个地址是 16.158.<101001><00>.1，即 16.158.164.1。子网掩码是 255.255.<111111><00>.0，即 255.255.252.0。广播地址为 16.158.<101001><11>.255，即 16.158.167.255。

#### 公有IP地址和私有IP地址

 ![img](.\df90239efec6e35880b9abe55089ffa9.jpg) 

#### lo

lo 全称是 loopback，又称环回接口，往往会被分配到 127.0.0.1 这个地址。这个地址用于本机通信，经过内核处理后直接返回，不会在任何网络中出现。

#### MAC

MAC 地址在 IP 地址的上一行是 link/ether fa:16:3e:c7:79:75 brd ff:ff:ff:ff:ff:ff，这个被称为 MAC 地址，是一个网卡的物理地址，用十六进制，6 个 byte 表示。

MAC 地址更像是身份证，是一个唯一的标识。

#### 网络设备的状态标识

解析完了 MAC 地址，我们再来看 <BROADCAST,MULTICAST,UP,LOWER_UP> 是干什么的？这个叫做 net_device flags，网络设备的状态标识。

UP 表示网卡处于启动的状态；BROADCAST 表示这个网卡有广播地址，可以发送广播包；MULTICAST 表示网卡可以发送多播包；LOWER_UP 表示 L1 是启动的，也即网线插着呢。

MTU1500 是指最大传输单元 MTU 为 1500，这是以太网的默认值。

MTU 是二层 MAC 层的概念。MAC 层有 MAC 的头，以太网规定正文部分不允许超过 1500 个字节。正文里面有 IP 的头、TCP 的头、HTTP 的头。如果放不下，就需要分片来传输。

#### 分片传输/排队规则

qdisc pfifo_fast 是什么意思呢？**qdisc** 全称是 **queueing discipline**，中文叫排队规则。内核如果需要通过某个网络接口发送数据包，它都需要按照为这个接口配置的 qdisc（排队规则）把数据包加入队列。

1. 最简单的 qdisc 是 **pfifo**，它不对进入的数据包做任何的处理，数据包采用先入先出的方式通过队列。

2. **pfifo_fast** 稍微复杂一些，它的队列包括三个波段（band）。在每个波段里面，使用先进先出规则。

   三个波段（**band**）的优先级也不相同。band 0 的优先级最高，band 2 的最低。如果 band 0 里面有数据包，系统就不会处理 band 1 里面的数据包，band 1 和 band 2 之间也是一样。

数据包是按照服务类型（Type of Service，**TOS**）被分配到三个波段（band）里面的。TOS 是 IP 头里面的一个字段，代表了当前的包是高优先级的，还是低优先级的。



### DHCP和PXE

#### 手动配置IP地址

```
# 使用net-tools
$ sudo ifconfig eth1 10.0.0.1/24
$ sudo ifconfig eth1 up


# iproute2
$ sudo ip addr add 10.0.0.1/24 dev eth1
$ sudo ip link set up eth1
```



**Linux默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。**



你看着它有自己的源IP地址16.158.23.6，也有目标IP地址192.168.1.6，但是包发不出去，这是因为MAC层还没填。

自己的MAC地址自己知道，这个容易。

Linux首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗？只有是一个网段的，它才会发送ARP请求，获取MAC地址。

 **不同系统的配置文件格式不同，但是无非就是CIDR、子网掩码、广播地址和网关地址**。 





#### 动态主机配置协议（DHCP）

 **动态主机配置协议（Dynamic Host Configuration Protocol）**，简称**DHCP**。 

 功能：他只需要配置一段共享的IP地址。每一台新接入的机器都通过DHCP协议，来这个共享的IP地址里申请，然后自动配置好就可以了。等人走了，或者用完了，还回去，这样其他的机器也能用。 



#### DHCP的工作方式

当一台机器新加入一个网络的时候，会使用IP地址0.0.0.0发送了一个广播包，目的IP地址为255.255.255.255。广播包封装了UDP，UDP封装了BOOTP。其实DHCP是BOOTP的增强版

这一步，我们称为**DHCP Discover。**

在这个广播包里面，新人大声喊：我是新来的（Boot request），我的MAC地址是这个，我还没有IP，谁能给租给我个IP地址！

格式就像这样：

 ![img](.\企业微信截图_16348035476530.png) 

如果一个网络管理员在网络里面配置了**DHCP Server**的话，他就相当于这些IP的管理员。当一台机器带着自己的MAC地址加入一个网络的时候，MAC是它唯一的身份，如果连这个都重复了，就没办法配置了。

只有MAC唯一，IP管理员才能知道这是一个新人，需要租给它一个IP地址，这个过程我们称为**DHCP Offer**。同时，DHCP Server为此客户保留为它提供的IP地址，从而不会为其他DHCP客户分配此IP地址。

DHCP Offer的格式就像这样，里面有给新人分配的地址。

 ![img](.\企业微信截图_16348037502738.png) 





DHCP Server仍然使用广播地址作为目的地址，因为，此时请求分配IP的新人还没有自己的IP。DHCP Server回复一个可用的IP。除此之外，服务器还发送了子网掩码、网关和IP地址租用期等信息。

如果有多个DHCP Server，这台新机器会收到多个IP地址，它会选择其中一个DHCP Offer，一般是最先到达的那个，并且会向网络发送一个DHCP Request广播数据包，包中包含客户端的MAC地址、接受的租约中的IP地址、提供此租约的DHCP服务器地址等，并告诉所有DHCP Server它将接受哪一台服务器提供的IP地址，告诉其他DHCP服务器，谢谢你们的接纳，并请求撤销它们提供的IP地址，以便提供给下一个IP租用请求者。

 ![img](.\企业微信截图_16348041347848.png) 



此时，由于还没有得到DHCP Server的最后确认，客户端仍然使用0.0.0.0为源IP地址、255.255.255.255为目标地址进行广播。在BOOTP里面，接受某个DHCP Server的分配的IP。

当DHCP Server接收到客户机的DHCP request之后，会广播返回给客户机一个DHCP ACK消息包，表明已经接受客户机的选择，并将这一IP地址的合法租用信息和其他的配置信息都放入该广播包，发给客户机，欢迎它加入网络大家庭。

 ![img](.\企业微信截图_16348042145242.png) 

最终租约达成的时候，还是需要广播一下，让大家都知道。



#### IP地址的收回和续租

客户机会在租期过去50%的时候，直接向为其提供IP地址的DHCP Server发送DHCP request消息包。户机接收到该服务器回应的DHCP ACK消息包，会根据包中所提供的新的租期以及其他已经更新的TCP/IP参数，更新自己的配置。这样，IP租用更新就完成了。



#### 预启动执行环境（PXE）

首先，启动BIOS。这是一个特别小的小系统，只能干特别小的一件事情。其实就是读取硬盘的MBR启动扇区，将GRUB启动起来；然后将权力交给GRUB，GRUB加载内核、加载作为根文件系统的initramfs文件；然后将权力交给内核；最后内核启动，初始化整个操作系统。

那我们安装操作系统的过程，只能插在BIOS启动之后了。因为没安装系统之前，连启动扇区都没有。因而这个过程叫做预启动执行环境（Pre-boot Execution Environment），简称PXE。

PXE协议分为客户端和服务器端，由于还没有操作系统，只能先把客户端放在BIOS里面。当计算机启动时，BIOS把PXE客户端调入内存里面，就可以连接到服务端做一些操作了。
首先，PXE客户端自己也需要有个IP地址。因为PXE的客户端启动起来，就可以发送一个DHCP的请求，让DHCP Server给它分配一个地址。PXE客户端有了自己的地址，那它怎么知道PXE服务器在哪里呢？

按照上面的原理，默认的DHCP Server是需要配置的，无非是我们配置IP的时候所需要的IP地址段、子网掩码、网关地址、租期等。如果想使用PXE，则需要配置next-server，指向PXE服务器的地址，另外要配置初始启动文件flename。
这样PXE客户端启动之后，发送DHCP请求之后，除了能得到一个IP地址，还可以知道PXE服务器在哪里，也可以知道如何从PXE服务器上下载某个文件，去初始化操作系统。

#### 解析PXE的工作过程

首先，启动PXE客户端。第一步是通过DHCP协议告诉DHCP Server租给它一个IP地址，同时也给它PXE服务器的地址、启动文件pxelinux.0。

其次，PXE客户端知道要去PXE服务器下载这个文件后，就可以初始化机器。于是便开始下载，下载的时候使用的是TFTP协议。所以PXE服务器上，往往还需要有一个TFTP服务器。PXE客户端向TFTP服务器请求下载这个文件。
然后，PXE客户端收到这个文件后，就开始执行这个文件。这个文件会指示PXE客户端，向TFTP服务器请求计算机的配置信息pxelinux.cfg。TFTP服务器会给PXE客户端一个配置文件，里面会说内核在哪
里、initramfs在哪里。PXE客户端会请求这些文件。
最后，启动Linux内核。一旦启动了操作系统，以后就啥都好办了。

![img](.\企业微信截图_16348050913205.png) 





### 从物理层到mac层

#### 物理层

有一个叫作Hub的东西，也就是集线器。这种设备有多个口，可以将宿舍里的多台电脑连接起来。但是，和交换机不同，它完全在物理层工作。它会将自己收到的每一个字节，都复制到其他端口上去。

#### 数据链路层

MAC层是用来解决多路访问的堵车问题的；

MAC的全称是Medium AccessControl，即媒体访问控制。其实就是控制在往媒体上发数据的时候，谁先发、谁后发的问题。防止发生混乱。

这种过程学名叫**多路访问**。

多路访问有三种方式：

方式一：分多个车道。每个车一个车道，你走你的，我走我的。这在计算机网络里叫作**信道划分**；
方式二：今天单号出行，明天双号出行，轮着来。这在计算机网络里叫作**轮流协议**；
方式三：不管三七二十一，有事儿先出门，发现特堵，就回去。错过高峰再出。我们叫作**随机接入协议**。著名的以太网，用的就是这个方式。

接下来要解决第一个问题：发给谁，谁接收？这里用到一个物理地址，叫作链路层地址。但是因为第二层主要解决媒体接入控制的问题，所以它常被称为MAC地址。
解决第一个问题就牵扯到第二层的网络包格式。对于以太网，第二层的最开始，就是目标的MAC地址和源的MAC地址。

![img](.\企业微信截图_16348061212322.png) 

接下来是类型，大部分的类型是IP数据包，然后IP里面包含TCP、UDP，以及HTTP等，这都是里层封装的事情。
有了这个目标MAC地址，数据包在链路上广播，MAC的网卡才能发现，这个包是给它的。MAC的网卡把包收进来，然后打开IP包，发现IP地址也是自己的，再打开TCP包，发现端口是自己，也就是80，而nginx就是监听80。

于是将请求提交给nginx，nginx返回一个网页。然后将网页需要发回请求的机器。然后层层封装，最后到MAC层。因为来的时候有源MAC地址，返回的时候，源MAC就变成了目标MAC，再返给请求的机器。

对于以太网，第二层的最后面是**CRC**，也就是**循环冗余检测**。通过XOR异或的算法，来计算整个包是否在发送的过程中出现了错误，主要解决第三个问题。

#### ARP协议

这里还有一个没有解决的问题，当源机器知道目标机器的时候，可以将目标地址放入包里面，如果不知道呢？一个广播的网络里面接入了N台机器，我怎么知道每个MAC地址是谁呢？这就是**ARP**协议，也就是**已知IP地址，求MAC地址的协议**。

发送一个广播包，谁是这个IP谁来回答。具体询问和回答的报文就像下面这样：

![img](.\企业微信截图_16348065269645.png) 

为了避免每次都用ARP请求，机器本地也会进行ARP缓存。当然机器会不断地上线下线，IP也可能会变，所以ARP的MAC地址缓存过一段时间就会过期。



#### 局域网



这就需要一个能把MAC头拿下来，检查一下目标MAC地址，然后根据策略转发的设备，按第二节课中讲过的，这个设备显然是个二层设备，我们称为**交换机**。

交换机是有MAC地址学习能力的。

交换机会记住，MAC1是来自一个明确的口。以后有包的目的地址是MAC1的，直接发送到这个口就可以了。
当交换机作为一个关卡一样，过了一段时间之后，就有了整个网络的一个结构了，这个时候，基本上不用广播了，全部可以准确转发。当然，每个机器的IP地址会变，所在的口也会变，因而交换机上的学习的结果，我们称为转发表，是有一个过期时间的。



### 交换机与VLAN



#### 拓扑结构形成

 ![img](.\企业微信截图_16349696284295.png) 



##### 两个交换机3个局域网的情形

当机器1要访问机器4
机器1 发起广播，机器2和交换机A都收到广播；
交换机会转发广播包到除了来的方向上之外的所有网口，所以机器3和交换机B都会收到；
交换机B将广播包发送给局域网三，机器4和机器5收到广播信息；
机器4响应，并回复MAC地址；
ARP请求成功



#### 环路问题

 ![img](.\企业微信截图_16349700931926.png) 



环路问题一般是STP协议来解决的，通过协议将图(环)生成树，解决

STP协议及相关概念



在数据结构中，有一个方法叫作最小生成树。有环的我们常称为图。将图中的环破了，就生成了树。在
计算机网络中，生成树的算法叫作STP，全称Spanning Tree Protocol。

Root Bridge: 根交换机

Designated Bridges：指定交换机（可以理解为指定了连接的根交换机的交换机）

Bridge Protocol Data Units：网桥协议数据单元（可以理解为特定的规则、环境）

Priority Vector: 优先级向量（可以理解为自身的优先级别，值越小越优先）





#### 解决广播问题和安全问题

##### 物理隔离

使用不同的交换机达到隔离的效果。

##### 虚拟隔离

就是VLAN(虚拟局域网)

 ![img](.\企业微信截图_16349713953268.png) 



需要在原来的二层头加TAG，里面有个VLAN ID，一共12位，可以划分4096个VLAN。当然需要支持vlan的交换机。

当这个交换机把二层的头取下来的时候，就能够识别这个VLANID。这样只有相同VLAN的包，才会互相转发，不同VLAN的包，是看不到的。这样广播问题和安全问题就都能够解决了。



#### 交换机与交换机连接

对于支持VLAN的交换机，有一种口叫作**Trunk**口。它可以转发属于任何VLAN的口。交换机之间可以通过这种口相互连接。



### ICMP协议与ping



ping是基于ICMP协议工作的。ICMP全称Internet Control Message Protocol，就是互联网控制报文协议。这里面的关键词是“控制”，

ICMP报文是封装在IP包里面的。因为传输指令的时候，肯定需要源地址和目标地址。



 ![img](.\企业微信截图_16349722182228.png) 

ICMP报文有很多的类型，不同的类型有不同的代码。最常用的类型是主动请求为8，主动请求的应答为0。



#### 查询报文类型

常用的ping就是查询报文，是一种主动请求，并且获得主动应答的ICMP协议。所以，ping发的包也是符合ICMP协议格式的，只不过它在后面增加了自己的格式。

对ping的主动请求，进行网络抓包，称为ICMP ECHO REQUEST。同理主动请求的回复，称为ICMP ECHO EPLY。比起原生的ICMP，这里面多了两个字段，一个是标识符。

 ![img](.\企业微信截图_16349726238036.png) 

ICMP数据包内包含多个字段。最重要的是两个，第一个是类型字段，对于请求数据包而言该字段为 8；另外一个是顺序号，主要用于区分连续ping的时候发出的多个数据包。每发出一个请求数据包，顺序号会自动加1。为了能够计算往返时间RTT，它会在报文的数据部分插入发送时间。

在选项数据中，ping还会存放发送请求的时间值，来计算往返时间，说明路程的长短。



#### 差错报文类型

终点不可达为3，源抑制为4，超时为11，重定向为5。

第一种终点不可达：包括网络不可达、主机不可达、协议不可达、端口不可达、分片设置不一致等；
第二种是源站抑制，也就是让源站放慢发送速度。
第三种是时间超时，也就是超过网络包的生存时间还是没到。
第四种是路由重定向，也就是让下次发给另一个路由器。

差错报文的结构相对复杂一些。除了前面还是IP，ICMP的前8字节不变，后面则跟上出错的那个IP包的IP头和IP正文的前8个字节。

有一个程序Traceroute ，它会使用ICMP的规则，故意制造一些能够产生错误的场景。

**Traceroute**的第一个作用就是故意设置特殊的TTL，来追踪去往目的地时沿途经过的路由器。

Traceroute 程序会发送一份UDP数据报给某个目的IP地址主机，但它会选择一个不可能的值作为UDP端口号（大于30000）。当该数据报到达时，将使目的主机的 UDP模块产生一份“端口不可达”错误ICMP报文。如果数据报没有到达，则可能是超时。

Traceroute还有一个作用是故意设置不分片，从而确定路径的MTU。要做的工作首先是发送分组，并设置“不分片”标志。发送的第一个分组的长度正好与出口MTU相等。如果中间遇到窄的关口会被卡住，会发送ICMP网络差错包，类型为“需要进行分片但设置了不分片位”。每次收到ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。



### 网关



#### MAC 和IP头细节

 ![img](.\企业微信截图_16349747357444.png) 

> 在MAC头里面，先是目标MAC地址，然后是源MAC地址，然后有一个协议类型，用来说明里面是IP协
> 议。IP头里面的版本号，目前主流的还是IPv4，服务类型TOS在第三节讲ip addr命令的时候讲过，TTL在第7节讲ICMP协议的时候讲过。另外，还有8位标识协议。这里到了下一层的协议，也就是，是TCP还是UDP。最重要的就是源IP和目标IP。先是源IP地址，然后是目标IP地址。



当一个机器访问另外一台机器时：

首先判断是否处于同一网段（根据CIDR和子网掩码），

- 如果同一网段，直接将源地址和目标地址放入IP头中，然后通过ARP获得MAC地址，将源MAC和目的MAC放入MAC头中，发出去就可以了。
- 如果不同网段，这就需要发往默认网关Gateway。Gateway的地址一定是和源IP地址是一个网段的。

#### 网关概念

网关往往是一个路由器，是一个三层转发的设备。路由器是一台设备，它有五个网口或者网卡，分别连着五个局域网。每个网口的IP地址都和局域网的IP地址相同的网段，每个网口都是它连接的那个局域网的网关。

#### 路由策略

分为静态路由和动态路由

静态路由：其实就是在路由器上，配置一条一条规则。



#### 转发网关和NAT网关

MAC地址是一个局域网内才有效的地址。因而，MAC地址只要过网关，就必定会改变，因为已经换了局域网。两者主要的区别在于IP地址是否改变。不改变IP地址的网关，我们称为转发网关；改变IP地址的网关，我们称为NAT网关。



##### 转发网关

 ![img](.\企业微信截图_16349762596469.png) 

服务器A要访问服务器B。首先判断192.168.4.101和本机不是一个网段的，因而需要先发给网关。网关已经静态配置好了，是192.168.1.1。发送ARP获取网关的MAC地址，然后发送包。包的内容是这样的：

```
源MAC：服务器A的MAC
目标MAC：192.168.1.1这个网口的MAC
源IP：192.168.1.101
目标IP：192.168.4.101
```


包到达192.168.1.1这个网口，发现MAC一致，将包收进来。

在路由器A中配置了静态路由之后，要想访问192.168.4.0/24，要从192.168.56.1这个口出去，下一跳
为192.168.56.2。

匹配上了这条路由，要从192.168.56.1这个口发出去，发给192.168.56.2，
路由器A发送ARP获取192.168.56.2的MAC地址，然后发送包。包的内容是这样的：

```
源MAC：192.168.56.1的MAC地址
目标MAC：192.168.56.2的MAC地址
源IP：192.168.1.101
目标IP：192.168.4.101
```

包到达192.168.56.2这个网口，发现MAC一致，将包收进来。
在路由器B中配置了静态路由，要想访问192.168.4.0/24，要从192.168.4.1这个口出去，没有下一跳了。

于是，匹配上了这条路由，要从192.168.4.1这个口发出去，发给192.168.4.101。
路由器B发送ARP获取192.168.4.101的MAC地址，然后发送包。包的内容是这样的：

```
源MAC：192.168.4.1的MAC地址
目标MAC：192.168.4.101的MAC地址
源IP：192.168.1.101
目标IP：192.168.4.101
```

包到达服务器B，MAC地址匹配，将包收进来。

通过这个过程可以看出，**每到一个新的局域网，MAC都是要变的，但是IP地址都不变。在IP头里面，不会保存任何网关的IP地址。**所谓的**下一跳是，某个IP要将这个IP地址转换为MAC放入MAC头。**



##### NAT网关

 ![img](.\企业微信截图_16349767373695.png) 

首先，目标服务器B在国际上要有一个国际的身份，我们给它一个192.168.56.2。在网关B上，我们记下
来，国际身份192.168.56.2对应国内身份192.168.1.101。凡是要访问192.168.56.2，都转成192.168.1.101。

源服务器A要访问目标服务器B，要指定的目标地址为192.168.56.2。服务器A需要发给网关192.168.1.1。发送ARP获取网关的MAC地址，然后发送包。包的内容是这样的：

```
源MAC：服务器A的MAC
目标MAC：192.168.1.1这个网口的MAC
源IP：192.168.1.101
目标IP：192.168.56.2
```

包到达192.168.1.1这个网口，发现MAC一致，将包收进来。
在路由器A中配置了静态路由：要想访问192.168.56.2/24，要从192.168.56.1这个口出去，发给192.168.56.2。
路由器A发送ARP获取192.168.56.2的MAC地址。当网络包发送到中间的局域网的时候，服务器A也需要有个国际身份，因而在国际上，源IP地址也不能用192.168.1.101，需要改成192.168.56.1。发送包的内容是这样的：

```
源MAC：192.168.56.1的MAC地址
目标MAC：192.168.56.2的MAC地址
源IP：192.168.56.1
目标IP：192.168.56.2
```

包到达192.168.56.2这个网口，发现MAC一致，将包收进来。
路由器B是一个NAT网关，它上面配置了，要访问国际身份192.168.56.2对应国内身份192.168.1.101，于是改为访问192.168.1.101。
在路由器B中配置了静态路由：要想访问192.168.1.0/24，要从192.168.1.1这个口出去发给192.168.1.101。
路由器B发送ARP获取192.168.1.101的MAC地址，然后发送包。内容是这样的：

```
源MAC：192.168.1.1的MAC地址
目标MAC：192.168.1.101的MAC地址
源IP：192.168.56.1
目标IP：192.168.1.101
```

包到达服务器B，MAC地址匹配，将包收进来。
从服务器B接收的包可以看出，源IP为服务器A的国际身份，因而发送返回包的时候，也发给这个国际身
份，由路由器A做NAT，转换为国内身份。

从这个过程可以看出**，IP地址也会变。这个过程用英文说就是Network Address Translation，简**
**称NAT。**



### 路由



#### 路由表

路由器就是一台网络设备，它有多张网卡。当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。这个转发信息库通常被称为**路由表**。

路由表中规则包含信息：

- 目的网络
- 出口设备
- 下一跳网关

#### 配置(静态)路由表

##### 根据ip地址配置路由

```
ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0
```

就说明要去10.176.48.0/20这目标网络，要从eth0端口出去，经过10.173.32.1。

##### 策略路由

在真实的复杂的网络环境中，除了可以根据目的ip地址配置路由外，还可以根据多个参数来配置
路由，这就称为策略路由。

##### 根据路由表

```
ip rule add from 192.168.1.0/24 table 10
ip rule add from 192.168.2.0/24 table 20
```

表示从192.168.1.10/24这个网段来的，使用table 10中的路由表，而从192.168.2.0/24网段来的，使
用table20的路由表。

##### 根据权重

```
ip route add default scope global nexthop via 100.100.100.1 weight 1 nexthop via 200.200.200.1 weight 2
```

下一跳有两个地方，分别是100.100.100.1和200.200.200.1，权重分别为1比2。



##### 较复杂的配置例子



![1634978803246](.\1634978803246.png)

路由配置结果

```
$ ip route lis table main
60.190.27.189/30 dev eth3 proto kernel scope link src 60.190.27.190
183.134.188.1 dev eth2 proto kernel scope link src 183.134.189.34
192.168.1.0/24 dev eth1 proto kernel scope link src 192.168.1.1
127.0.0.0/8 dev lo scope link
default via 183.134.188.1 dev eth2
```

当路由这样配置的时候，就告诉这个路由器如下的规则：
如果去运营商二，就走eth3；
如果去运营商一呢，就走eth2；
如果访问内网，就走eth1；
如果所有的规则都匹配不上，默认走运营商一，也即走快的网络。

添加一个表，chao

```
# echo 200 chao >> /etc/iproute2/rt_tables


# 添加一条规则
# ip rule add from 192.168.1.101 table chao
# ip rule ls
0: from all lookup local
32765: from 10.0.0.10 lookup chao
32766: from all lookup main
32767: from all lookup default
```

设定规则为：从192.168.1.101来的包都查看个chao这个新的路由表。

在chao路由表中添加规则

```
# ip route add default via 60.190.27.189 dev eth3 table chao
# ip route fush cache
```

默认192.168.1.101的路由走慢的



#### 动态路由

使用动态路由路由器，可以根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。

最短路径常用的有两种方法，一种是Bellman-Ford算法，一种是Dijkstra算法。在计算机网络中基本也是用这两种方法计算的。

##### 距离矢量路由算法

第一大类的算法称为距离矢量路由（distance vector routing）。它是基于Bellman-Ford算法的。

这种算法的基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。

由此可以看出，每个路由器都是知道全局信息的。那这个信息如何更新呢？每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。

每个路由器根据新收集的信息，计算和其他路由器的距离，比如自己的一个邻居距离目标路由器的距离是M，而自己距离邻居是x，则自己距离目标路由器是x+M。

第一个问题就是好消息传得快，坏消息传得慢。

- 如果有个路由器加入了这个网络，它的邻居就能很快发现它，然后将消息广播出去。要不了多久，整个网络就都知道了。但是一旦一个路由器挂了，挂的消息是没有广播的。当每个路由器发现原来的道路到不了这个路由器的时候，感觉不到它已经挂了，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器是真的挂了。

这种算法的第二个问题是，每次发送的时候，要发送整个全局路由表。

所以上面的两个问题，限制了距离矢量路由的网络规模。

###### **基于距离矢量路由算法的BGP**

外网的路由协议，也即国家之间的，我们称为外网路由协议（**Border GatewayProtocol，简称BGP**）。

每个数据中心都设置自己的Policy。例如，哪些外部的IP可以让内部知晓，哪些内部的IP可以让外部知晓，哪些可以通过，哪些不能通过。
在网络世界，这一个个国家成为自治系统AS（Autonomous System）。自治系统分几种类型。

- Stub AS：对外只有一个连接。这类AS不会传输其他AS的包。例如，个人或者小公司的网络。
- Multihomed AS：可能有多个连接连到其他的AS，但是大多拒绝帮其他的AS传输包。例如一些大公
  司的网络。
- Transit AS ：有多个连接连到其他的AS，并且可以帮助其他的AS传输包。例如主干网。

**每个自治系统都有边界路由器**，通过它和外面的世界建立联系。

**BGP又分为两类，eBGP和iBGP。**

自治系统间，边界路由器之间使用**eBGP**广播路由。

内部网络也需要访问其他的自治系统。边界路由器如何将BGP学习到的路由导入到内部网络呢？就是通过运行**iBGP**，使得内部的路由器能够找到到达外网目的地的最好的边界路由器。
BGP协议使用的算法是路径矢量路由协议（path-vector protocol）。它是距离矢量路由协议的升级版。
前面说了距离矢量路由协议的缺点。其中一个是收敛慢。在BGP里面，除了下一跳hop之外，还包括了自治系统AS的路径，从而可以避免坏消息传的慢的问题，也即上面所描述的，B知道C原来能够到达A，是因为通过自己，一旦自己都到达不了A了，就不用假设C还能到达A了。
另外，在路径中将一个自治系统看成一个整体，不区分自治系统内部的路由器，这样自治系统的数目是非常有限的。就算是发送全局信息，也是没有问题的。



##### 链路状态路由算法

第二大类算法是链路状态路由（link state routing），基于Dijkstra算法。

这种算法的基本思路是：当一个路由器启动的时候，首先是发现邻居，向邻居say hello，邻居都回复。然后计算和邻居的距离，发送一个echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链路状态包广播出去，发送到整个网络的每个路由器。这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用Dijkstra算法，找到两点之间的最短路径。
不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和CPU利用率。而且一旦一个路由器挂了，它的邻居都会广播这个消息，可以使得坏消息迅速收敛。

###### 基于链路状态路由算法的OSPF

**OSPF**（Open Shortest Path First，开放式最短路径优先）就是这样一个基于链路状态路由协议，广泛应用在数据中心中的协议。由于主要用在数据中心内部，用于路由决策，因而称为**内部网关协**
**议（Interior Gateway Protocol，简称IGP**）。



### UDP协议

#### UDP特点

UDP继承了IP包的特性，不保证不丢失，不保证按顺序到达。
UDP继承了IP的特性，基于数据报的，一个一个地发，一个一个地收。
UDP没有拥塞控制；
UDP是无状态服务，它不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也
可以传给任何人数据，甚至可以同时传给多个人数据。

当发送的UDP包到达目标机器后，发现MAC地址匹配，于是就取下来，将剩下的包传给处理IP层的代码。把IP头取下来，发现目标IP匹配，在IP头里面有个8位协议，这里会存放数据里面到底是TCP还是UDP，当然这里是UDP。

#### UDP包头格式

![img](.\企业微信截图_16349820919903.png) 

#### UDP使用场景

第一，需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用。（比如监控数据）
第二，不需要一对一沟通，建立连接，而是可以广播的应用。
第三，需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前
的时候。

### TCP协议



#### 特点

所谓的建立连接，是为了在客户端和服务端维护连接，而建立一定的数据结构来维护双方交互的状态，用这样的数据结构来保证所谓的面向连接的特性。
TCP提供可靠交付。通过TCP连接传输的数据，无差错、不丢失、不重复、并且按序到达。
TCP是面向字节流的。发送的时候发的是一个流，没头没尾。IP包可不是一个流，而是一个个的IP包。之所以变成了流，这也是TCP自己的状态维护做的事情。
TCP是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。
TCP其实是一个有状态服务。



#### TCP包头格式

![img](.\企业微信截图_16349825165439.png) 

- 首先，源端口号和目标端口号是不可少的，这一点和UDP是一样的。如果没有这两个端口号。数据就不
  知道应该发给哪个应用。
- 接下来是包的序号。为了**解决乱序**的问题。
- 还应该有的就是确认序号。这个可以解决**不丢包**的问题。
- TCP是靠谱的协议，对于TCP层面上，会努力保证**可靠**性（重传等机制）。
- 接下来有一些状态位。例如SYN是发起一个连接，ACK是回复，RST是重新连接，FIN是结束连接
  等。TCP是**面向连接**的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变
  更。
- 还有一个重要的就是窗口大小。TCP要做**流量控制**，通信双方各声明一个窗口，标识自己当前能够的处
  理能力。
- TCP还会做**拥塞控制**，控制发送的速度。



#### 三次握手



 ![img](.\企业微信截图_16350669667909.png) 

一开始，客户端和服务端都处于CLOSED状态。先是服务端主动监听某个端口，处于LISTEN状态。然后客户端主动发起连接SYN，之后处于SYN-SENT状态。服务端收到发起的连接，返回SYN，并且ACK客户端的SYN，之后处于SYN-RCVD状态。客户端收到服务端发送的SYN和ACK之后，发送ACK的ACK，之后处于ESTABLISHED状态，因为它一发一收成功了。服务端收到ACK的ACK之后，处于ESTABLISHED状态，因为它也一发一收了。



#### 四次挥手



![img](.\企业微信截图_16350673531207.png) 



断开的时候，我们可以看到，当客户端主动发送断开请求后，就进入FIN_WAIT_1的状态，服务端收到消息后，回复ack，就进入CLOSE_WAIT的状态。
客户端收到服务端的ack，就进入FIN_WAIT_2的状态，如果这个时候服务端强制断开了，则客户端将永远在这个状态。TCP协议里面并没有对这个状态的处理，但是Linux有，可以调整tcp_fn_timeout这个参数，设置一个超时时间。
如果服务端没有断开，处理完所有数据后，发送了FIN ACK的请求到达客户端时，客户端收到后发送ACK后，从FIN_WAIT_2状态结束，按说客户端可以断开了，但是最后的这个ACK万一服务端收不到呢？则服务端会重新发一个FIN ACK，这个时候客户端已经断开了的话，服务端就再也收不到ACK了，因而TCP协议要求客户端最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果服务端没收到ACK的话，“FIN ACK会重发的，客户端会重新发一个ACK并且足够时间到达服务端。
客户端直接断开还有一个问题是，客户端的端口就直接空出来了，但是服务端不知道，原来发过的很多包很可能还在路上，如果客户端的端口被一个新的应用占用了，这个新的应用会收到上个连接中服务端发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来服务端发送的所有的包都死翘翘，再空出端口来。
等待的时间设为2MSL，MSL是Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为TCP报文基于是IP协议的，而IP头中有一个TTL域，是IP数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。协议规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。
还有一个异常情况就是，服务端超过了2MSL的时间，依然没有收到它发的FIN的ACK，怎么办呢？按照TCP的原理，服务端当然还会重发FIN，这个时候客户端再收到这个包之后，就直接发送RST，服务端就知道客户端早断开连接了。



#### TCP状态机

 ![img](.\企业微信截图_16350682615524.png) 





#### 顺序性

TCP协议使用的也是同样的模式。为了保证顺序性，每一个包都有一个ID。在建立连接的时候，会商定
起始的ID是什么，然后按照ID一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应
答也不是一个一个来的，而是会应答某个之前的ID，表示都收到了，这种模式称为**累计确认或者累计应**
**答（cumulative acknowledgment）**。

为了记录所有发送的包和接收的包，TCP也需要发送端和接收端分别都有缓存来保存这些记录。**发送端**
**的缓存**里是按照包的ID一个个排列，根据处理的情况分成四个部分。

 ![img](.\企业微信截图_16352085506251.png) 

第一部分：发送了并且已经确认的。
第二部分：发送了并且尚未确认的。
第三部分：没有发送，但是已经等待发送的。
第四部分：没有发送，并且暂时还不会发送的。

在TCP里，**接收端会给发送端报一个窗口的大小，叫Advertised window**。这个窗口的大小应该等于上面的第二部分加上第三部分。超过这个窗口的，接收端做不过来，就不能发送了。

对于**接收端**来讲，它的**缓存**里记录的内容要简单一些。

第一部分：接受并且确认过的。也就是我领导交代给我，并且我做完的。
第二部分：还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。
第三部分：还没接收，也没法接收的。也即超过工作量的部分，实在做不完。
对应的数据结构就像这样。

![img](.\企业微信截图_16352087636698.png) ﻿
MaxRcvBuffer：最大缓存的量；
LastByteRead之后是已经接收了，但是还没被应用层读取的；
NextByteExpected是第一部分和第二部分的分界线。

其中第二部分里面，由于**收到**的包**可能不是顺序**的，会出现空挡**，只有和第一部分连续的，可以马上进**
**行回复**，中间空着的部分需要等待，哪怕后面的已经来了。

#### 确认与重发的机制

一种方法就是**超时重试**，也即对每一个发送了，但是没有ACK的包，都有设一个定时器，超过了一定的
时间，就重新尝试。

估计往返时间，需要TCP通过采样RTT的时间，然后进行加权平均，算出一个值，而且这个值还是要不
断变化的，因为网络状况不断的变化。除了采样RTT，还要采样RTT的波动范围，计算出一个估计的超
时时间。由于重传时间是不断变化的，我们称为自适应重传算法（Adaptive Retransmission
Algorithm）。

**有需要重传的时候，TCP的策略是超时间隔加倍。**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。

**有一个可以快速重传的机制**，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个没有收到包序号的前一个包的冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段。

**还有一种方式称为Selective Acknowledgment （SACK）。**这种方式需要在TCP头里加一个SACK的
东西，可以将缓存的地图发送给发送方。

#### 流量控制问题

发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。

#### 拥塞控制问题

拥塞控制的问题，也是通过窗口的大小来控制的，前面的**滑动窗口rwnd**是怕发送方把接收方缓存塞满，而**拥塞窗口cwnd**，是怕把网络塞满。

这里有一个公式 **LastByteSent - LastByteAcked <= min {cwnd, rwnd}** ，**是拥塞窗口和滑动窗口共同控制发送的速度**。

**TCP的拥塞控制主要来避免两种现象，包丢失和超时重传。**

一条TCP连接开始，cwnd设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认cwnd加一，两个确认cwnd加二，于是一次能够发送四个；当这四个的确认到来的时候，每个确认cwnd加一，四个确认cwnd加四，于是一次能够发送八个。可以看出这是指数性的增长。

有一个值ssthresh为65535个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满，再慢下来。每收到一个确认后，cwnd增加1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加1/8，八个确认一共cwnd增加1，于是一次能够发送九个，变成了线性增长。

但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子
降低倒水的速度，等待溢出的水慢慢渗下去。

拥塞的一种表现形式是丢包，需要超时重传，这个时候，将sshresh设为cwnd/2，将cwnd设为1，重新
开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度
一下子停了下来，会造成网络卡顿。
前面我们讲过快速重传算法。当接收端发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发
送端就会快速的重传，不必等待超时再重传。TCP认为这种情况不严重，因为大部分没丢，只丢了一小
部分，cwnd减半为cwnd/2，然后sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，
也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。

##### 包丢失和超时重传的问题

- 第一个问题是丢包并不代表着通道满了。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。

- 第二个问题是TCP的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了。其实TCP只要填满管道就可以了，不应该接着填，直到连缓存也填满。

为了优化这两个问题，后来有了**TCP BBR拥塞算法**。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的  达到高带宽和低时延的平衡。



### 基于TCP和UDP协议的Socket编程



Socket编程进行的是端到端的通信，往往意识不到中间经过多少局域网，多少路由器，因而能够设置的参数，也只能是端到端协议之上网络层和传输层的。
在网络层，Socket函数需要指定到底是IPv4还是IPv6，分别对应设置为AF_INET和AF_INET6。另外，还要指定到底是TCP还是UDP。
TCP协议是基于数据流的，所以设置为SOCK_STREAM，而UDP是基于数据报的，因而设置为SOCK_DGRAM。



#### 基于TCP协议的Socket程序函数调用过程

1. TCP的服务端要先监听一个端口，一般是先调用bind函数，给这个Socket赋予一个IP地址和端口。
2. 当服务端有了IP和端口号，就可以调用listen函数进行监听。在TCP的状态图里面，有一个listen状态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。
3. **在内核中，为每个Socket维护两个队列。**
   - 一个是已经建立了连接的队列，这时候连接三次- 握手已经完毕，处于established状态；
   - 一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于syn_rcvd的状态。

4. 接下来，服务端调用accept函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。
5. 在服务端等待的时候，客户端可以通过connect函数发起连接。先在参数中指明要连接的IP地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。
6. 一旦握手成功，服务端的accept就会返回另一个Socket。

> 这是一个经常考的知识点，**就是监听的Socket和真正用来传数据的Socket是两个，一个叫作监听Socket，一个叫作已连接Socket。**

7. 连接建立成功之后，双方开始通过read和write函数来读写数据，就像往一个文件流里面写东西一样。



这个图就是基于TCP协议的Socket程序函数调用过程。

 ![img](.\企业微信截图_16354697365533.png) 

说TCP的Socket就是一个**文件流**，是非常准确的。因为，Socket在Linux中就是以文件的形式存在的。除此之外，还存在文件描述符。写入和读出，也是通过文件描述符。
**在内核中，Socket是一个文件，那对应就有文件描述符。每一个进程都有一个数据结构task_struct**，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符。文件描述符是一个整数，是这个数组的下标。

这个数组中的内容是一个指针，指向内核中所有打开的文件的列表。既然是一个文件，就会有一个inode，只不过Socket对应的inode不像真正的文件系统一样，保存在硬盘上的，而是在内存中的。在这个inode中，指向了Socket在内核中的Socket结构。

在这个结构里面，主要的是两个队列，一个是发送队列，一个是接收队列。在这两个队列里面保存的是一个缓存sk_buff。这个缓存里面能够看到完整的包的结构。

 ![img](.\企业微信截图_16354698147560.png) 





#### 基于UDP协议的Socket程序函数调用过程

UDP是没有连接的，所以不需要三次握手，也就不需要调用listen和connect，但是，UDP的的交互仍然需要IP和端口号，因而也需要bind。UDP是没有维护连接状态的，因而不需要每对连接建立一组Socket，而是只要有一个Socket，就能够和多个客户端通信。也正是因为没有连接状态，每次通信的时候，都调用sendto和recvfrom，都可以传入IP地址和端口。

 ![img](.\企业微信截图_16354699355596.png) 

#### 最大连接数限制及解决方法

服务端最大并发TCP连接数远不能达到理论上限。首先主要是**文件描述符限制**，按照上面的原理，Socket都是文件，所以首先要通过ulimit配置文件描述符的数目；**另一个限制是内存**，按上面的数据结构，每个TCP连接都要占用一定内存，操作系统是有限的。

##### 多进程

在Linux下，**创建子进程使用fork函数**。通过名字可以看出，这是在父进程的基础上完全拷贝一个子进程。在Linux内核中，会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了哪一行程序的进程。显然，复制的时候在调用fork，复制完毕之后，父进程和子进程都会记录当前刚刚执行完fork。这两个进程刚复制完时候，几乎一模一样，**只是根据fork的返回值来区分到底是父进程，还是子进程。如果返回值是0，则是子进程；如果返回值是其他的整数，就是父进程。**

![img](.\企业微信截图_16354700676766.png) 

因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为accept创建的已连接Socket也是一个文件描述符，同样也会被子进程获得。

接下来，子进程就可以通过这个已连接Socket和客户端进行互通了，当通信完毕之后，就可以退出进程，那父进程如何知道子进程干完了项目，要退出呢？还记得fork返回的时候，如果是整数就是父进程吗？这个整数就是子进程的ID，父进程可以通过这个ID查看子进程是否完成项目，是否需要退出。



##### 多线程

在Linux下，通过pthread_create创建一个线程，也是调用do_fork。不同的是，虽然新的线程在task列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一个引用而已。

![img](.\企业微信截图_16354702572644.png) 

新的线程也可以通过已连接Socket处理请求，从而达到并发处理的目的。

##### C10K问题

一台机器要维护1万个连接，就要创建1万个进程或者线程，那么操作系统是无法承受的。

##### select（IO多路复用）

IO多路复用，一个线程维护多个Socket。

调用select函数来监听文件描述符集合是否有变化。一旦有变化，就会**依次查看每个文件描述符**。那些发生变化的文件描述符在fd_set对应的位都设为1，表示Socket可读或者可写，从而可以进行读写操作，然后再调用select，接着盯着下一轮的变化。

##### epoll（IO多路复用）

epoll，它在内核中的实现不是通过轮询的方式，而是通过注册callback函数的方式，当某个**文件描述符发送变化**的时候，就会**主动通知**。

 ![img](.\企业微信截图_16354704618667.png) 

假设进程打开了Socket m, n, x等多个文件描述符，现在需要通过epoll来监听是否这些Socket都有事件发生。其中**epoll_create创建一个epoll对象**，也是一个文件，也对应一个文件描述符，同样也对应着**打开文件列表中的一项。**在这**项里面有一个红黑树**，在红黑树里，要保存这个epoll要监听的所有Socket。
**当epoll_ctl添加一个Socket的时候，其实是加入这个红黑树**，同时红黑树里面的节点指向一个结构，将这个结构挂在被监听的Socket的事件列表中。当一个Socket来了一个事件的时候，可以从这个列表中得到epoll对象，并调用**call back通知**它。
这种通知方式使得监听的Socket数据增加的时候，效率不会大幅度降低，能够同时监听的Socket的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，**epoll被称为解决C10K问题的利器**。

### HTTP协议

#### 请求结构

HTTP的报文大概分为三大部分。第一部分是请求行，第二部分是请求的首部，第三部分才是请求的正文实体。

 ![img](.\企业微信截图_1635473356972.png) 

##### 第一部分：请求行

顾名思义，**GET**就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。其实也有很多其他的格式，比如说返回一个JSON字符串，到底要返回什么，是由服务器端的实现决定的。=

另外一种类型叫做**POST**。它需要主动告诉服务端一些信息，而非获取。

还有一种类型叫**PUT**，就是向指定资源位置上传最新内容。但是，HTTP的服务器往往是不允许上传文件的，所以PUT和POST就都变成了要传给服务器东西的方法。

再有一种常见的就是**DELETE**。这个顾名思义就是用来删除资源的。

##### 第二部分：首部字段、

请求行下面就是我们的首部字段。首部是key value，通过冒号分隔。这里面，往往保存了一些非常重要的字段。

Accept-Charset，表示客户端可以接受的字符集。防止传过来的是另外的字符集，从而导致出现乱码。
再如，Content-Type是指正文的格式。例如，我们进行POST的请求，如果正文是JSON，那么我们就应该将这个值设置为JSON。

这里需要重点说一下的就是缓存。

在HTTP头里面**，Cache-control**是用来控制缓存的。当客户端发送的请求中包含max-age指令时，如果判定缓存层中，资源的缓存时间数值比指定时间的数值小，那么客户端可以接受缓存的资源；当指定max-age值为0，那么缓存层通常需要将请求转发给应用集群。

**If-Modified-Since**也是一个关于缓存的。也就是说，如果服务器的资源在某个时间之后更新了，那么客户端就应该下载最新的资源；如果没有更新，服务端会返回“304 Not Modifed”的响应，那客户端就不用下载了，也会节省带宽。

#### 返回结构

 ![img](.\企业微信截图_16354736408271.png) 

状态码会反应HTTP请求的结果。

在返回的头部里面也会有Content-Type，表示返回的是HTML，还是JSON。

Retry-After表示，告诉客户端应该在多长时间以后再次尝试一下。“503错误”是说“服务暂时不再和这个值配合使用”。

#### HTTP 2.0

- HTTP 2.0会对HTTP的**头进行一定的压缩**，将原来每次都要携带的大量key value在两端建立一个索引表，对相同的头只发送索引表中的索引。
- HTTP 2.0协议**将一个TCP的连接中，切分成多个流**，每个流都有自己的ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。
- HTTP 2.0还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。
  - 常见的帧有Header帧，用于传输Header内容，并且会开启一个新的流。
  - 再就是Data帧，用来传输正文实体。多个Data帧属于同一个流。
   >通过这两种机制，HTTP 2.0的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。



#### QUIC协议

Google的QUIC协议，基于UDP。

**机制一：自定义连接机制**
我们都知道，一条TCP连接是由四元组标识的，分别是源 IP、源端口、目的 IP、目的端口。一旦一个元素发生变化时，就需要断开重连，重新连接。在移动互联情况下，当手机信号不稳定或者在WIFI和 移动网络切换时，都会导致重连，从而进行再次的三次握手，导致一定的时延。
这在TCP是没有办法的，但是基于UDP，就可以在QUIC自己的逻辑里面维护连接的机制，不再以四元组标识，而是以一个64位的随机数作为ID来标识，而且UDP是无连接的，所以当IP或者端口变化的时候，只要ID不变，就不需要重新建立连接。
**机制二：自定义重传机制**
前面我们讲过，TCP为了保证可靠性，通过使用序号和应答机制，来解决顺序问题和丢包问题。任何一个序号的包发过去，都要在一定的时间内得到应答，否则一旦超时，就会重发这个序号的包。

QUIC也有个序列号，是递增的。任何一个序列号的包只发送一次，下次就要加一了。例如，发送一个包，序号是100，发现没有返回；再次发送的时候，序号就是101了；如果返回的ACK 100，就是对第一个包的响应。如果返回ACK 101就是对第二个包的响应，RTT计算相对准确。

QUIC定义了一个offset概念。QUIC既然是面向连接的，也就像TCP一样，是一个数据流，发送的数据在这个数据流里面有个偏移量offset，可以通过offset查看数据发送到了哪里，这样只要这个offset的包没有来，就要重发；如果来了，按照offset拼接，还是能够拼成一个流。

**机制三：无阻塞的多路复用**
有了自定义的连接和重传机制，我们就可以解决上面HTTP 2.0的多路复用问题。
同HTTP 2.0一样，同一条QUIC连接上可以创建多个stream，来发送多个 HTTP 请求。但是，QUIC是基于UDP的，一个连接上的多个stream之间没有依赖。这样，假如stream2丢了一个UDP包，后面跟着stream3的一个UDP包，虽然stream2的那个包需要重传，但是stream3的包无需等待，就可以发给用户。
**机制四：自定义流量控制**
TCP的流量控制是通过滑动窗口协议。QUIC的流量控制也是通过window_update，来告诉对端它可以接受的字节数。但是QUIC的窗口是适应自己的多路复用机制的，不但在一个连接上控制窗口，还在一个连接中的每个stream控制窗口。

QUIC的ACK是基于offset的，每个offset的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空挡会等待到来或者重发即可，而窗口的起始位置为当前收到的最大offset，从这个offset到当前的stream所能容纳的最大缓存，是真正的窗口大小。显然，这样更加准确。

![img](.\企业微信截图_16354745953386.png) 

### HTTPS协议



当然一般的思路就是加密。加密分为两种方式一种是对称加密，一种是非对称加密。

在**对称加密算法**中，加密和解密使用的密钥是相同的。也就是说，加密和解密使用的是同一个密钥。因此，对称加密算法要保证安全性的话，密钥要做好保密。只能让使用的人知道，不能对外公开。（密钥相互传输有问题）

在**非对称加密算法**中，加密使用的密钥和解密使用的密钥是不相同的。一把是作为公开的公钥，另一把是作为谁都不能给的私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。（私钥安全性及真伪问题）

因为对称加密算法相比非对称加密算法来说，效率要高得多，性能也好，所以交互的场景下多用对称加密。



#### 数字证书

个由权威部门颁发的称为**证书**（Certificate）
证书里面：

- 当然应该有公钥，这是最重要的；
- 还有证书的所有者；
- 另外还有证书的发布机构和证书的有效期。

生成证书需要发起一个证书请求，然后将这个请求发给一个权威机构去认证，这个权威机构我们称为**CA**（ Certificate Authority）。
  将这个请求发给权威机构，权威机构会给这个证书卡一个章，我们称为**签名算法。**只有用只掌握在权威机构手里的东西签名了才行，这就是CA的私钥。
**签名算法**：一般是对信息做一个Hash计算，得到一个Hash值，这个过程是不可逆的，也就是说无法通过Hash值得出原来的信息内容。在把信息发送出去时，把这个Hash值加密后，作为一个签名和信息一起发出去。
**签名后证书的内容**：

- 这里面有个Issuer，也即证书是谁颁发的；
- Subject，就是证书颁发给谁；
- Validity是证书期限；
- Publickey是公钥内容；
- Signature Algorithm是签名算法。

#### HTTPS的工作模式





![img](.\7042f5c3d9e3437d5b0b30b30f43c802.jpg)

当你登录一个外卖网站的时候，由于是HTTPS，客户端会发送Client Hello消息到服务器，以明文传输TLS版本信息、加密套件候选列表、压缩算法候选列表等信息。另外，还会有一个随机数，在协商对称密钥的时候使用。
然后，外卖网站返回Server Hello消息, 告诉客户端，服务器选择使用的协议版本、加密套件、压缩算法等，还有一个随机数，用于后续的密钥协商。
然后，外卖网站会给你一个服务器端的证书，然后说：“Server Hello Done，我这里就这些信息了。”
你当然不相信这个证书，于是你从自己信任的CA仓库中，拿CA的证书里面的公钥去解密外卖网站的证书。如果能够成功，则说明外卖网站是可信的。这个过程中，你可能会不断往上追溯CA、CA的CA、CA的CA的CA，反正直到一个授信的CA，就可以了。
证书验证完毕之后，觉得这个外卖网站可信，于是客户端计算产生随机数字Pre-master，发送Client Key Exchange，用证书中的公钥加密，再发送给服务器，服务器可以通过私钥解密出来。
到目前为止，无论是客户端还是服务器，都有了三个随机数，分别是：自己的、对端的，以及刚生成的Pre-Master随机数。通过这三个随机数，可以在客户端和服务器产生相同的对称密钥。
有了对称密钥，客户端就可以说：“Change Cipher Spec，咱们以后都采用协商的通信密钥和加密算法进行加密通信了。”
然后发送一个Encrypted Handshake Message，将已经商定好的参数等，采用协商密钥进行加密，发送给服务器用于数据与握手验证。
同样，服务器也可以发送Change Cipher Spec，说：“没问题，咱们以后都采用协商的通信密钥和加密算法进行加密通信了”，并且也发送Encrypted Handshake Message的消息试试。当双方握手结束之后，就可以通过对称密钥进行加密传输了。
这个过程除了加密解密之外，其他的过程和HTTP是一样的，过程也非常复杂。
上面的过程只包含了HTTPS的单向认证，也即客户端验证服务端的证书，是大部分的场景，也可以在更
加严格安全要求的情况下，启用双向认证，双方互相验证证书。





### 流媒体协议(未完待续)

每一张图片，我们称为一**帧**。只要每秒钟帧的数据足够多，也即播放得足够快。比如每秒30帧，以人的眼睛的敏感程度，是看不出这是一张张独立的图片的，这就是我们常说的**帧率**（FPS）。

每一张图片，都是由像素组成的，假设为1024*768（这个像素数不算多）。每个像素由RGB组成，每个8位，共24位。这个数据量实在是太大，根本没办法存储和传输。

人们想到了编码，就是看如何用尽量少的Bit数保存视频，使播放的时候画面看起来仍然很精美。编码是一个压缩的过程。

之所以能够对视频流中的图片进行压缩，因为视频和图片有这样一些特点。
1. 空间冗余：图像的相邻像素之间有较强的相关性，一张图片相邻像素往往是渐变的，不是突变的，
没必要每个像素都完整地保存，可以隔几个保存一个，中间的用算法计算出来。
2. 时间冗余：视频序列的相邻图像之间内容相似。一个视频中连续出现的图片也不是突变的，可以根
据已有的图片进行预测和推断。
3. 视觉冗余：人的视觉系统对某些细节不敏感，因此不会每一个细节都注意到，可以允许丢失一些数
据。
4. 编码冗余：不同像素值出现的概率不同，概率高的用的字节少，概率低的用的字节多，类似霍夫曼
编码（Huffman Coding）的思路。



编码过程

![img](.\433a51e15d0ed50e313454ceccd61cb4.jpg)



视频编码的两大流派

- 流派一：**ITU**（International Telecommunications Union ）的**VCEG**（Video Coding Experts Group），这个称为国际电联下的VCEG。既然是电信，可想而知，他们最初做视频编码，主要侧重传输。名词系列二，就是这个组织制定的标准。
- 流派二：**ISO**（International Standards Organization）的**MPEG**（Moving Picture Experts Group），这个是ISO旗下的MPEG，本来是做视频存储的。例如，编码后保存在VCD和DVD中。当然后来也慢慢侧重视频传输了。名词系列三，就是这个组织制定的标准。

后来，**ITU-T**（国际电信联盟电信标准化部门，ITU Telecommunication Standardization Sector ）与**MPEG****联合制定**了**H.264/MPEG-4 AVC** ，这才是我们这一节要重点关注的。

经过编码之后，生动活泼的一帧一帧的图像，就变成了一串串让人看不懂的二进制，这个二进制可以放在一个文件里面，按照一定的格式保存起来，这就是名词系列一。

当然，这个二进制也可以通过某种网络协议进行封装，放在互联网上传输，这个时候就可以进行网络直播了。
网络协议将编码好的视频流，从主播端推送到服务器，在服务器上有个运行了同样协议的**服务端来接收**这些网络包，从而得到里面的视频流，这个过程称为**接流**。
服务端接到视频流之后，可以对视频流进行一定的处理，例如转码，也即从一个编码格式，转成另一种格式。因为观众使用的客户端千差万别，要保证他们都能看到直播。
流处理完毕之后，就可以等待观众的客户端来请求这些视频流。观众的**客户端请求**的过程称为**拉流**。
如果有非常多的观众，同时看一个视频直播，那都从一个服务器上拉流，压力太大了，因而需要一个视频的**分发**网络，将视频**预先加载**到就近的**边缘节点**，这样大部分观众看的视频，是从边缘节点拉取的，就能降低服务器的压力。

当观众的客户端将视频流拉下来之后，就需要进行解码，也即通过上述过程的逆过程，将一串串看不懂的二进制，再转变成一帧帧生动的图片，在客户端播放出来。
整个直播过程，可以用这个的图来描述。

![img](.\e4d4b538c434ec0eade37028a34391f8.jpg)



### P2P协议(待续)


但是无论是HTTP的方式，还是FTP的方式，都有一个比较大的缺点，就是难以解决单一服务器的带宽压力， 因为它们使用的都是传统的客户端服务器的方式。
P2P就是peer-to-peer。资源开始并不集中地存储在某些设备上，而是分散地存储在多台设备上。这些设备我们姑且称为peer。
想要下载一个文件的时候，你只要得到那些已经存在了文件的peer，并和这些peer之间，建立点对点的连接，而不需要到中心服务器上，就可以就近下载文件。一旦下载了文件，你也就成为peer中的一员，你旁边的那些机器，也可能会选择从你这里下载文件，所以当你使用P2P软件的时候，例如BitTorrent ，往往能够看到，既有下载流量，也有上传的流量，也即你自己也加入了这个P2P的网络，自己从别人那里下载，同时也提供给其他人下载。可以想象，这种方式，参与的人越多，下载速度越快，一切完美。





### DNS协议

DNS服务器，一定要设置成高可用、高并发和分布式的。
DNS可以做内部负载均衡，还可以做全局负载均衡。

![img](.\企业微信截图_16361148135963.png)

**根DNS服务器** ：返回顶级域DNS服务器的IP地址
**顶级域DNS服务器**：返回权威DNS服务器的IP地址
**权威DNS服务器** ：返回相应主机的IP地址



#### DNS解析流程

1. 电脑客户端会发出一个DNS请求，查询www.163.com的IP，并发给本地域名服务器 (本地DNS)。本地DNS由你的网络服务商（ISP），如电信、移动等自动分配，它通常就在你网络服务商的某个机房；
2. 本地DNS收到来自客户端的请求。这台服务器上缓存了一张域名与之对应IP地址的大表格。如果能找到 www.163.com，它直接就返回IP地址。如果没有，本地DNS会去请求根域名服务器；
3. 根DNS收到来自本地DNS的请求，发现后缀是 .com，这个域名是由.com区域管理，返回它的顶级域名服务器的地址；
4. 本地DNS转向请求顶级域名服务器(比如 .com、.net、 .org这些一级域名)，它负责管理二级域名（比如 163.com）；
5. 顶级域名服务器返回 www.163.com 区域的权威DNS服务器的地址；
6. 本地DNS转向请求权威DNS服务器（163.com的权威DNS服务器，它是域名解析结果的原出处）；
7. 权限DNS服务器查询后将对应的IP地址X.X.X.X告诉本地DNS；
8. 本地DNS再将IP地址返回客户端，客户端和目标建立连接。

![img](.\企业微信截图_1636199418635.png)



#### HTTPDNS

HTTPNDS其实就是，不走传统的DNS解析，而是自己搭建基于HTTP协议的DNS服务器集群，分布在多个地点和多个运营商。当客户端需要DNS解析的时候，直接通过HTTP协议进行请求这个服务器集群，得到就近的地址。

> 这就相当于每家基于HTTP协议，自己实现自己的域名解析，自己做一个自己的地址簿，而不使用统一的地址簿。但是默认的域名解析都是走DNS的，因而使用HTTPDNS需要绕过默认的DNS路径，就不能使用默认的客户端。使用HTTPDNS的，往往是手机应用，需要在手机端嵌入支持HTTPDNS的客户端SDK。

![img](.\企业微信截图_16362004622471.png)

### CDN

分布在各个地方的各个数据中心的节点，就称为**边缘节点**。由于边缘节点数目比较多，但是每个集群规模比较小，不可能缓存下来所有东西，因而可能无法命中，这样就会在边缘节点之上。有**区域节点**，规模就要更大，缓存的数据会更多，命中的概率也就更大。在区域节点之上是**中心节点**，规模更大，缓存数据更多。如果还不命中，就只好回**源站**访问了。

![img](.\企业微信截图_16362008682439.png)

这就是CDN的分发系统的架构。CDN系统的缓存，也是一层一层的，能不访问后端真正的源，就不打扰它。

#### 客户端到边缘节点访问流程

![img](.\企业微信截图_16362021538318.png)

如上图，有了CDN之后。在web.com这个权威DNS服务器上，会设置一个CNAME别名，指向另外一个域名 www.web.cdn.com，返回给本地DNS服务器。
当本地DNS服务器拿到这个新的域名时，需要继续解析这个新的域名。这个时候，再访问的就不是web.com的权威DNS服务器了，而是web.cdn.com的权威DNS服务器，这是CDN自己的权威DNS服务器。在这个服务器上，还是会设置一个CNAME，指向另外一个域名，也即CDN网络的全局负载均衡器。
接下来，本地DNS服务器去请求CDN的全局负载均衡器解析域名，全局负载均衡器会为用户选择一台合适的缓存服务器提供服务，选择的依据包括：

- 根据用户IP地址，判断哪一台服务器距用户最近；
- 用户所处的运营商；
- 根据用户所请求的URL中携带的内容名称，判断哪一台服务器上有用户所需的内容；
- 查询各个服务器当前的负载情况，判断哪一台服务器尚有服务能力。

基于以上这些条件，进行综合分析之后，全局负载均衡器会返回一台缓存服务器的IP地址。
本地DNS服务器缓存这个IP地址，然后将IP返回给客户端，客户端去访问这个边缘节点，下载资源。缓存服务器响应用户请求，将用户所需内容传送到用户终端。如果这台缓存服务器上并没有用户想要的内容，那么这台服务器就要向它的上一级缓存服务器请求内容，直至追溯到网站的源服务器将内容拉到本地。

#### CDN缓存内容

CDN最擅长的是缓存静态数据，除此之外还可以缓存流媒体数据，这时候要注意使用防盗链。

##### 静态数据

对于静态页面来讲，内容的分发往往采取拉取的方式，也即当发现未命中的时候，再去上一级进行拉取。但是，流媒体数据量大，如果出现回源，压力会比较大，所以往往采取主动推送的模式，将热点数据主动推送到边缘节点。

##### 流媒体数据

对于流媒体来讲，很多CDN还提供预处理服务，也即文件在分发之前，经过一定的处理。

- 例如将视频转换为不同的码流，以适应不同的网络带宽的用户需求；
- 再如对视频进行分片，降低存储压力，也使得客户端可以选择使用不同的码率加载不同的分片。这就是我们常见的，“我要看超清、标清、流畅等”。

对于流媒体CDN来讲，有个关键的问题是**防盗链**问题。

###### 防盗链

- 最**常用**也最简单的方法就是**HTTP头的refer字段**， 当浏览器发送请求的时候，一般会带上referer，告诉服务器是从哪个页面链接过来的，服务器基于此可以获得一些信息用于处理。如果refer信息不是来自本站，就阻止访问或者跳到其它链接。refer的机制相对比较容易破解，所以还需要配合其他的机制。

- 一种常用的机制是**时间戳防盗链**。使用CDN的管理员可以在配置界面上，和CDN厂商约定一个加密字符串。
  客户端取出当前的时间戳，要访问的资源及其路径，连同加密字符串进行签名算法得到一个字符串，然后生成一个下载链接，带上这个签名字符串和截止时间戳去访问CDN。
  在CDN服务端，根据取出过期时间，和当前 CDN 节点时间进行比较，确认请求是否过期。然后CDN服务端有了资源及路径，时间戳，以及约定的加密字符串，根据相同的签名算法计算签名，如果匹配则一致，访问合法，才会将资源返回给客户。

##### 动态数据

有关生鲜的缓存就是非常麻烦的事情，这对应着就是动态的数据，比较难以缓存。现在也有动态CDN，主要有两种模式。

- 一种为生鲜超市模式，也即边缘计算的模式。既然数据是动态生成的，所以数据的逻辑计算和存储，也相应的放在边缘的节点。其中定时从源数据那里同步存储的数据，然后在边缘进行计算得到结果。就像对生鲜的烹饪是动态的，没办法事先做好缓存，因而将生鲜超市放在你家旁边，既能够送货上门，也能够现场烹饪，也是边缘计算的一种体现。
- 另一种是冷链运输模式，也即路径优化的模式。数据不是在边缘计算生成的，而是在源站生成的，但是数据的下发则可以通过CDN的网络，对路径进行优化。因为CDN节点较多，能够找到离源站很近的边缘节点，也能找到离用户很近的边缘节点。中间的链路完全由CDN来规划，选择一个更加可靠的路径，使用类似专线的方式进行访问。



### 数据中心

数据中心分为三层。服务器连接到接入层，然后是汇聚层，再然后是核心层，最外面是边界路由器和安全设备。

数据中心的入口和出口也是路由器，由于在数据中心的边界，就像在一个国家的边境，称为**边界路由器（Border Router）**。为了高可用，边界路由器会有多个。

既然是路由器，就需要跑路由协议，数据中心往往就是路由协议中的**自治区域（AS）**。数据中心里面的机器要想访问外面的网站，数据中心里面也是有对外提供服务的机器，都可以通过**BGP**协议，获取内外互通的路由信息。这就是我们常听到的**多线BGP**的概念。

这些交换机往往是放在机架顶端的，所以经常称为**TOR（Top Of Rack）交换机**。这一层的交换机常常称为**接入层**（Access Layer）。

当一个机架放不下的时候，就需要多个机架，还需要有交换机将多个机架连接在一起。这些交换机对性能的要求更高，带宽也更大。这些交换机称为**汇聚层交换机（Aggregation Layer）**。

数据中心里面的每一个连接都是需要考虑高可用的。所以，需要至少两个网卡、两个网线插到TOR交换机上，但是两个网卡要工作得像一张网卡一样，这就是常说的**网卡绑定（bond）**。

这就需要服务器和交换机都支持一种协议**LACP（Link Aggregation Control Protocol）**。它们互相通信，将多个网卡聚合称为一个网卡，多个网线聚合成一个网线，在网线之间可以进行负载均衡，也可以为了高可用作准备。

 ![img](.\企业微信截图_16365052239322.png) 

网卡有了高可用保证，但交换机还有问题。因而T **OR交换 机也需要高可用**，同理接入层和汇聚层的连接也需要高可用性，也不能单线连着。
最传统的方法是，部署两个接入交换机、两个汇聚交换机。服务器和两个接入交换机都连接，接入交换机和两个汇聚都连接，当然这样会形成环，所以需要启用**STP协议**，去除环，但是这样两个**汇聚就只能一主一备**了。STP协议里我们学过，只有一条路会起作用。

交换机有一种技术叫作**堆叠**，所以另一种方法是，将多个交换机形成一个逻辑的交换机，服务器通过多根线分配连到多个接入层交换机上，而接入层交换机多根线分别连接到多个交换机上，并且通过**堆叠的私有协议**，**形成双活**的连接方式。

 ![img](.\企业微信截图_16365054677003.png) 

汇聚层将大量的计算节点相互连接在一起，形成一个集群。在这个集群里面，服务器之间通过二层互通，这个区域常称为一个POD（Point Of Delivery），有时候也称为一个**可用区（AvailableZone）**。
当节点数目再多的时候，一个可用区放不下，需要将多个可用区连在一起，连接多个可用区的交换机称为**核心交换机**。

 ![img](.\企业微信截图_16365056498738.png) 

不同的可用区在不同的二层网络，需要分配不同的网段。汇聚和核心之间通过三层网络互通的，二层都不在一个广播域里面，不会存在二层环路的问题。三层有环是没有问题的，只要通过路由协议选择最佳的路径就可以了。

 ![img](.\企业微信截图_16365057299147.png) 

但是随着数据中心里面的机器越来越多，尤其是有了云计算、大数据，集群规模非常大，而且都要求在一个二层网络里面。这就**需要二层互连从汇聚层上升为核心层**，也即在核心以下，全部是二层互连，全部在一个广播域里面，这就是常说的**大二层**。

 ![img](.\企业微信截图_16365057755272.png) 

如果大二层横向流量不大，核心交换机数目不多，可以做堆叠，但是如果横向流量很大，仅仅堆叠满足不了，就需要部署多组核心交换机，而且要和汇聚层进行全互连。由于堆叠只解决一个核心交换机组内的无环问题，而组之间全互连，还需要其他机制进行解决。
如果是STP，那部署多组核心无法扩大横向流量的能力，因为还是只有一组起作用。
于是大二层就引入了**TRILL（Transparent Interconnection of Lots of Link ）**，即**多链接透明互联协议**。它的基本思想是，二层环有问题，三层环没有问题，那就把三层的路由能力模拟在二层实现。**运行TRILL协议的交换机称为RBridge，是具有路由转发特性的网桥设备，只不过这个路由是根据MAC地址来的，不是根据IP来的。**
Rbridage之间通过链路状态协议运作。记得这个路由协议吗？通过它可以学习整个大二层的拓扑，知道访问哪个MAC应该从哪个网桥走；还可以计算最短的路径，也可以通过等价的路由进行负载均衡和高可用性。

 ![img](.\企业微信截图_16365059451271.png) 

这是一个典型的**三层网络结构**。这里的三层不是指IP层，而是**指接入层、汇聚层、核心层三层**。这种模式非常有利于外部流量请求到内部应用。这个类型的流量，是从外到内或者从内到外，对应到上面那张图里，就是从上到下，从下到上，上北下南，所以**称为南北流量**。

但是随着云计算和大数据的发展，节点之间的交互越来越多，例如大数据计算经常要在不同的节点将数据拷贝来拷贝去，这样需要经过交换机，使得数据从左到右，从右到左，左西右东，所以称为东西流量。

为了解决东西流量的问题，演进出了**叶脊网络（Spine/Leaf）**。
**叶子交换机（leaf），直接连接物理服务器。**L2/L3网络的分界点在叶子交换机上，**叶子交换机之上是三层网络**。
**脊交换机（spine switch），相当于核心交换机。**叶脊之间通过ECMP动态选择多条路径。脊交换机现在只是为叶子交换机提供一个弹性的L3路由网络。南北流量可以不用直接从脊交换机发出，而是通过与leaf交换机并行的交换机，再接到边界路由器出去。

 ![img](.\企业微信截图_16365060321877.png) 

传统的三层网络架构是垂直的结构，而**叶脊网络架构是扁平的结构，更易于水平扩展**。



### VPN

需要将多个数据中心连接起来，或者需要办公室和数据中心连接起来的方法：

- 第一种方式是走公网，但是公网太不安全，你的隐私可能会被别人偷窥；
- 第二种方式是租用专线的方式把它们连起来，这是土豪的做法，需要花很多钱；
- 第三种方式是用VPN来连接，这种方法比较折中，安全又不贵。

 ![img](.\企业微信截图_16365071701992.png) 



#### vpn概念

**VPN**，全名**Virtual Private Network**，**虚拟专用网**，就是利用开放的公众网络，建立专用数据传输通道，将远程的分支机构、移动办公人员等连接起来。

VPN通过**隧道技术**在公众网络上仿真一条点到点的专线，是通过利用一种协议来传输另外一种协议的技 术，这里面涉及三种协议：**乘客协议、隧道协议和承载协议**。

我们以IPsec协议为例来说明。

 ![img](H:\code\learnning\jike_qutanwangluoxieyi\企业微信截图_16365074764368.png) 



#### IPsec VPN

**IPsec VPN**是**基于IP协议的安全隧道协议**，为了保证在公网上面信息的安全，因而采取了一定的机制保证安全性。

- 机制一：**私密性**，防止信息泄漏给未经授权的个人，通过加密把数据从明文变成无法读懂的密文，从而确保数据的私密性。采取**对称加密**(处理数据量大)和**因特网密钥交换**（**IKE**，Internet Key Exchange）协议（解决交换密钥问题）。
- 机制二：**完整性**，数据没有被非法篡改，通过对数据进行hash运算，产生类似于指纹的数据摘要，以保证数据的完整性。
- 机制三：**真实性**，数据确实是由特定的对端发出，通过身份认证可以保证数据的真实性。
  - 第一种方法就是预共享密钥；
  - 另外一种方法就是用数字签名来验证。使用私钥进行签名。

基于以上三个特性，组成了**IPsec VPN的协议簇**。这个协议簇内容比较丰富。

 ![img](H:\code\learnning\jike_qutanwangluoxieyi\企业微信截图_16365101271391.png) 

在这个协议簇里面，**有两种协议**，这两种协议的区别在于封装网络包的格式不一样。

- 一种协议称为**AH（Authentication Header**），只能进行数据摘要 ，不能实现数据加密。
- 还有一种**ESP（Encapsulating Security Payload）**，能够进行数据加密和数据摘要。

在这个协议簇里面，还有**两类算法**，分别是**加密算法**和**摘要算法**。
 这个协议簇还包含**两大组件**：

- 一个用于VPN的双方要进行**对称密钥的交换**的**IKE组件**；
- 一个是VPN的**双方要对连接进行维护**的**SA（Security Association）组件**。



##### IPsec VPN的建立过程

第一个阶段，**建立IKE自己的SA**。在这个阶段，通过DH（Diffe-Hellman）算法计算出一个对称密钥K。

 ![img](H:\code\learnning\jike_qutanwangluoxieyi\企业微信截图_16365115963622.png) 



接下来是第二个阶段，**建立IPsec SA**。在这个SA里面，双方会生成一个随机的对称密钥M，由K加密传给对方，然后使用M进行双方接下来通信的数据。对称密钥M是有过期时间的，会过一段时间，重新生成一次，从而防止被破解。

IPsec SA里面有以下内容：

- SPI（Security Parameter Index），用于标识不同的连接；
- 双方商量好的加密算法、哈希算法和封装模式；
- 生存周期，超过这个周期，就需要重新生成一个IPsec SA，重新生成对称密钥。

 ![img](H:\code\learnning\jike_qutanwangluoxieyi\企业微信截图_16365116669656.png) 

两个阶段建立的图示。



 有了IPsec VPN之后，客户端发送的明文的IP包，都会被加上ESP头和IP头，在公网上传输，由于加密，可以保证不被窃取，到了对端后，去掉ESP的头，进行解密。![img](H:\code\learnning\jike_qutanwangluoxieyi\企业微信截图_16365118367120.png) 

左面是原始的IP包，在IP头里面，会指定上一层的协议为TCP。ESP要对IP包进行封装，因而IP头里面的上一层协议为ESP。在ESP的正文里面，ESP的头部有双方商讨好的SPI，以及这次传输的序列号。

这种点对点的基于IP的VPN，能满足互通的要求，但是速度往往比较慢，这是由底层IP协议的特性决定的。IP不是面向连接的，是尽力而为的协议，每个IP包自由选择路径，到每一个路由器，都自己去找下一跳，丢了就丢了，是靠上一层TCP的重发来保证可靠性。

和IP对应的另一种技术称为**ATM**。这种协议和IP协议的不同在于，它是面向连接的。你可以说TCP也是面向连接的啊。这两个不同，ATM和IP是一个层次的，和TCP不是一个层次的。

好处是不需要每次都查路由表的，虚拟路径已经建立，打上了标签，后续的包傻傻的跟着走就是了，坏处是一旦虚拟路径上的某个路由器坏了，则这个连接就断了，什么也发不过去了，因为其他的包还会按照原来的路径走。

#### 多协议标签交换MPLS

是多协议标签交换（MPLS，**Multi-Protocol Label Switchin**g）。MPLS的格式如图所示，在原始的IP头之外，多了MPLS的头，里面可以打标签。

有了标签，还需要设备认这个标签，并且能够根据这个标签转发，这种能够转发标签的路由器称为标签交换路由器（LSR，Label Switching Router）。

这种路由器会有两个表格，一个就是传统的FIB，也即路由表，另一个就是LFIB，标签转发表。有了这两个表，既可以进行普通的路由转发，也可以进行基于标签的转发。

 ![img](H:\code\learnning\jike_qutanwangluoxieyi\企业微信截图_1636512219678.png) 

这里我们区分MPLS区域和非MPLS区域。在MPLS区域中间，使用标签进行转发，非MPLS区域，使用普通路由转发，在边缘节点上，需要有能力将对于普通路由的转发，变成对于标签的转发。

这样一个通过标签转换而建立的路径称为LSP，标签交换路径。在一条LSP上，沿数据包传送的方向，



相邻的LSR分别叫上游LSR（upstream LSR）和下游LSR（downstream LSR）。
有了标签，转发是很简单的事，但是如何生成标签，却是MPLS中最难修炼的部分。在MPLS秘笈中，这部分被称为LDP（Label Distribution Protocol），是一个动态的生成标签的协议。
其实LDP与IP帮派中的路由协议十分相像，通过LSR的交互，互相告知去哪里应该打哪个标签，称为标签分发，往往是从下游开始的。

![1636512725156](H:\code\learnning\jike_qutanwangluoxieyi\1636512725156.png)

如果有一个边缘节点发现自己的路由表中出现了新的目的地址，它就要给别人说，我能到达一条新的路径了。
如果此边缘节点存在上游LSR，并且尚有可供分配的标签，则该节点为新的路径分配标签，并向上游发出标签映射消息，其中包含分配的标签等信息。
收到标签映射消息的LSR记录相应的标签映射信息，在其标签转发表中增加相应的条目。此LSR为它的上游LSR分配标签，并继续向上游LSR发送标签映射消息。
当入口LSR收到标签映射消息时，在标签转发表中增加相应的条目。这时，就完成了LSP的建立。有了标签，转发轻松多了。





####  MPLS VPN![img](H:\code\learnning\jike_qutanwangluoxieyi\企业微信截图_16365127679481.png) 



在MPLS VPN中，网络中的路由器分成以下几类：

- PE（Provider Edge）：运营商网络与客户网络相连的边缘网络设备；
- CE（Customer Edge）：客户网络与PE相连接的边缘设备；
- P（Provider）：这里特指运营商网络中除PE之外的其他运营商网络设备。



PE路由器之间使用特殊的MP-BGP来发布VPN路由，在相互沟通的消息中，在一般32位IPv4的地址之前加上一个客户标示的区分符用于客户地址的区分，这种称为VPN-IPv4地址族，这样PE路由器会收到如下的消息，机构A的192.168.101.0/24应该往这面走，机构B的192.168.101.0/24则应该去另外一个方向。



在PE上，可以通过VRF（VPN Routing&Forwarding Instance）建立每个客户一个路由表，与其它VPN客户路由和普通路由相互区分。可以理解为专属于客户的小路由器。
远端PE通过MP-BGP协议把业务路由放到近端PE，近端PE根据不同的客户选择出相关客户的业务路由放到相应的VRF路由表中。

VPN报文转发采用两层标签方式：

- 第一层（外层）标签在骨干网内部进行交换，指示从PE到对端PE的一条LSP。VPN报文利用这层标签，可以沿LSP到达对端PE；
- 第二层（内层）标签在从对端PE到达CE时使用，在PE上，通过查找VRF表项，指示报文应被送到哪个VPN用户，或者更具体一些，到达哪一个CE。这样，对端PE根据内层标签可以找到转发报文的接口。

![img](H:\code\learnning\jike_qutanwangluoxieyi\企业微信截图_16365128901829.png) 



我们来举一个例子，看MPLS VPN的包发送过程。
1. 机构A和机构B都发出一个目的地址为192.168.101.0/24的IP报文，分别由各自的CE将报文发送
至PE。
2. PE会根据报文到达的接口及目的地址查找VPN实例表项VRF，匹配后将报文转发出去，同时打上内
层和外层两个标签。假设通过MP-BGP配置的路由，两个报文在骨干网走相同的路径。
3. MPLS网络利用报文的外层标签，将报文传送到出口PE，报文在到达出口PE 2前一跳时已经被剥离
外层标签，仅含内层标签。
4. 出口PE根据内层标签和目的地址查找VPN实例表项VRF，确定报文的出接口，将报文转发至各自
的CE。
5. CE根据正常的IP转发过程将报文传送到目的地。





