## 一、linux相关



### 1. 常用linux系统调用

系统调用（System Call）是操作系统为在用户态运行的进程与**硬件设备（如CPU、磁盘、打印机等）进行交互**提供的一组接口。当用户进程需要发生系统调用时，CPU 通过软中断切换到内核态开始执行内核系统调用函数

**系统调用在内核里的主要用途**。虽然给出了数种分类，不过总的概括来讲系统调用主要在系统中的用途无非以下几类：

- **控制硬件**——系统调用往往作为硬件资源和用户空间的抽象接口，比如读写文件时用到的write/read调用。

- **设置系统状态或读取内核数据**——因为系统调用是用户空间和内核的唯一通讯手段[2]，所以用户设置系统状态，比如开/关某项内核服务（设置某个内核变量），或读取内核数据都必须通过系统调用。比如getpgid、getpriority、setpriority、sethostname

- **进程管理**——一系列调用接口是用来保证系统中进程能以多任务，在虚拟内存环境下得以运行。比如 fork、clone、execve、exit等

**什么功能应该实现在内核而不是在用户空间**

- 服务必须获得内核数据，比如一些服务必须获得中断或系统时间等内核数据。

- 从安全角度考虑，在内核中提供的服务相比用户空间提供的毫无疑问更安全，很难被非法访问到。

- 从效率考虑，在内核实现服务避免了和用户空间来回传递数据以及保护现场等步骤，因此效率往往要比实现在用户空间高许多。比如,httpd等服务。

- 如果内核和用户空间都需要使用该服务，那么最好实现在内核空间，比如随机数产生。



信号：kill、signal/sigpending/sigsuspend/

管道：pipe

socket控制：socket/bind/connect/accept/send/listen/select/shutdown/setsockopt

用户管理：getuid/setuid/getgid/setgid/

网络管理：gethostname/sethostname/setdomainname/getdomainname/gethostid/sethostid

系统控制：reboot/time/uname/

文件系统控制：open/creat/close/read/write/readv/writev/pread/poll/truncate/access/stat/chown/chmod/chdir/rename/mkdir/mount/unmount/

进程控制：fork/clone/exit/execve/setpgid/getpid/getppid/nice/pause/ptrace/wait/wait3/waitpid/setsid/getsid

#### open

在用户态使用open()时，必须向该函数传入文件路径和打开权限。这两个参数传入内核后，内核首先检查这个文件路径存在的合法性，同时还需检查使用者是否有合法权限打开该文件。如果一切顺利，那么内核将对访问该文件的进程创建一个file结构。

在用户态，通常open()在操作成功时返回的是一个非负整数，即所谓的文件描述符（fd，file descriptor）；并且，用户态后续对文件的读写操作等都是通过fd来完成的。由此可见fd与file结构在内核中有一定的关联。

内核使用进程描述符task_struct来描述一个进程，而该进程所有已打开文件对应的file结构将形成一个数组files（其为files_struct结构），内核向用户返回的fd便是该数组中具体file结构的索引。默认情况下，每个进程创建后都已打开了标准输入文件、标准输出文件、标准错误文件，因此他们的文件描述符依次为0、1和2。



参考连接：https://www.cnblogs.com/shijiaqi1066/p/5749030.html





### 2. 进程、线程、协程、绿色线程



1. 进程：是一个正在执行的程序的实例。每个进程都有独立的内存空间，可以同时执行多个进程来完成不同的任务，进程是操作系统进行资源分配和调度的基本单位。
2. 线程：是进程中的一个执行路径，不同的线程可以同时执行在同一个进程内，共享该进程的内存资源。线程之间的切换开销比进程小，但线程需要考虑同步和互斥的问题。
3. 协程：是一种轻量级的线程，可以在单线程内实现多个任务的并发执行，也可以通过多进程来实现并发。协程之间的切换开销很小，通常使用非抢占式调度方式，需要手动控制任务的切换。



1. 进程之间通信需要IPC机制，线程之间通信可以使用共享内存，协程之间通信可以使用全局变量。不同的进程之间需要通过进程间通信（IPC）机制来进行数据交换；线程之间可以直接访问共享内存进行数据交换；协程之间可以使用全局变量等方式进行数据交换。
2. 进程切换开销较大，线程切换开销比进程小，协程切换开销最小。由于进程之间相互独立，因此进程切换的开销较大；线程切换的开销要比进程小，但需要考虑同步和互斥的问题；协程切换的开销最小，通常使用非抢占式调度方式，需要手动控制任务的切换。
3. 进程数受限于硬件资源，线程数受限于进程内存空间，协程数无限制。由于每个进程都有独立的内存空间，因此进程数量是受限于硬件资源的；线程共享进程内存空间，因此线程数量是受限于进程内存空间的，而协程数量没有限制。





绿色线程

通常使用第三方库（如gevent、eventlet等）来实现，因为Python标准库中没有原生支持绿色线程的机制。绿色线程使用的是替换调度器的方式，在一个线程内模拟多个线程之间的切换，实现异步非阻塞的目的。

协程

则是在Python标准库中有原生支持的概念，通常使用async/await语法结合asyncio库来实现。协程通过使用事件循环（Event Loop）和异步IO等机制来实现非阻塞的并发执行。



IPC（Inter-Process Communication，进程间通信）是指不同进程之间进行数据交换和协作的机制。在操作系统中，进程之间有时需要共享数据、资源或者通知对方做一些操作，这时就需要使用IPC机制。

常见的IPC机制包括：

1. 管道（Pipe）：是一种半双工的通信方式，可以实现父子进程或兄弟进程之间的通信。管道有两种，一种是匿名管道，只能用于父子进程间的内部通信；另一种是命名管道，可以在不同进程之间通信。
2. 信号量（Semaphore）：是一个计数器，用于多个进程之间的同步和互斥操作。通过对信号量的P操作和V操作来实现进程之间的同步和互斥。
3. 共享内存（Shared Memory）：是指多个进程共享同一块物理内存，并且可以相互访问。可以通过共享内存来提高进程间的通信效率。
4. 套接字（Socket）：是一种计算机之间网络通信的机制，不仅可以在同一台计算机上的进程之间通信，也可以在不同计算机之间通信。
5. 消息队列（Message Queue）：是一种存放消息的队列，被多个进程共享。每个消息都有一个类型，接收进程可以选择性地接收某一类型的消息。
6. 信号（Signal）：是异步通知的一种方式，可以在进程中发送软件中断信号，让接收进程进行相应的处理。

不同的IPC机制各有优劣，需要根据具体的应用场景来选择合适的机制。







### 3. poll/epoll/select



**不同操作系统中IO多路复用模型介绍**

 

#### 3.1 select机制

 IO多路复用模型得以实现得核心：就是操作系统 监控1个[sk......conn,]列表，不断轮询每1个sk/conn/是否可以accpet/revive，随着监控列表的增加，效率会递减；

select函数监视的文件描述符分为3类，分别是writefds、readfds和exceptfds。调用后select函数会被阻塞，直到有描述符就绪（有数据可读、可写或者有except）、或者超时(timeout可用于指定等待时间，如果想立即返回可设置为null)，函数返回。当select函数返回后，可以通过遍历fdset来找到就绪的描述符。

> 在网络编程中统一的操作顺序是创建socket－>绑定端口－>监听－>accept->write/read,当有客户端连接到来时,select会把该连接的文件描述符放到fd_set（一组文件描述符(fd)的集合）,然后select会循环遍历它所监测的fd_set内的所有文件描述符，当select循环遍历完所有fd_set内指定的文件描述符对应的poll函数后，如果没有一个资源可用(即没有一个文件可供操作)，则select让该进程睡眠，一直等到有资源可用为止，fd_set是一个类似于数组的数据结构，由于它每次都要遍历整个数组，所有她的效率会随着文件描述符的数量增多而明显的变慢，除此之外在每次遍历这些描述符之前，系统还需要把这些描述符集合从内核copy到用户空间，然后再copy回去，如果此时没有一个描述符有事件发生（例如：read和write）这些copy操作和便利操作都是无用功，可见slect随着连接数量的增多，效率大大降低。可见如果在高并发的场景下select并不适用，况且select默认的最大描述符为1024，如果想要更多还要做响应参数的配置。



![img](./select模型.png)



1. **最大限制**：单个进程能够监视的文件描述符的数量存在最大限制。(基于数组存储的赶脚)一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。它由FD_SETSIZE设置，32位机默认是1024个。64位机默认是2048.
2. **时间复杂度：** 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低，时间复杂度O(n)。
   当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。
   它仅仅知道有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。
3. **内存拷贝：**需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。



**支持操作系统**：linux/windows

 

#### 3.2 poll机制

不同于select使用三个位图来表示三个fdset的方式，poll使用一个pollfd指针来实现。pollfd结构包含了要监视的event和发生的event，不再使用select的“参数-值”传递的方式。同时pollfd并没有最大数量限制（但是数量过大后其性能也会降低）。和select函数一样，poll返回后需要轮询pollfd来获取就绪的描述符。

**没有最大连接数的限制**。（基于链表来存储的）

**支持操作系统**：linux

 

#### 3.3 epoll机制

##### epoll原理与流程

1.epoll很高级，epoll不会去再通过操作循环检查监控的socket列表中，那些socket出现了读操作，而是给需要监听的socket 1--1绑定1个回调函数；

2.检测的socket中 有1个soket出现了读操作，直接执行调用那个和该sk/con绑定的回调函数执行sk.accpet() 和conn.receve()

> ###### epoll基本流程
>
> **一棵红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。**
>
> 1. 执行 epoll_create
>    内核在epoll文件系统中建了个file结点，（使用完，必须调用close()关闭，否则导致fd被耗尽）
>    在内核cache里建了红黑树存储epoll_ctl传来的socket，
>    在内核cache里建了rdllist双向链表存储准备就绪的事件。
> 2. 执行 epoll_ctl
>    如果增加socket句柄，检查红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，告诉内核如果这个句柄的中断到了，就把它放到准备就绪list链表里。
>    ps：所有添加到epoll中的事件都会与设备（如网卡）驱动程序简历回调关系，相应的事件发生时，会调用回调方法。
> 3. 执行 epoll_wait
>    立刻返回准备就绪表里的数据即可（将内核cache里双向列表中存储的准备就绪的事件 复制到用户态内存）
>    当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。
>    如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。



##### epoll基本特点

1. **边缘触发**，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。
2. **事件驱动，**每个事件关联上fd，使用事件就绪通知方式，通过 epoll_ctl 注册 fd，一旦该fd就绪，内核就会采用 callback 的回调机制来激活该fd，epoll_wait 便可以收到通知。

1. **没有最大连接数的限制**。（基于 红黑树+双链表 来存储的:1G的内存上能监听约10万个端口）
2. **时间复杂度低：** 边缘触发和事件驱动，监听回调，时间复杂度O(1)。
   只有活跃可用的fd才会调用callback函数；即epoll最大的优点就在于它只管“活跃”的连接，而跟连接总数无关，因此实际网络环境中，Epoll的效率就会远远高于select和poll。
3. **内存拷贝：**利用mmap()文件映射内存加速与内核空间的消息传递，减少拷贝开销。



##### epoll两种模式(LT/ET)

epoll对文件描述符的操作有两种模式：LT(level trigger) 和 ET(edge trigger)。LT是默认的模式，ET是“高速”模式。

- LT（水平触发）模式下，只要有数据就触发，缓冲区剩余未读尽的数据会导致 epoll_wait都会返回它的事件；
- ET（边缘触发）模式下，只有新数据到来才触发，不管缓存区中是否还有数据，缓冲区剩余未读尽的数据不会导致epoll_wait返回



##### 适合用epoll的应用场景：

- 对于连接特别多，活跃的连接特别少(大量的idle-connection)
- 典型的应用场景为一个需要处理上万的连接服务器，例如各种app的入口服务器，例如qq

##### 不适合epoll的场景：

- 连接比较少，数据量比较大，例如ssh (没有大量的idle-connection或者dead-connection)
  epoll 的惊群问题：
  因为epoll 多用于多个连接，只有少数活跃的场景，但是万一某一时刻，epoll 等的上千个文件描述符都就绪了，这时候epoll 要进行大量的I/O，此时压力太大。



Python中的selectors模块就是帮我们自动选择最佳IO多路复用代理的；



### 2.1.Event Loop的惊群效应

通过查阅资料发现`Linux`通过`WQ_FLAG_EXCLUSIVE`标记解决了`socket.accept`的惊群问题， 但是现在很多服务通过基于事件循环的方法来提供更高的并发能力。比如我线上运行的服务就是用到了**`Gevent`，而`Gevent`用到的核心事件循环则是`Epoll`**，它与`Select`, `Poll`并称为`Event Loop`。

对于任何工作模式来说， 使用`Event Loop`后，进程调用`socket.accept`后的行为逻辑就不一样了，具体的逻辑步骤如下：

- 1.进程在调用`socket.accept`时，`Event Loop`会把进程挂在`socket`对应的文件描述符的等待队列上。
- 2.当`socket`的文件描述符有事件产生时，对应的驱动就会将等待队列上对应的进程进行唤醒。
- 3.被唤醒的进程会通过`Event Loop`检查事件是否就绪，如果事件就绪就会返回对应的事件给刚才的进程。
- 4.检查`accept`事件是否可调用， 如果可以就执行`accept`操作，并取得该四元组的对应`socket`。

可以看到，之前进程是挂在网络驱动上等着被内核唤醒，而在使用`Event Loop`后进程是挂在对应文件描述符的等待队列上等待被`Event Loop`唤醒，对于`Pre-Worker`模型下的每个工作进程虽然都有自己专属的`Event Loop`，但是他们都是等待着同样的资源，于是当该文件描述符有事件产生时，就会唤醒所有工作进程对应的`Event Loop`来检查事件以及判断是否可以返回事件给工作进程, 而且由于是通过`Event Loop`的逻辑来执行`socket.accept`，这样会绕过上面所说的`WQ_FLAG_EXCLUSIVE`标记的限制，从而又产生了惊群效应。

可以看到，`Event Loop`产生惊群效应的原因跟进程直接调用`sock.accept`十分的像，所以他们的解决思路也很像，首先是给`Event Loop`增加一个名为`EPOLLEXCLUSIVE`的标记， 然后开发者在编程时可以在`Event Loop`实例化后注册对应的标记,当进程在调用`sock.accept`且系统检到`Event Loop`带有该标记时，就会把进程挂在文件描述符的队列尾部，等到事件产生时，**内核会只唤醒该队列的第一个进程来处理对应的事件。**

> 关于标记`EPOLLEXCLUSIVE`的具体内容可见:[Add epoll round robin wakeup mode](https://link.juejin.cn?target=https%3A%2F%2Flwn.net%2FArticles%2F632590%2F)， 通过内容还可以知道还有一个标记`EPOLLROUNDROBIN`用来解决唤醒不均衡的情况，但是在`Python`中似乎没办法使用。



☆☆☆参考连接：https://juejin.cn/post/7082005823328632839



### 4. pre-worker服务模型

包含nginx 、gunicorn/gevent/event loop/惊群现象及解决方法

tcp三种工作模式

负载不均衡问题

（gevent/**asyncio**，）

由于之前一直在使用`Asyncio`，所以我知道`Event Loop`在收到对应文件描述符的事件时，它不是以雨露均沾的方式去唤醒进程/线程/协程，而是**会优先唤醒第一个注册的进程/线程/协程，只有第一个进程/线程/协程繁忙的情况下才会去唤醒后面的进程/线程/协程，造成了唤醒倾斜的问题**，所以我猜测是这个规则引发了负载不均衡的问题。



☆☆☆参考连接：https://juejin.cn/post/7082005823328632839



### 5. nginx的惊群现象

首先，我们先大概梳理一下 Nginx 的网络架构，几个关键步骤为：

1. Nginx 主进程解析配置文件，根据 listen 指令，将监听套接字初始化到全局变量 ngx_cycle 的 listening 数组之中。此时，监听套接字的创建、绑定工作早已完成。
2. Nginx 主进程 fork 出多个子进程。
3. 每个子进程在 ngx_worker_process_init 方法里依次调用各个 Nginx 模块的 init_process 钩子，其中当然也包括 NGX_EVENT_MODULE 类型的 ngx_event_core_module 模块，其 init_process 钩子为 ngx_event_process_init。
4. ngx_event_process_init 函数会初始化 Nginx 内部的连接池，并把 ngx_cycle 里的监听套接字数组通过连接池来获得相应的表示连接的 ngx_connection_t 数据结构，这里关于 Nginx 的连接池先略过。我们主要看 ngx_event_process_init 函数所做的另一个工作：如果在配置文件里**没有**开启 [accept_mutex 锁](http://nginx.org/en/docs/ngx_core_module.html#accept_mutex)，就通过 ngx_add_event 将所有的监听套接字添加到 epoll 中。
5. 每一个 Nginx 子进程在执行完 ngx_worker_process_init 后，会在一个死循环中执行 ngx_process_events_and_timers，这就进入到事件处理的核心逻辑了。
6. 在 ngx_process_events_and_timers 中，如果在配置文件里开启了 accept_mutext 锁，子进程就会去获取 accet_mutext 锁。如果获取成功，则通过 ngx_enable_accept_events 将监听套接字添加到 epoll 中，否则，不会将监听套接字添加到 epoll 中，甚至有可能会调用 ngx_disable_accept_events 将监听套接字从 epoll 中删除（如果在之前的连接中，本worker子进程已经获得过accept_mutex锁)。
7. ngx_process_events_and_timers 继续调用 ngx_process_events，在这个函数里面阻塞调用 epoll_wait。

至此，关于 Nginx 如何处理 fork 后的监听套接字，我们已经差不多理清楚了，当然还有一些细节略过了，比如在每个 Nginx 在获取 accept_mutex 锁前，还会根据当前负载来判断是否参与 accept_mutex 锁的争夺。

把这个过程理清了之后，Nginx 解决惊群问题的方法也就出来了，就是利用 accept_mutex 这把锁。

**如果配置文件中没有开启 accept_mutex，则所有的监听套接字不管三七二十一，都加入到每子个进程的 epoll 中，这样当一个新的连接来到时，所有的 worker 子进程都会惊醒。**

**如果配置文件中开启了 accept_mutex，则只有一个子进程会将监听套接字添加到 epoll 中，这样当一个新的连接来到时，当然就只有一个 worker 子进程会被唤醒了。**



### 6. ifconfig参数解释

```
ifconfig
ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
inet 192.168.1.63 netmask 255.255.255.0 broadcast 192.168.1.255
inet6 fe80::c09d:975d:89cd:fd3f prefixlen 64 scopeid 0x20
ether 00:0c:29:02:83:db txqueuelen 1000 (Ethernet)
RX packets 3255 bytes 4458479 (4.2 MiB)
RX errors 0 dropped 26 overruns 0 frame 0
TX packets 1130 bytes 81645 (79.7 KiB)
TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0

上图信息大概说明：
第一行：up–>网卡开启状态
RUNNING–>网线处理连接状态
MULTICAST–>支持组播
mtu 1500–>（Maximum Transmission Unit）最大传输单元大小为1500字节
第二行：该网卡的IP地址，子网掩码，广播地址
第三行：IPV6的配置信息
第四行：网卡的MAC地址
ether表示连接类型为以太网
txqueuelen 1000 --》传输队列的长度
第五六行：网卡接收数据包的统计信息和接收错误的统计信息
第七八行：网卡发送数据包的统计信息和发送错误的统计信息
```

















常见进程调度算法





操作系统如何申请及管理内存





同步、阻塞、异步、并发、非阻塞、并行



nginx惊群现象 







## 二、网络相关





### 2.1. 三次握手、四次挥手

为什么是三次握手、不是两次握手，

参考-learnning\jike_qutanwangluoxieyi/网络学习





http与https





tcp与udp特点，区别



http网页，从请求到响应。 都走了那些步骤、（dns）

如果设置代理(外网代理)，请求有何不同





dns



http keepalive 和 tcp  keepalive





syn攻击、半连接



进程间如何通信



python的底层网络交互模块有哪些



OSI七层协议



## 三、数据库相关

### mysql



mysql引擎，各个引擎之间有什么区别



数据库事务，及其特性



数据库事务隔离级别有哪些、区别与特点



死锁发生的情况，如何解决



索引的原理

mysql  B+索引、优缺点

mysql索引类型

聚簇索引和非聚簇索引

唯一索引和普通索引区别，使用索引有哪些优缺点

myql索引什么情况下会失效





mysql主从同步机制



数据库的ACID



如何开启慢查询日志



数据库的脏读、幻读、幻行的原理、发生场景，及解决方式





serializable 序列化、最好的事务级别



#### 乐观锁、悲观锁

悲观锁, 每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

乐观锁，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制，乐观锁适用于多读的应用类型，这样可以提高吞吐量。





#### sql注入原理，

SQL注入（SQL Injection）是一种常见的Web应用程序安全漏洞，攻击者通过对Web应用程序的输入参数或其他可控制的变量注入恶意的SQL代码，从而达到非法获取、篡改、删除敏感数据等目的。

具体来说，SQL注入是指攻击者在提交的请求中，通过构造特定的字符串，欺骗服务器，使其将命令当作SQL语句来执行。比如，攻击者可以通过在表单中输入特殊字符，从而改变SQL查询的含义，使查询返回所有用户信息，而不仅仅是当前用户的信息。

```
如果用户搜索字符串为 Tom，则在后台生成的SQL查询语句为：
SELECT * FROM users WHERE name = 'Tom'
然而，如果黑客输入字符串：' or '1'='1 这就是一个典型的SQL注入攻击，这个字符串会被拼接到原始的SQL查询中，构造出下面的恶意查询语句：
SELECT * FROM users WHERE name = '' or '1'='1'
```

在 Python 中使用特殊的函数将用户输入值进行转义或对用户输入值中的引号等进行转义作为字符串而不是符号达到要求，可以使用一些库的方法，如 MySQLdb 库的 `escape_string()` 方法或 psycopg2 库的 `sql.Identifier()` 和 `sql.Literal()` 方法。







数据库的优化













### 3.2 redis

#### 3.2.1 redis单线程

Redis采用单线程，那么它是如何处理多个客户端连接请求呢？

Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

下图就是基于多路复用的 Redis IO 模型。图中的多个 FD 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。

![img](./redis-io.png)

参考链接：https://www.cnblogs.com/databasepub/p/16691115.html



Redis使用单线程模型，没有了线程上下文切换和访问共享资源加锁的性能损耗，配合IO多路复用技术，可以完成多个连接的请求处理。而且正是由于它的使用定位是内存数据库，这样几乎所有的操作都在内存中完成，它的性能可以达到非常之高。

**Redis 6.0 版本为什么又引入了多线程，这里也解释下。**

Redis 的性能瓶颈不在 CPU ，而在内存和网络，内存不够可以增加内存或通过数据结构等进行优化；但 Redis 的网络 IO 的读写占用了大部分 CPU 的时间，如果可以把网络处理改成多线程的方式，性能会有很大提升。所以总结下 Redis 6.0 版本引入多线程有两个原因：1.充分利用服务器的多核资源 2.多线程分摊 Redis 同步 IO 读写负荷

**注意：执行命令还是由单线程顺序执行，只是处理网络数据读写采用了多线程，而且 IO 线程要么同时读 Socket ，要么同时写 Socket ，不会同时读写。**











redis如何解决雪崩、缓存击穿、



redis 持久化中rdb和 aof方案的优缺点











## 四、python相关



### 交集差集并集

```
python
list1 = [1, 2, 3, 4, 5]
list2 = [4, 5, 6, 7, 8]


# 求交集
set1 = set(list1)
set2 = set(list2)
intersection = set1 & set2  # 或者使用 set1.intersection(set2)
print(intersection)  # 输出 {4, 5}


# 求差集
difference = set1 - set2  # 或者使用 set1.difference(set2)
print(difference)  # 输出 {1, 2, 3}


# 求对称差集
result = set1 ^ set2
print(result)  # {1, 2, 3, 6, 7, 8}
# 使用 symmetric_difference() 方法
# result = set1.symmetric_difference(set2)


# 求并集
union = set1 | set2  # 或者使用 set1.union(set2)
print(union)  # 输出 {1, 2, 3, 4, 5, 6, 7, 8}
```



### python垃圾回收机制

Python 的垃圾回收机制主要是基于引用计数和循环垃圾收集两种方式。

#### 引用计数

 在 Python 中，每个对象都有一个整数计数器，表示该对象的引用数。当对象被引用时，引用数加1；当引用被删除时，引用数减1。当引用数归零时，Python 会自动回收这个对象的内存空间。



引用的含义：在 Python 中，引用是一个指向对象的指针。当您创建一个变量并将其赋值给某个对象时，实际上是创建了一个指针，该指针指向该对象的内存位置。通过在变量中保留对该内存位置的引用，您可以在程序的其他部分使用对象。

python垃圾回收主要以引用计数为主，标记-清除和分代清除为辅的机制，其中标记-清除和分代回收主要是为了处理循环引用的难题。

#### 循环垃圾收集

引用计数虽然简单高效，但并不能完全解决内存泄漏的问题。

两个对象相互引用的情况是一种循环引用（Circular Reference）的情形。在这种情况下，每个对象的引用计数都不为零，因为它们相互引用对方，无法被垃圾回收机制回收。

为了解决这个问题，Python 还提供了一种循环垃圾收集机制。

标记-清除（Mark and Sweep）和分代清除（Generational Collection）都是常见的垃圾回收算法，用于在编程语言中自动释放内存空间，保证程序的稳定性和可靠性。

标记-清除算法通过遍历对象图，标记所有活动对象，并清除所有未被标记的垃圾对象。该算法消耗的时间较长，但可以处理任意形式的内存分配，适合于垃圾散布比较均匀的情况。缺点是在清除垃圾后可能会产生大量的碎片，导致内存利用率降低。

分代清除算法则将内存分成几个不同的区域，根据对象的存活时间和垃圾回收的频度将其分为不同的代。通常，只有在经过多次垃圾回收仍然存活的对象才会升级到更高的代。这样，对于不同代的对象，采取不同的垃圾回收策略，可以极大地提高垃圾回收效率。例如，对于生命周期较短的对象，可以采用标记-清除算法进行回收；对于生命周期较长的对象，则通过移动、整理等方式进行回收。该算法相对于标记-清除算法来说，具有更好的性能和空间利用率。

在 Python 中，所有的对象都有一个内部计数器，记录着当前被多少个变量引用着。在循环垃圾回收机制中，它会从一些特殊的地方开始扫描对象，这些地方称为“根”。比如，全局变量、当前执行代码的函数等都是根。然后，从这些根开始，回收机制会递归地访问所有能够访问到的对象，将它们标记为活动对象，也就是正在使用中的对象。而对于那些没有被标记的对象，则说明它们不再被使用，可以被清理掉。

在遍历对象图的过程中，当循环垃圾回收机制发现两个或多个对象之间相互引用，形成了一个环形结构时，就会将它们都标记为活动对象，不会被清理掉。同时，在后续的标记-清除过程中，如果回收机制发现某个对象被标记为垃圾，但它引用着其他的活动对象，那么就可以推断出这是一个循环引用，可以采取特殊的回收策略将其处理掉。

总之，在 Python 中，垃圾回收机制是通过引用计数和循环垃圾收集两种方式实现的，它们共同工作，确保内存空间被有效地回收和管理。



### with

在 Python 中，`with` 是一种上下文管理器，它可以在代码块开始之前执行一些操作，在结束时做一些清理工作。`with` 语句的语法格式如下：

```
pythonCopy Codewith context_expression [as target(s)]:
    with-block
```

其中 `context_expression` 表示一个上下文管理器对象，该对象必须实现 `__enter__()` 和 `__exit__()` 方法，这两个方法分别在进入和离开 `with` 块时被调用。 `as target(s)` 可选，表示将 `context_expression.__enter__()` 方法返回的值绑定到某个变量或元组上。

`with` 语句可以帮助程序员避免对资源的手动管理和释放，例如打开一个文件、建立一个数据库连接等。相应的代码可以写成如下形式：

```
pythonCopy Code# 1. 使用 with 打开文件
with open("hello.txt", "w") as f:
    f.write("Hello, World!")

# 2. 使用 with 建立数据库连接
import psycopg2

with psycopg2.connect(database="mydb", user="myuser", password="mypassword") as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM mytable")
```

在上述示例中，使用 `with` 打开文件时，当代码块执行结束时，Python 会自动关闭文件，无需手动调用 `close()` 方法；使用 `with` 建立数据库连接也类似，当程序执行完毕，Python 会自动关闭数据库连接。







### restfull和rpc区别与联系

RESTful 和 RPC（Remote Procedure Call）都是常用的网络通信协议，但它们有一些区别和联系。

首先，RESTful 是建立在 HTTP 协议之上的一种软件架构风格，它使用 URL 来标识资源，通过 HTTP 方法来对资源进行操作，包括 GET、POST、PUT、DELETE 等。RESTful 的设计思想是基于客户端和服务器之间的无状态通信，服务器不保存客户端的状态并且以资源为中心，充分利用 HTTP 的缓存、代理等机制，提高网络效率。RESTful 通常被用于 Web API 的开发，其良好的可读性和可扩展性使其逐渐成为 Web 应用程序的主要开发模式。

RPC 是远程过程调用协议，它允许程序在本地或远程系统上调用一个函数或方法，就像本地调用一样，屏蔽了底层通信细节，使得网络通信透明化、简化化。RPC 协议传输的是请求和响应的数据，可以通过多种传输协议实现，如 TCP、HTTP、UDP 等。RPC 协议具有更高的效率和更小的网络开销，因此多被用于传输大型数据和复杂的计算任务。

下面是 RESTful 和 RPC 的区别和联系：

1. RESTful 和 RPC 的通信方式不同。RESTful 是面向资源的，客户端使用 HTTP 方法（如 GET、POST、PUT、DELETE 等）来对服务器上的资源进行操作。RPC 是面向函数的，客户端通过调用远程函数来实现通信。
2. RESTful 和 RPC 的网络传输协议不同。RESTful 使用 HTTP 协议来传输数据，而 RPC 可以使用 TCP、HTTP、UDP 等多种协议来传输数据。
3. RESTful 和 RPC 的数据传输格式不同。RESTful 通常使用 JSON 或 XML 格式来传输数据，而 RPC 可以使用多种格式来传输数据，如二进制流、JSON、XML、Protobuf 等。
4. RESTful 和 RPC 的适用场景不同。RESTful 适用于大量资源的处理和 Web API 的开发，RPC 适用于需要高效传输数据和复杂计算任务时的应用场景。

综上所述，RESTful 和 RPC 都是常用的网络通信协议，它们在通信方式、网络传输协议、数据传输格式和适用场景等方面有区别和联系，具体选择哪种协议应根据实际情况来考虑。



### is 和 ==区别

在 Python 中，`is` 和 `==` 都是比较运算符，但它们的含义不同。

`is` 比较的是两个对象的身份标识，即它们**是否是同一个对象**。如果两个对象的身份标识相同，则返回 `True`，否则返回 `False`。

`==` 比较的是两个对象的**值是否相等**。如果两个对象的值相同，则返回 `True`，否则返回 `False`。

以下是示例代码，演示了 `is` 和 `==` 的不同：

```
pythonCopy Codea = [1, 2, 3] # 创建一个列表对象 a
b = [1, 2, 3] # 创建另一个列表对象 b

print(a == b) # 输出 True，因为 a 和 b 的值相等
print(a is b) # 输出 False，因为 a 和 b 是不同的对象

c = a # 创建一个对象 c，将其引用指向 a 指向的对象
print(a is c) # 输出 True，因为 a 和 c 引用同一个对象
```

需要注意的是，在 Python 中，一些常用的对象（如数值、字符串等）会被缓存起来供重用，因此可能会出现一些意外的结果。例如，对于整数值 `-5` 到 `256`，它们会被缓存起来，因此使用 `is` 比较同样的整数值时，会得到 `True` 的结果：

```
a = 1
b = 1
print(a is b) # 输出 True，因为 a 和 b 引用同一个整数对象
```



### 装饰器实现单例模式

```
def singleton(cls):
    instances = {}

    def getinstance(*args, **kwargs):
        if cls not in instances:
            instances[cls] = cls(*args, **kwargs)
        return instances[cls]
    return getinstance
    

@singleton
class MyClass:
    pass
```



### python内置的数据结构



Python 提供了多种内置的数据结构，以下是一些常用的数据结构：

列表（List）: 基于序列的动态数组，可以包含任意数量的元素，支持索引、切片、增加、删除等操作。
元组（Tuple）: 也是基于序列的不可变有序集合，可以包含任意数量的元素，一旦创建就不能修改。
集合（Set）: 无序的不重复元素的集合，可以进行交集、并集、差集等操作。
字典（Dictionary）: 一种映射类型，由键值对组成，支持通过键获取值，添加、删除、修改键值对等操作。
栈（Stack）: 后进先出的数据结构，只能从栈顶插入和删除元素。
队列（Queue）: 先进先出的数据结构，可以在队尾插入元素，在队头删除元素。
堆（Heap）: 一种特殊的树形数据结构，通常具有最小堆和最大堆两种形式。
链表（Linked List）: 通过指针连接各个节点的线性数据结构，可以分为单向链表、双向链表和循环链表。
以上是 Python 中常用的一些数据结构，不同的数据结构适用于不同的应用场景，掌握这些数据结构能够帮助我们更好地解决各种问题。



### 栈的使用

一个字符串，里面只有左括号和右括号元素，但是不确定都有多少，python如何实现判断是否里面的括号是闭合的，并计算最大深度

```
def max_depth(s):
    stack = []
    max_depth = 0
    depth = 0

    for c in s:
        if c == '(':
            stack.append(c)
            depth += 1
            if depth > max_depth:
                max_depth = depth
        elif c == ')':
            if not stack or stack[-1] != '(':
                return False
            stack.pop()
            depth -= 1

    return depth == 0, max_depth

在上述代码中，我们遍历字符串 s 中的每个字符，如果字符是左括号，则将其压入栈 stack 中，并更新当前深度 depth。如果当前深度大于最大深度，则更新最大深度。如果字符是右括号，则判定该字符是否与栈顶元素匹配，并同时更新当前深度。如果栈为空或者栈顶元素与当前右括号不匹配，则返回 False。最后，检查栈是否为空，如果为空说明该字符串是合法的闭合括号序列，返回 True 和最大深度；否则返回 False 和 0。
```



读取一个文件然后文件里面内容找合法的ip地址并并做去重

```
import re

# 读取文件
with open('file.txt', 'r') as f:
    s = f.read()

# 定义 IP 地址的正则表达式模式
pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'

# 使用正则表达式匹配 IP 地址，并存储到 set 集合中实现去重
ips = set(re.findall(pattern, s))

# 打印去重后的 IP 地址集合
print(ips)
```









字典按值排序（sorted(dict.iterms(), key=lambda x: x[1],）



翻转字符串  s = "w3423", s[::-1]



list1中age按由大到小排序（list1=[{"age": 5}, {"age": 67}, {"age": 56}],    sorted(list1, key=lambda x:x['age'], reverse=True)）



lista=[1,2,43,7],  lista[10:]



两个列表，找出相同元素和不同元素

list1= [1,2 ,4,6, 67],  list2=[3, 2, 43, 76]

set1=set(list1) , set2=set(list2), set1&set2,  set1^set2





### 什么是反射，反射应用场景

在 Python 中，反射是指程序可以访问、检查和修改其本身状态或行为的能力。通过反射，我们可以在运行时动态地获取对象的类型信息、属性、方法等，并且可以在不知道对象类型的情况下对其进行操作。

Python 提供了一些内置函数，例如 `getattr()`、`setattr()`、`hasattr()` 等，用于实现反射相关的功能。这些函数接收一个对象和一个属性名作为参数，然后进行相应的操作。例如，可以使用 `getattr(obj, "attr_name")` 来获取对象中的指定属性值，如果不存在则返回默认值；可以使用 `hasattr(obj, "attr_name")` 来检查对象是否存在指定的属性。

反射在 Python 中的应用场景比较广泛，下面列举几个典型的例子：

1. 动态导入模块：使用 `__import__(module_name)` 函数可以在运行时动态地导入指定模块，实现动态加载扩展功能的功能。
2. 插件架构：通过在程序运行时动态加载插件，实现程序功能的可扩展性。
3. 序列化和反序列化：当我们需要将对象序列化成字节流或 JSON 格式时，可以使用反射获取对象的属性列表和值列表，然后将它们转换为序列化格式；当我们需要从字节流或 JSON 中反序列化出对象时，可以使用反射创建对象，并为其设置属性值。
4. 测试框架：测试框架需要动态地加载测试用例，并对其进行执行和验证，可以使用反射实现动态加载并运行函数或方法。

总之，反射在 Python 中的应用非常广泛，可以大大提高程序的灵活性和可扩展性。但是，在使用反射时也需要注意一些安全性问题，例如可能会导致属性/方法访问不当、属性名字符串拼写错误等问题。因此，反射建议在必要时谨慎使用。





### 深拷贝和浅拷贝

浅拷贝会创建一个新的对象，但是这个新的对象还是会引用原始对象中的子对象。也就是说，浅拷贝只会复制原始对象的顶层结构，而其中的嵌套对象则会继续被共享。浅拷贝可以使用 `copy()` 方法或者切片来实现。

与之不同的是，深拷贝会创建一个新的对象，并递归地复制原始对象中所有的子对象。也就是说，深拷贝会完全独立于原始对象，不会共享其中的任何对象。深拷贝可以使用 `copy.deepcopy()` 方法来实现。





### `new和init`的区别



`__new__` 和 `__init__` 都是 Python 中用于创建对象的内置方法。它们在对象创建过程中具有不同的职责，因此二者之间具有一些区别。

`__new__` 是用于返回一个新的实例对象的方法，它是一个类级别的方法，在对象实例化之前调用。`__new__` 方法接收到的第一个参数是它所属的类，后续参数是用户传递的参数，返回值是创建的实例对象。在使用 `super().__new__(cls)` 时，它调用的是父类的 `__new__` 方法，从而创建了一个新的实例对象。

`__init__` 是用于初始化已经创建的实例对象的方法，它是一个实例级别的方法，在 `__new__` 方法返回实例对象之后调用。`__init__` 方法接收到的第一个参数是它所属的实例对象，后续参数是用户传递的参数。该方法不会返回任何值，它通过修改已经生成的对象的属性来对其进行初始化。







### GIL对python性能的影响

GIL（Global Interpreter Lock）是 Python 解释器中的一种机制，它的作用是确保同一时间只有一个线程在执行 Python 代码。这个机制是出于对解释器内部资源的保护和简化 C 拓展模块的设计而提出的。

虽然 GIL 的存在可以确保 Python 程序的安全性和稳定性，但同时也会对其性能产生一定的影响。由于 GIL 的存在，多线程的 Python 程序实际上是以并发的方式运行的，而不是真正的并行。因为在任何时刻都只有一个线程在执行 Python 代码，所以多个线程不能同时利用多核处理器的计算能力，从而限制了程序的性能和处理能力。

另外，由于 GIL 的存在，一个线程在持有解释器锁的时候，其他线程无法执行Python代码，只能等待当前线程释放锁。这就会导致CPU的利用率较低，从而降低程序的执行效率。

虽然 GIL 的存在是一种权衡，但是一些计算密集型任务、CPU 密集型的多线程程序以及高并发的网络应用程序等需要充分利用多核处理器的场景，都可能会受到 GIL 的限制，从而导致程序性能下降。针对这种情况，开发者可以考虑使用多进程、协程等替代方案，以便更好地发挥硬件的计算能力。





### 双下划线和单下划线

在 Python 中，双下划线和单下划线都有特殊的含义。

双下划线（__variable）表示私有变量，在类的内部指代使用，外部不可访问。在 Python 中，没有真正意义上的私有属性，但是使用双下划线可以让属性变成“伪私有”，因为 Python 解释器会将双下划线开头的变量名重命名，变成 _classname__variable 的形式，从而使得该变量在外部无法直接访问。例如，在一个类中定义了 __name 变量，在外部不能直接使用 obj.__name 访问，而应该使用 obj._classname__name 的方式来访问。需要注意的是，Python 中的私有变量只是一种约定俗成的规范，并不是强制性的。

单下划线（_variable）表示命名约定，表示该变量是“内部使用”的，不应该被外部直接访问。它主要用于区分临时变量和公共变量，也可以用于避免名称冲突。使用单下划线并不会改变变量的实际功能或访问权限，只是提醒开发者遵循良好的编程习惯。通常情况下，单下划线变量的功能与普通变量没有区别。

需要注意的是，单下划线和双下划线只是一种约定，不是关键字或保留字，因此在实际使用时需要注意遵循惯例。



with语句，如何构造，原理



单例模式，优缺点，如何实现







json序列化时，会遇到中文转unicode，想保留中文如何做（json.dumps({"dd", "你好"}， ensure_ascii=False)）



mro



C3算法



判断邮箱合法，re使用





python函数调用时候参数的传递是值传递还是引用传递







### python递归

#### 最大层数

在 Python 中，递归调用的最大深度由解释器的堆栈大小限制。默认情况下，Python 解释器限制递归深度不超过 1000 层。如果递归深度超过了这个值，会触发 `RecursionError` 异常，表示递归调用过深。

可以通过 `sys.setrecursionlimit()` 函数来修改递归调用的最大深度，但是不建议设置太大的值，因为过深的递归可能导致栈溢出等问题。

#### 停止条件

1. 达到指定的深度或层数：可以设置一个计数器或者参数来记录当前的递归层数或深度，当达到指定层数或深度时，不再继续调用自身，而是返回一个值或执行其他操作。
2. 达到特定的条件：可以根据具体的问题设置一些特定的条件，例如在查找树形结构中的某个节点时，当找到该节点时就不再继续递归。
3. 输入参数不符合要求：可以在函数开头对输入参数进行一些判断和筛选，当参数不符合要求时，直接返回一个错误信息或默认值。





### 列表推导式和生成器表达式

 输出结果分别是什么

```
[i % 2 for i in range(10)]    # 列表

(i % 2 for i in range(10))   # 迭代器
```



### 闭包

在 Python 中，闭包（Closure）是指一个函数对象和该函数所引用的外部变量组合而成的整体。

换句话说，闭包就是通过在一个函数内部定义另一个函数，并返回该函数对象，使得内部函数可以访问外部函数的变量和参数。这样做可以将函数和它所需的数据打包在一起，形成一个特殊的对象，具有不同于普通函数的行为。

常见的例子是利用闭包实现装饰器



### 正则表达式 

`re.search(pattern, string, flags=0)`：在字符串 `string` 中搜索匹配正则表达式 `pattern` 的第一个位置，并返回匹配的结果对象。如果匹配成功，则返回 MatchObject 对象，否则返回 None。

```
import re

# 在字符串中查找是否包含字母 a
str = "Hello World!"
match_result = re.search(r'a', str)
if match_result:
    print("Match found: ", match_result.group())
else:
    print("Match not found")
```



`re.findall(pattern, string, flags=0)`：在字符串 `string` 中查找所有满足正则表达式 `pattern` 的非重叠匹配，并以列表形式返回匹配的结果。如果没有匹配成功，则返回空列表。



```
import re

# 查找字符串中所有数字
str = "The price of the book is $20.99 and the weight is 2.5kg"
num_list = re.findall(r'\d+', str)
print(num_list)
```



`re.match(pattern, string, flags=0)`：从字符串 `string` 的开头开始匹配正则表达式 `pattern`，如果匹配成功，则返回匹配的结果对象，否则返回 None。与 `re.search()` 不同的是，`re.match()` 必须从字符串的开头开始匹配。

示例代码：

```
import re

# 匹配字符串是否以 Hello 开头
str = "Hello World!"
match_result = re.match(r'Hello', str)
if match_result:
    print("Match found: ", match_result.group())
else:
    print("Match not found")
```



`re.compile(pattern, flags=0)` 方法用于将正则表达式模式 `pattern` 编译成一个正则表达式对象，并返回该对象。这个编译过程可以提高正则表达式的执行效率，因为编译后的正则表达式对象可以重复使用。

示例代码如下：

```
import re

pattern = r"\d+"  # 匹配任意数字
text = "hello 123 world 456"
regex = re.compile(pattern)  # 将正则表达式编译为正则对象

match_obj = regex.search(text)  # 直接调用正则对象的方法进行匹配

if match_obj:
    print("Match found: ", match_obj.group())
else:
    print("Match not found")
```





```
import re

# 读取文件
with open('file.txt', 'r') as f:
    s = f.read()

# 定义 IP 地址的正则表达式模式 #结果不对
pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'

# 使用正则表达式匹配 IP 地址，并存储到 set 集合中实现去重
ips = set(re.findall(pattern, s))

# 打印去重后的 IP 地址集合
print(ips)


该正则表达式无法正确匹配符合 IPv4 标准的 IP 地址，原因是 [] 中的点号.只是一个普通字符，表示匹配任意一个字符。正确匹配 IPv4 地址的正则表达式应该是\b(?:\d{1,3}\.){3}\d{1,3}\b。

这个正则表达式具体含义如下：

\b 表示单词边界，避免匹配到 IP 地址的一部分。
(?:\d{1,3}\.){3} 表示匹配 3 个数字（每个数字长度为 1~3），并以点号.结尾的字符串，由于使用了非捕获分组 (?:)，所以匹配结果中不包含点号。
\d{1,3} 表示匹配一个长度为 1~3 的数字。
\b 表示单词边界，确保匹配到完整的 IP 地址。
```





### python面试题

https://juejin.cn/post/7067744227127459871





## 五、框架相关（django）



python三大框架各自应用场景



uWSGI 和nginx的理解

uwsgi  区别uWSGI



### 5.1 django



手动删除了表，导致，django迁移失败原因及解决办法

django中 Model    ForeignKey字段的on_delete参数作用



基于django使用ajax发送post请求时，有哪种方法携带csrftoken



django  FBV  CBV



django的request对象是什么时候创建的



django请求的生命周期



django中如何在model保存前做一定的固定操作，比如写一句日志（signal Dispatcher）



django中间件的使用



django  ORM查询中  select_related和prefetch_related的区别





cookie和session的区别





celery分布式队列





## 六、其他



自学python最大的困难



