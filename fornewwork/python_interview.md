## 一、linux相关



### 1. 常用linux系统调用

系统调用（System Call）是操作系统为在用户态运行的进程与**硬件设备（如CPU、磁盘、打印机等）进行交互**提供的一组接口。当用户进程需要发生系统调用时，CPU 通过软中断切换到内核态开始执行内核系统调用函数

**系统调用在内核里的主要用途**。虽然给出了数种分类，不过总的概括来讲系统调用主要在系统中的用途无非以下几类：

- **控制硬件**——系统调用往往作为硬件资源和用户空间的抽象接口，比如读写文件时用到的write/read调用。

- **设置系统状态或读取内核数据**——因为系统调用是用户空间和内核的唯一通讯手段[2]，所以用户设置系统状态，比如开/关某项内核服务（设置某个内核变量），或读取内核数据都必须通过系统调用。比如getpgid、getpriority、setpriority、sethostname

- **进程管理**——一系列调用接口是用来保证系统中进程能以多任务，在虚拟内存环境下得以运行。比如 fork、clone、execve、exit等

**什么功能应该实现在内核而不是在用户空间**

- 服务必须获得内核数据，比如一些服务必须获得中断或系统时间等内核数据。

- 从安全角度考虑，在内核中提供的服务相比用户空间提供的毫无疑问更安全，很难被非法访问到。

- 从效率考虑，在内核实现服务避免了和用户空间来回传递数据以及保护现场等步骤，因此效率往往要比实现在用户空间高许多。比如,httpd等服务。

- 如果内核和用户空间都需要使用该服务，那么最好实现在内核空间，比如随机数产生。



信号：kill、signal/sigpending/sigsuspend/

管道：pipe

socket控制：socket/bind/connect/accept/send/listen/select/shutdown/setsockopt

用户管理：getuid/setuid/getgid/setgid/

网络管理：gethostname/sethostname/setdomainname/getdomainname/gethostid/sethostid

系统控制：reboot/time/uname/

文件系统控制：open/creat/close/read/write/readv/writev/pread/poll/truncate/access/stat/chown/chmod/chdir/rename/mkdir/mount/unmount/

进程控制：fork/clone/exit/execve/setpgid/getpid/getppid/nice/pause/ptrace/wait/wait3/waitpid/setsid/getsid

#### open

在用户态使用open()时，必须向该函数传入文件路径和打开权限。这两个参数传入内核后，内核首先检查这个文件路径存在的合法性，同时还需检查使用者是否有合法权限打开该文件。如果一切顺利，那么内核将对访问该文件的进程创建一个file结构。

在用户态，通常open()在操作成功时返回的是一个非负整数，即所谓的文件描述符（fd，file descriptor）；并且，用户态后续对文件的读写操作等都是通过fd来完成的。由此可见fd与file结构在内核中有一定的关联。

内核使用进程描述符task_struct来描述一个进程，而该进程所有已打开文件对应的file结构将形成一个数组files（其为files_struct结构），内核向用户返回的fd便是该数组中具体file结构的索引。默认情况下，每个进程创建后都已打开了标准输入文件、标准输出文件、标准错误文件，因此他们的文件描述符依次为0、1和2。



参考连接：https://www.cnblogs.com/shijiaqi1066/p/5749030.html





### 2. 进程、线程、协程、绿色线程



1. 进程：是一个正在执行的程序的实例。每个进程都有独立的内存空间，可以同时执行多个进程来完成不同的任务，进程是操作系统进行资源分配和调度的基本单位。
2. 线程：是进程中的一个执行路径，不同的线程可以同时执行在同一个进程内，共享该进程的内存资源。线程之间的切换开销比进程小，但线程需要考虑同步和互斥的问题。
3. 协程：是一种轻量级的线程，可以在单线程内实现多个任务的并发执行，也可以通过多进程来实现并发。协程之间的切换开销很小，通常使用非抢占式调度方式，需要手动控制任务的切换。



1. 进程之间通信需要IPC机制，线程之间通信可以使用共享内存，协程之间通信可以使用全局变量。不同的进程之间需要通过进程间通信（IPC）机制来进行数据交换；线程之间可以直接访问共享内存进行数据交换；协程之间可以使用全局变量等方式进行数据交换。
2. 进程切换开销较大，线程切换开销比进程小，协程切换开销最小。由于进程之间相互独立，因此进程切换的开销较大；线程切换的开销要比进程小，但需要考虑同步和互斥的问题；协程切换的开销最小，通常使用非抢占式调度方式，需要手动控制任务的切换。
3. 进程数受限于硬件资源，线程数受限于进程内存空间，协程数无限制。由于每个进程都有独立的内存空间，因此进程数量是受限于硬件资源的；线程共享进程内存空间，因此线程数量是受限于进程内存空间的，而协程数量没有限制。





绿色线程

通常使用第三方库（如gevent、eventlet等）来实现，因为Python标准库中没有原生支持绿色线程的机制。绿色线程使用的是替换调度器的方式，在一个线程内模拟多个线程之间的切换，实现异步非阻塞的目的。

协程

则是在Python标准库中有原生支持的概念，通常使用async/await语法结合asyncio库来实现。协程通过使用事件循环（Event Loop）和异步IO等机制来实现非阻塞的并发执行。



IPC（Inter-Process Communication，进程间通信）是指不同进程之间进行数据交换和协作的机制。在操作系统中，进程之间有时需要共享数据、资源或者通知对方做一些操作，这时就需要使用IPC机制。

常见的IPC机制包括：

1. 管道（Pipe）：是一种半双工的通信方式，可以实现父子进程或兄弟进程之间的通信。管道有两种，一种是匿名管道，只能用于父子进程间的内部通信；另一种是命名管道，可以在不同进程之间通信。
2. 信号量（Semaphore）：是一个计数器，用于多个进程之间的同步和互斥操作。通过对信号量的P操作和V操作来实现进程之间的同步和互斥。
3. 共享内存（Shared Memory）：是指多个进程共享同一块物理内存，并且可以相互访问。可以通过共享内存来提高进程间的通信效率。
4. 套接字（Socket）：是一种计算机之间网络通信的机制，不仅可以在同一台计算机上的进程之间通信，也可以在不同计算机之间通信。
5. 消息队列（Message Queue）：是一种存放消息的队列，被多个进程共享。每个消息都有一个类型，接收进程可以选择性地接收某一类型的消息。
6. 信号（Signal）：是异步通知的一种方式，可以在进程中发送软件中断信号，让接收进程进行相应的处理。

不同的IPC机制各有优劣，需要根据具体的应用场景来选择合适的机制。







### 3. poll/epoll/select



**不同操作系统中IO多路复用模型介绍**

 

#### 3.1 select机制

 IO多路复用模型得以实现得核心：就是操作系统 监控1个[sk......conn,]列表，不断轮询每1个sk/conn/是否可以accpet/revive，随着监控列表的增加，效率会递减；

select函数监视的文件描述符分为3类，分别是writefds、readfds和exceptfds。调用后select函数会被阻塞，直到有描述符就绪（有数据可读、可写或者有except）、或者超时(timeout可用于指定等待时间，如果想立即返回可设置为null)，函数返回。当select函数返回后，可以通过遍历fdset来找到就绪的描述符。

> 在网络编程中统一的操作顺序是创建socket－>绑定端口－>监听－>accept->write/read,当有客户端连接到来时,select会把该连接的文件描述符放到fd_set（一组文件描述符(fd)的集合）,然后select会循环遍历它所监测的fd_set内的所有文件描述符，当select循环遍历完所有fd_set内指定的文件描述符对应的poll函数后，如果没有一个资源可用(即没有一个文件可供操作)，则select让该进程睡眠，一直等到有资源可用为止，fd_set是一个类似于数组的数据结构，由于它每次都要遍历整个数组，所有她的效率会随着文件描述符的数量增多而明显的变慢，除此之外在每次遍历这些描述符之前，系统还需要把这些描述符集合从内核copy到用户空间，然后再copy回去，如果此时没有一个描述符有事件发生（例如：read和write）这些copy操作和便利操作都是无用功，可见slect随着连接数量的增多，效率大大降低。可见如果在高并发的场景下select并不适用，况且select默认的最大描述符为1024，如果想要更多还要做响应参数的配置。



![img](./select模型.png)



1. **最大限制**：单个进程能够监视的文件描述符的数量存在最大限制。(基于数组存储的赶脚)一般来说这个数目和系统内存关系很大，具体数目可以cat /proc/sys/fs/file-max察看。它由FD_SETSIZE设置，32位机默认是1024个。64位机默认是2048.
2. **时间复杂度：** 对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低，时间复杂度O(n)。
   当套接字比较多的时候，每次select()都要通过遍历FD_SETSIZE个Socket来完成调度，不管哪个Socket是活跃的，都遍历一遍。这会浪费很多CPU时间。
   它仅仅知道有I/O事件发生了，却并不知道是哪那几个流（可能有一个，多个，甚至全部），我们只能无差别轮询所有流，找出能读出数据，或者写入数据的流，对他们进行操作。所以**select具有O(n)的无差别轮询复杂度**，同时处理的流越多，无差别轮询时间就越长。
3. **内存拷贝：**需要维护一个用来存放大量fd的数据结构，这样会使得用户空间和内核空间在传递该结构时复制开销大。



**支持操作系统**：linux/windows

 

#### 3.2 poll机制

不同于select使用三个位图来表示三个fdset的方式，poll使用一个pollfd指针来实现。pollfd结构包含了要监视的event和发生的event，不再使用select的“参数-值”传递的方式。同时pollfd并没有最大数量限制（但是数量过大后其性能也会降低）。和select函数一样，poll返回后需要轮询pollfd来获取就绪的描述符。

**没有最大连接数的限制**。（基于链表来存储的）

**支持操作系统**：linux

 

#### 3.3 epoll机制

##### epoll原理与流程

1.epoll很高级，epoll不会去再通过操作循环检查监控的socket列表中，那些socket出现了读操作，而是给需要监听的socket 1--1绑定1个回调函数；

2.检测的socket中 有1个soket出现了读操作，直接执行调用那个和该sk/con绑定的回调函数执行sk.accpet() 和conn.receve()

> ###### epoll基本流程
>
> **一棵红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。**
>
> 1. 执行 epoll_create
>    内核在epoll文件系统中建了个file结点，（使用完，必须调用close()关闭，否则导致fd被耗尽）
>    在内核cache里建了红黑树存储epoll_ctl传来的socket，
>    在内核cache里建了rdllist双向链表存储准备就绪的事件。
> 2. 执行 epoll_ctl
>    如果增加socket句柄，检查红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，告诉内核如果这个句柄的中断到了，就把它放到准备就绪list链表里。
>    ps：所有添加到epoll中的事件都会与设备（如网卡）驱动程序简历回调关系，相应的事件发生时，会调用回调方法。
> 3. 执行 epoll_wait
>    立刻返回准备就绪表里的数据即可（将内核cache里双向列表中存储的准备就绪的事件 复制到用户态内存）
>    当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。
>    如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。



##### epoll基本特点

1. **边缘触发**，它只告诉进程哪些fd刚刚变为就绪态，并且只会通知一次。
2. **事件驱动，**每个事件关联上fd，使用事件就绪通知方式，通过 epoll_ctl 注册 fd，一旦该fd就绪，内核就会采用 callback 的回调机制来激活该fd，epoll_wait 便可以收到通知。

1. **没有最大连接数的限制**。（基于 红黑树+双链表 来存储的:1G的内存上能监听约10万个端口）
2. **时间复杂度低：** 边缘触发和事件驱动，监听回调，时间复杂度O(1)。
   只有活跃可用的fd才会调用callback函数；即epoll最大的优点就在于它只管“活跃”的连接，而跟连接总数无关，因此实际网络环境中，Epoll的效率就会远远高于select和poll。
3. **内存拷贝：**利用mmap()文件映射内存加速与内核空间的消息传递，减少拷贝开销。



##### epoll两种模式(LT/ET)

epoll对文件描述符的操作有两种模式：LT(level trigger) 和 ET(edge trigger)。LT是默认的模式，ET是“高速”模式。

- LT（水平触发）模式下，只要有数据就触发，缓冲区剩余未读尽的数据会导致 epoll_wait都会返回它的事件；
- ET（边缘触发）模式下，只有新数据到来才触发，不管缓存区中是否还有数据，缓冲区剩余未读尽的数据不会导致epoll_wait返回



##### 适合用epoll的应用场景：

- 对于连接特别多，活跃的连接特别少(大量的idle-connection)
- 典型的应用场景为一个需要处理上万的连接服务器，例如各种app的入口服务器，例如qq

##### 不适合epoll的场景：

- 连接比较少，数据量比较大，例如ssh (没有大量的idle-connection或者dead-connection)
  epoll 的惊群问题：
  因为epoll 多用于多个连接，只有少数活跃的场景，但是万一某一时刻，epoll 等的上千个文件描述符都就绪了，这时候epoll 要进行大量的I/O，此时压力太大。



Python中的selectors模块就是帮我们自动选择最佳IO多路复用代理的；



#### 3.4 Event Loop的惊群效应

通过查阅资料发现`Linux`通过`WQ_FLAG_EXCLUSIVE`标记解决了`socket.accept`的惊群问题， 但是现在很多服务通过基于事件循环的方法来提供更高的并发能力。比如我线上运行的服务就是用到了**`Gevent`，而`Gevent`用到的核心事件循环则是`Epoll`**，它与`Select`, `Poll`并称为`Event Loop`。

对于任何工作模式来说， 使用`Event Loop`后，进程调用`socket.accept`后的行为逻辑就不一样了，具体的逻辑步骤如下：

- 1.进程在调用`socket.accept`时，`Event Loop`会把进程挂在`socket`对应的文件描述符的等待队列上。
- 2.当`socket`的文件描述符有事件产生时，对应的驱动就会将等待队列上对应的进程进行唤醒。
- 3.被唤醒的进程会通过`Event Loop`检查事件是否就绪，如果事件就绪就会返回对应的事件给刚才的进程。
- 4.检查`accept`事件是否可调用， 如果可以就执行`accept`操作，并取得该四元组的对应`socket`。

可以看到，之前进程是挂在网络驱动上等着被内核唤醒，而在使用`Event Loop`后进程是挂在对应文件描述符的等待队列上等待被`Event Loop`唤醒，对于`Pre-Worker`模型下的每个工作进程虽然都有自己专属的`Event Loop`，但是他们都是等待着同样的资源，于是当该文件描述符有事件产生时，就会唤醒所有工作进程对应的`Event Loop`来检查事件以及判断是否可以返回事件给工作进程, 而且由于是通过`Event Loop`的逻辑来执行`socket.accept`，这样会绕过上面所说的`WQ_FLAG_EXCLUSIVE`标记的限制，从而又产生了惊群效应。

可以看到，`Event Loop`产生惊群效应的原因跟进程直接调用`sock.accept`十分的像，所以他们的解决思路也很像，首先是给`Event Loop`增加一个名为`EPOLLEXCLUSIVE`的标记， 然后开发者在编程时可以在`Event Loop`实例化后注册对应的标记,当进程在调用`sock.accept`且系统检到`Event Loop`带有该标记时，就会把进程挂在文件描述符的队列尾部，等到事件产生时，**内核会只唤醒该队列的第一个进程来处理对应的事件。**

> 关于标记`EPOLLEXCLUSIVE`的具体内容可见:[Add epoll round robin wakeup mode](https://link.juejin.cn?target=https%3A%2F%2Flwn.net%2FArticles%2F632590%2F)， 通过内容还可以知道还有一个标记`EPOLLROUNDROBIN`用来解决唤醒不均衡的情况，但是在`Python`中似乎没办法使用。



☆☆☆参考连接：https://juejin.cn/post/7082005823328632839



### 4. pre-worker服务模型

包含nginx 、gunicorn/gevent/event loop/惊群现象及解决方法

tcp三种工作模式

负载不均衡问题

（gevent/**asyncio**，）

由于之前一直在使用`Asyncio`，所以我知道`Event Loop`在收到对应文件描述符的事件时，它不是以雨露均沾的方式去唤醒进程/线程/协程，而是**会优先唤醒第一个注册的进程/线程/协程，只有第一个进程/线程/协程繁忙的情况下才会去唤醒后面的进程/线程/协程，造成了唤醒倾斜的问题**，所以我猜测是这个规则引发了负载不均衡的问题。



☆☆☆参考连接：https://juejin.cn/post/7082005823328632839



### 5. nginx的惊群现象

首先，我们先大概梳理一下 Nginx 的网络架构，几个关键步骤为：

1. Nginx 主进程解析配置文件，根据 listen 指令，将监听套接字初始化到全局变量 ngx_cycle 的 listening 数组之中。此时，监听套接字的创建、绑定工作早已完成。
2. Nginx 主进程 fork 出多个子进程。
3. 每个子进程在 ngx_worker_process_init 方法里依次调用各个 Nginx 模块的 init_process 钩子，其中当然也包括 NGX_EVENT_MODULE 类型的 ngx_event_core_module 模块，其 init_process 钩子为 ngx_event_process_init。
4. ngx_event_process_init 函数会初始化 Nginx 内部的连接池，并把 ngx_cycle 里的监听套接字数组通过连接池来获得相应的表示连接的 ngx_connection_t 数据结构，这里关于 Nginx 的连接池先略过。我们主要看 ngx_event_process_init 函数所做的另一个工作：如果在配置文件里**没有**开启 [accept_mutex 锁](http://nginx.org/en/docs/ngx_core_module.html#accept_mutex)，就通过 ngx_add_event 将所有的监听套接字添加到 epoll 中。
5. 每一个 Nginx 子进程在执行完 ngx_worker_process_init 后，会在一个死循环中执行 ngx_process_events_and_timers，这就进入到事件处理的核心逻辑了。
6. 在 ngx_process_events_and_timers 中，如果在配置文件里开启了 accept_mutext 锁，子进程就会去获取 accet_mutext 锁。如果获取成功，则通过 ngx_enable_accept_events 将监听套接字添加到 epoll 中，否则，不会将监听套接字添加到 epoll 中，甚至有可能会调用 ngx_disable_accept_events 将监听套接字从 epoll 中删除（如果在之前的连接中，本worker子进程已经获得过accept_mutex锁)。
7. ngx_process_events_and_timers 继续调用 ngx_process_events，在这个函数里面阻塞调用 epoll_wait。

至此，关于 Nginx 如何处理 fork 后的监听套接字，我们已经差不多理清楚了，当然还有一些细节略过了，比如在每个 Nginx 在获取 accept_mutex 锁前，还会根据当前负载来判断是否参与 accept_mutex 锁的争夺。

把这个过程理清了之后，Nginx 解决惊群问题的方法也就出来了，就是利用 accept_mutex 这把锁。

**如果配置文件中没有开启 accept_mutex，则所有的监听套接字不管三七二十一，都加入到每子个进程的 epoll 中，这样当一个新的连接来到时，所有的 worker 子进程都会惊醒。**

**如果配置文件中开启了 accept_mutex，则只有一个子进程会将监听套接字添加到 epoll 中，这样当一个新的连接来到时，当然就只有一个 worker 子进程会被唤醒了。**



### 6. ifconfig参数解释

```
ifconfig
ens33: flags=4163<UP,BROADCAST,RUNNING,MULTICAST> mtu 1500
inet 192.168.1.63 netmask 255.255.255.0 broadcast 192.168.1.255
inet6 fe80::c09d:975d:89cd:fd3f prefixlen 64 scopeid 0x20
ether 00:0c:29:02:83:db txqueuelen 1000 (Ethernet)
RX packets 3255 bytes 4458479 (4.2 MiB)
RX errors 0 dropped 26 overruns 0 frame 0
TX packets 1130 bytes 81645 (79.7 KiB)
TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0

上图信息大概说明：
第一行：up–>网卡开启状态
RUNNING–>网线处理连接状态
MULTICAST–>支持组播
mtu 1500–>（Maximum Transmission Unit）最大传输单元大小为1500字节
第二行：该网卡的IP地址，子网掩码，广播地址
第三行：IPV6的配置信息
第四行：网卡的MAC地址
ether表示连接类型为以太网
txqueuelen 1000 --》传输队列的长度
第五六行：网卡接收数据包的统计信息和接收错误的统计信息
第七八行：网卡发送数据包的统计信息和发送错误的统计信息
```





### 7. 操作系统的调度机制



![本文提纲](./调度算法提纲.png)

#### 7.1 进程调度算法



进程调度算法也称 CPU 调度算法，毕竟进程是由 CPU 调度的。

当 CPU 空闲时，操作系统就选择内存中的某个「就绪状态」的进程，并给其分配 CPU。

什么时候会发生 CPU 调度呢？通常有以下情况：

1. 当进程从运行状态转到等待状态；
2. 当进程从运行状态转到就绪状态；
3. 当进程从等待状态转到就绪状态；
4. 当进程从运行状态转到终止状态；

其中发生在 1 和 4 两种情况下的调度称为「非抢占式调度」，2 和 3 两种情况下发生的调度称为「抢占式调度」。

非抢占式的意思就是，当进程正在运行时，它就会一直运行，直到该进程完成或发生某个事件而被阻塞时，才会把 CPU 让给其他进程。

而抢占式调度，顾名思义就是进程正在运行的时，可以被打断，使其把 CPU 让给其他进程。那抢占的原则一般有三种，分别是时间片原则、优先权原则、短作业优先原则。

你可能会好奇为什么第 3 种情况也会发生 CPU 调度呢？假设有一个进程是处于等待状态的，但是它的优先级比较高，如果该进程等待的事件发生了，它就会转到就绪状态，一旦它转到就绪状态，如果我们的调度算法是以优先级来进行调度的，那么它就会立马抢占正在运行的进程，所以这个时候就会发生 CPU 调度。

那第 2 种状态通常是时间片到的情况，因为时间片到了就会发生中断，于是就会抢占正在运行的进程，从而占用 CPU。

调度算法影响的是等待时间（进程在就绪队列中等待调度的时间总和），而不能影响进程真在使用 CPU 的时间和 I/O 时间。

接下来，说说常见的调度算法：

- 先来先服务调度算法
- 最短作业优先调度算法
- 高响应比优先调度算法
- 时间片轮转调度算法
- 最高优先级调度算法
- 多级反馈队列调度算法

##### 7.1.1 先来先服务调度算法

最简单的一个调度算法，就是非抢占式的**先来先服务（\*First Come First Severd, FCFS\*）算法**了。

![FCFS 调度算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/24-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.jpg)FCFS 调度算法

顾名思义，先来后到，**每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。**

这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。

FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统。

##### 7.1.2 最短作业优先调度算法

**最短作业优先（\*Shortest Job First, SJF\*）调度算法**同样也是顾名思义，它会**优先选择运行时间最短的进程来运行**，这有助于提高系统的吞吐量。

![SJF 调度算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/25-%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E7%AE%97%E6%B3%95.jpg)SJF 调度算法

这显然对长作业不利，很容易造成一种极端现象。

比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。

##### 7.1.3 高响应比优先调度算法

前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。

那么，**高响应比优先 （\*Highest Response Ratio Next, HRRN\*）调度算法**主要是权衡了短作业和长作业。

**每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行**，「响应比优先级」的计算公式：

![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/26-%E5%93%8D%E5%BA%94%E6%AF%94%E5%85%AC%E5%BC%8F.jpg)

从上面的公式，可以发现：

- 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；
- 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；

##### 7.1.4 时间片轮转调度算法

最古老、最简单、最公平且使用最广的算法就是**时间片轮转（\*Round Robin, RR\*）调度算法**。
。

![RR 调度算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/27-%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%AF%A2.jpg)RR 调度算法

**每个进程被分配一个时间段，称为时间片（\*Quantum\*），即允许该进程在该时间段中运行。**

- 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配另外一个进程；
- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

另外，时间片的长度就是一个很关键的点：

- 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
- 如果设得太长又可能引起对短作业进程的响应时间变长。将

通常时间片设为 `20ms~50ms` 通常是一个比较合理的折中值。

##### 7.1.5 最高优先级调度算法

前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。

但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能**从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（\*Highest Priority First，HPF\*）调度算法**。

进程的优先级可以分为，静态优先级或动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是**随着时间的推移增加等待进程的优先级**。

该算法也有两种处理优先级高的方法，非抢占式和抢占式：

- 非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。
- 抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。

但是依然有缺点，可能会导致低优先级的进程永远不会运行。

##### 7.1.6 多级反馈队列调度算法

**多级反馈队列（\*Multilevel Feedback Queue\*）调度算法**是「时间片轮转算法」和「最高优先级算法」的综合和发展。

顾名思义：

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![多级反馈队列](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B/28-%E5%A4%9A%E7%BA%A7%E9%98%9F%E5%88%97.jpg)多级反馈队列

来看看，它是如何工作的：

- 设置了多个队列，赋予每个队列不同的优先级，每个**队列优先级从高到低**，同时**优先级越高时间片越短**；
- 新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；

可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也会更长了，所以该算法很好的**兼顾了长短作业，同时有较好的响应时间。**

#### 7.2 内存页面置换算法

在了解内存页面置换算法前，我们得先谈一下**缺页异常（缺页中断）**。

当 CPU 访问的页面不在物理内存时，便会产生一个缺页中断，请求操作系统将所缺页调入到物理内存。那它与一般中断的主要区别在于：

- 缺页中断在指令执行「期间」产生和处理中断信号，而一般中断在一条指令执行「完成」后检查和处理中断信号。
- 缺页中断返回到该指令的开始重新执行「该指令」，而一般中断返回回到该指令的「下一个指令」执行。

我们来看一下缺页中断的处理流程，如下图：

![缺页中断的处理流程](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%BC%BA%E9%A1%B5%E5%BC%82%E5%B8%B8%E6%B5%81%E7%A8%8B.png)缺页中断的处理流程

1. 在 CPU 里访问一条 Load M 指令，然后 CPU 会去找 M 所对应的页表项。
2. 如果该页表项的状态位是「有效的」，那 CPU 就可以直接去访问物理内存了，如果状态位是「无效的」，则 CPU 则会发送缺页中断请求。
3. 操作系统收到了缺页中断，则会执行缺页中断处理函数，先会查找该页面在磁盘中的页面的位置。
4. 找到磁盘中对应的页面后，需要把该页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中。
5. 页面从磁盘换入到物理内存完成后，则把页表项中的状态位修改为「有效的」。
6. 最后，CPU 重新执行导致缺页异常的指令。

上面所说的过程，第 4 步是能在物理内存找到空闲页的情况，那如果找不到呢？

找不到空闲页的话，就说明此时内存已满了，这时候，就需要「页面置换算法」选择一个物理页，如果该物理页有被修改过（脏页），则把它换出到磁盘，然后把该被置换出去的页表项的状态改成「无效的」，最后把正在访问的页面装入到这个物理页中。

这里提一下，页表项通常有如下图的字段：

![img](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E9%A1%B5%E8%A1%A8%E9%A1%B9%E5%AD%97%E6%AE%B5.png)

那其中：

- *状态位*：用于表示该页是否有效，也就是说是否在物理内存中，供程序访问时参考。
- *访问字段*：用于记录该页在一段时间被访问的次数，供页面置换算法选择出页面时参考。
- *修改位*：表示该页在调入内存后是否有被修改过，由于内存中的每一页都在磁盘上保留一份副本，因此，如果没有修改，在置换该页时就不需要将该页写回到磁盘上，以减少系统的开销；如果已经被修改，则将该页重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。
- *硬盘地址*：用于指出该页在硬盘上的地址，通常是物理块号，供调入该页时使用。

这里我整理了虚拟内存的管理整个流程，你可以从下面这张图看到：

![虚拟内存的流程](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%B5%81%E7%A8%8B.png)虚拟内存的流程

所以，页面置换算法的功能是，**当出现缺页异常，需调入新页面而内存已满时，选择被置换的物理页面**，也就是说选择一个物理页面换出到磁盘，然后把需要访问的页面换入到物理页。

那其算法目标则是，尽可能减少页面的换入换出的次数，常见的页面置换算法有如下几种：

- 最佳页面置换算法（*OPT*）
- 先进先出置换算法（*FIFO*）
- 最近最久未使用的置换算法（*LRU*）
- 时钟页面置换算法（*Lock*）
- 最不常用置换算法（*LFU*）

##### 7.2.1 最佳页面置换算法

最佳页面置换算法基本思路是，**置换在「未来」最长时间不访问的页面**。

所以，该算法实现需要计算内存中每个逻辑页面的「下一次」访问时间，然后比较，选择未来最长时间不访问的页面。

我们举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：

![最佳页面置换算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E6%9C%80%E4%BC%98%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)最佳页面置换算法

在这个请求的页面序列中，缺页共发生了 `7` 次（空闲页换入 3 次 + 最优页面置换 4 次），页面置换共发生了 `4` 次。

这很理想，但是实际系统中无法实现，因为程序访问页面时是动态的，我们是无法预知每个页面在「下一次」访问前的等待时间。

所以，最佳页面置换算法作用是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明你的算法是高效的。

##### 7.2.2 先进先出置换算法

既然我们无法预知页面在下一次访问前所需的等待时间，那我们可以**选择在内存驻留时间很长的页面进行中置换**，这个就是「先进先出置换」算法的思想。

还是以前面的请求的页面序列作为例子，假设使用先进先出置换算法，则过程如下图：

![先进先出置换算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/FIFO%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)先进先出置换算法

在这个请求的页面序列中，缺页共发生了 `10` 次，页面置换共发生了 `7` 次，跟最佳页面置换算法比较起来，性能明显差了很多。

##### 7.2.3 最近最久未使用的置换算法

最近最久未使用（*LRU*）的置换算法的基本思路是，发生缺页时，**选择最长时间没有被访问的页面进行置换**，也就是说，该算法假设已经很久没有使用的页面很有可能在未来较长的一段时间内仍然不会被使用。

这种算法近似最优置换算法，最优置换算法是通过「未来」的使用情况来推测要淘汰的页面，而 LRU 则是通过「历史」的使用情况来推测要淘汰的页面。

还是以前面的请求的页面序列作为例子，假设使用最近最久未使用的置换算法，则过程如下图：

![最近最久未使用的置换算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/LRU%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)最近最久未使用的置换算法

在这个请求的页面序列中，缺页共发生了 `9` 次，页面置换共发生了 `6` 次，跟先进先出置换算法比较起来，性能提高了一些。

虽然 LRU 在理论上是可以实现的，但代价很高。为了完全实现 LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。

困难的是，在每次访问内存时都必须要更新「整个链表」。在链表中找到一个页面，删除它，然后把它移动到表头是一个非常费时的操作。

所以，LRU 虽然看上去不错，但是由于开销比较大，实际应用中比较少使用。

##### 7.2.4 时钟页面置换算法

那有没有一种即能优化置换的次数，也能方便实现的算法呢？

时钟页面置换算法就可以两者兼得，它跟 LRU 近似，又是对 FIFO 的一种改进。

该算法的思路是，把所有的页面都保存在一个类似钟面的「环形链表」中，一个表针指向最老的页面。

当发生缺页中断时，算法首先检查表针指向的页面：

- 如果它的访问位位是 0 就淘汰该页面，并把新的页面插入这个位置，然后把表针前移一个位置；
- 如果访问位是 1 就清除访问位，并把表针前移一个位置，重复这个过程直到找到了一个访问位为 0 的页面为止；

我画了一副时钟页面置换算法的工作流程图，你可以在下方看到：

![时钟页面置换算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E6%97%B6%E9%92%9F%E7%BD%AE%E6%8D%A2%E7%AE%97%E6%B3%95.png)时钟页面置换算法

了解了这个算法的工作方式，就明白为什么它被称为时钟（*Clock*）算法了。

##### 7.2.5 最不常用算法

最不常用（*LFU*）算法，这名字听起来很调皮，但是它的意思不是指这个算法不常用，而是**当发生缺页中断时，选择「访问次数」最少的那个页面，并将其淘汰**。

它的实现方式是，对每个页面设置一个「访问计数器」，每当一个页面被访问时，该页面的访问计数器就累加 1。在发生缺页中断时，淘汰计数器值最小的那个页面。

看起来很简单，每个页面加一个计数器就可以实现了，但是在操作系统中实现的时候，我们需要考虑效率和硬件成本的。

要增加一个计数器来实现，这个硬件成本是比较高的，另外如果要对这个计数器查找哪个页面访问次数最小，查找链表本身，如果链表长度很大，是非常耗时的，效率不高。

但还有个问题，LFU 算法只考虑了频率问题，没考虑时间的问题，比如有些页面在过去时间里访问的频率很高，但是现在已经没有访问了，而当前频繁访问的页面由于没有这些页面访问的次数高，在发生缺页中断时，就会可能会误伤当前刚开始频繁访问，但访问次数还不高的页面。

那这个问题的解决的办法还是有的，可以定期减少访问的次数，比如当发生时间中断时，把过去时间访问的页面的访问次数除以 2，也就说，随着时间的流失，以前的高访问次数的页面会慢慢减少，相当于加大了被置换的概率。

------

#### 7.3 磁盘调度算法

我们来看看磁盘的结构，如下图：

![磁盘的结构](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E7%BB%93%E6%9E%84.jpg)磁盘的结构

常见的机械磁盘是上图左边的样子，中间圆的部分是磁盘的盘片，一般会有多个盘片，每个盘面都有自己的磁头。右边的图就是一个盘片的结构，盘片中的每一层分为多个磁道，每个磁道分多个扇区，每个扇区是 `512` 字节。那么，多个具有相同编号的磁道形成一个圆柱，称之为磁盘的柱面，如上图里中间的样子。

磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。

寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。

假设有下面一个请求序列，每个数字代表磁道的位置：

98，183，37，122，14，124，65，67

初始磁头当前的位置是在第 `53` 磁道。

接下来，分别对以上的序列，作为每个调度算法的例子，那常见的磁盘调度算法有：

- 先来先服务算法
- 最短寻道时间优先算法
- 扫描算法算法
- 循环扫描算法
- LOOK 与 C-LOOK 算法

##### 7.3.1 先来先服务

先来先服务（*First-Come，First-Served，FCFS*），顾名思义，先到来的请求，先被服务。

那按照这个序列的话：

98，183，37，122，14，124，65，67

那么，磁盘的写入顺序是从左到右，如下图：

![先来先服务](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1.png)先来先服务

先来先服务算法总共移动了 `640` 个磁道的距离，这么一看这种算法，比较简单粗暴，但是如果大量进程竞争使用磁盘，请求访问的磁道可能会很分散，那先来先服务算法在性能上就会显得很差，因为寻道时间过长。

##### 7,3.2 最短寻道时间优先

最短寻道时间优先（*Shortest Seek First，SSF*）算法的工作方式是，优先选择从当前磁头位置所需寻道时间最短的请求，还是以这个序列为例子：

98，183，37，122，14，124，65，67

那么，那么根据距离磁头（ 53 位置）最近的请求的算法，具体的请求则会是下列从左到右的顺序：

65，67，37，14，98，122，124，183

![最短寻道时间优先](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E6%9C%80%E7%9F%AD%E5%AF%BB%E9%81%93%E6%97%B6%E9%97%B4%E4%BC%98%E5%85%88.png)最短寻道时间优先

磁头移动的总距离是 `236` 磁道，相比先来先服务性能提高了不少。

但这个算法可能存在某些请求的**饥饿**，因为本次例子我们是静态的序列，看不出问题，假设是一个动态的请求，如果后续来的请求都是小于 183
磁道的，那么 183 磁道可能永远不会被响应，于是就产生了饥饿现象，这里**产生饥饿的原因是磁头在一小块区域来回移动**。

##### 7.3.3 扫描算法

最短寻道时间优先算法会产生饥饿的原因在于：磁头有可能再一个小区域内来回得移动。

为了防止这个问题，可以规定：**磁头在一个方向上移动，访问所有未完成的请求，直到磁头到达该方向上的最后的磁道，才调换方向，这就是扫描（\*Scan\*）算法**。

这种算法也叫做电梯算法，比如电梯保持按一个方向移动，直到在那个方向上没有请求为止，然后改变方向。

还是以这个序列为例子，磁头的初始位置是 53：

98，183，37，122，14，124，65，67

那么，假设扫描调度算先朝磁道号减少的方向移动，具体请求则会是下列从左到右的顺序：

37，14，`0`，65，67，98，122，124，183

![扫描算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-%E6%89%AB%E6%8F%8F%E7%AE%97%E6%B3%95.png)扫描算法

磁头先响应左边的请求，直到到达最左端（ 0 磁道）后，才开始反向移动，响应右边的请求。

扫描调度算法性能较好，不会产生饥饿现象，但是存在这样的问题，中间部分的磁道会比较占便宜，中间部分相比其他部分响应的频率会比较多，也就是说每个磁道的响应频率存在差异。

##### 7.3.4 循环扫描算法

扫描算法使得每个磁道响应的频率存在差异，那么要优化这个问题的话，可以总是按相同的方向进行扫描，使得每个磁道的响应频率基本一致。

循环扫描（*Circular Scan, CSCAN* ）规定：只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且**返回中途不处理任何请求**，该算法的特点，就是**磁道只响应一个方向上的请求**。

还是以这个序列为例子，磁头的初始位置是 53：

98，183，37，122，14，124，65，67

那么，假设循环扫描调度算先朝磁道增加的方向移动，具体请求会是下列从左到右的顺序：

65，67，98，122，124，183，`199`，`0`，14，37

![循环扫描算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-C-SCAN%E7%AE%97%E6%B3%95.png)循环扫描算法

磁头先响应了右边的请求，直到碰到了最右端的磁道 199，就立即回到磁盘的开始处（磁道 0），但这个返回的途中是不响应任何请求的，直到到达最开始的磁道后，才继续顺序响应右边的请求。

循环扫描算法相比于扫描算法，对于各个位置磁道响应频率相对比较平均。

##### 7.3.5 LOOK 与 C-LOOK算法

我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。

那这其实是可以优化的，优化的思路就是**磁头在移动到「最远的请求」位置，然后立即反向移动。**

那针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，**反向移动的途中会响应请求**。

![LOOK 算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-LOOK%E7%AE%97%E6%B3%95.png)LOOK 算法

而针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，**反向移动的途中不会响应请求**。

![C-LOOK 算法](https://cdn.jsdelivr.net/gh/xiaolincoder/ImageHost2/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95/%E7%A3%81%E7%9B%98%E8%B0%83%E5%BA%A6-C-LOOK%E7%AE%97%E6%B3%95.png)C-LOOK 算法



参考链接：https://www.cnblogs.com/xiaolincoding/p/13631224.html







### 8. 操作系统如何申请及管理内存

- 内存的分配与回收：当作业或进程创建后系统会为他们分配内存空间，当结束后内存空间也会被回收。
- 地址转换：将程序中的逻辑地址转换成内存中的物理地址
- 内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存
- 存储保护：保证个个作业在自己的内存空间内运行，互不干扰

详细信息：https://zhuanlan.zhihu.com/p/141602175



### 9. 同步、阻塞、异步、并发、非阻塞、并行

一个线程/进程经历的5个状态，创建，就绪，运行，阻塞，终止。各个状态的转换条件如上图，其中有个阻塞状态，就是说当线程中调用某个函数，需要IO请求，或者暂时得不到竞争资源的，操作系统会把该线程阻塞起来，避免浪费CPU资源，等到得到了资源，再变成就绪状态，等待CPU调度运行。

**阻塞**调用是指调用结果返回之前，调用者会进入阻塞状态等待。只有在得到结果之后才会返回。
**非阻塞**调用是指在不能立刻得到结果之前，该函数不会阻塞当前线程，而会立刻返回。
**同步**：在发出一个同步调用时，在没有得到结果之前，该调用就不返回。
**异步**：在发出一个异步调用后，调用者不会立刻得到结果，该调用就返回了。
同步阻塞调用：得不到结果不返回，线程进入阻塞态等待。
同步非阻塞调用：得不到结果不返回，线程不阻塞一直在CPU运行。
异步阻塞调用：去到别的线程，让别的线程阻塞起来等待结果，自己不阻塞。
异步非阻塞调用：去到别的线程，别的线程一直在运行，直到得出结果。
**并发**是指一个时间段内，有几个程序都在同一个CPU上运行，但任意一个时刻点上只有一个程序在处理机上运行。
**并行**是指一个时间段内，有几个程序都在几个CPU上运行，任意一个时刻点上，有多个程序在同时运行，并且多道程序之间互不干扰。 两者区别如下图



## 二、网络相关





### 2.1. 三次握手、四次挥手

**URG**：(**URG**ent)紧急
**ACK**：(**ACK**nowledgment)确认
**PSH**：(**P**u**SH**)推送
**RST**：(**R**e**S**e**T**)复位
**SYN**：(**SYN**chronization) 同步
**FIN**:（**FIN**ish）终止



#### 三次握手

 ![img](/Users/yjz/code/learnning/network_knowledge/jike_qutanwangluoxieyi/./企业微信截图_16350669667909.png) 

一开始，客户端和服务端都处于CLOSED状态。先是服务端主动监听某个端口，处于LISTEN状态。然后客户端主动发起连接SYN，之后处于SYN-SENT状态。服务端收到发起的连接，返回SYN，并且ACK客户端的SYN，之后处于SYN-RCVD状态。客户端收到服务端发送的SYN和ACK之后，发送ACK的ACK，之后处于ESTABLISHED状态，因为它一发一收成功了。服务端收到ACK的ACK之后，处于ESTABLISHED状态，因为它也一发一收了。

#### 四次挥手

![img](/Users/yjz/code/learnning/network_knowledge/jike_qutanwangluoxieyi/企业微信截图_16350673531207.png) 

断开的时候，我们可以看到，当客户端主动发送断开请求后，就进入FIN_WAIT_1的状态，服务端收到消息后，回复ack，就进入CLOSE_WAIT的状态。
客户端收到服务端的ack，就进入FIN_WAIT_2的状态，如果这个时候服务端强制断开了，则客户端将永远在这个状态。TCP协议里面并没有对这个状态的处理，但是Linux有，可以调整tcp_fn_timeout这个参数，设置一个超时时间。
如果服务端没有断开，处理完所有数据后，发送了FIN ACK的请求到达客户端时，客户端收到后发送ACK后，从FIN_WAIT_2状态结束，按说客户端可以断开了，但是最后的这个ACK万一服务端收不到呢？则服务端会重新发一个FIN ACK，这个时候客户端已经断开了的话，服务端就再也收不到ACK了，因而TCP协议要求客户端最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果服务端没收到ACK的话，“FIN ACK会重发的，客户端会重新发一个ACK并且足够时间到达服务端。
客户端直接断开还有一个问题是，客户端的端口就直接空出来了，但是服务端不知道，原来发过的很多包很可能还在路上，如果客户端的端口被一个新的应用占用了，这个新的应用会收到上个连接中服务端发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来服务端发送的所有的包都死翘翘，再空出端口来。
等待的时间设为2MSL，MSL是Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为TCP报文基于是IP协议的，而IP头中有一个TTL域，是IP数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值为0则数据报将被丢弃，同时发送ICMP报文通知源主机。协议规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。
还有一个异常情况就是，服务端超过了2MSL的时间，依然没有收到它发的FIN的ACK，怎么办呢？按照TCP的原理，服务端当然还会重发FIN，这个时候客户端再收到这个包之后，就直接发送RST，服务端就知道客户端早断开连接了。

#### TCP状态机

 ![img](/Users/yjz/code/learnning/network_knowledge/jike_qutanwangluoxieyi/企业微信截图_16350682615524.png) 





#### 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？

这是因为服务端在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。而关闭连接时，当收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方也未必全部数据都发送给对方了，所以己方可以立即close，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送。



### 2.2 http与https



#### 2.2.1 什么是http

超文本传输协议，是一个基于请求与响应，无状态的，应用层的协议，常基于TCP/IP协议传输数据，互联网上应用最为广泛的一种网络协议,所有的WWW文件都必须遵守这个标准。设计HTTP的初衷是为了提供一种发布和接收HTML页面的方法。

#### 2.2.2 什么是https

https是身披SSL外壳的http。是一种通过计算机网络进行安全通信的传输协议，经由http进行通信，利用SSL/TLS建立全信通，加密数据包。主要的目的https是解决http网络请求中数据被篡改的问题，保护数据的隐私和完整性。

#### 2.2.3 http的缺点

客户端通过http请求服务器，中间经过很多中间商，例如路由器，局域网，网络运营商，而http请求又是明文传输的，所以中间任何一步都能捕获传输信息，并进行篡改。

#### 2.2.4 https解决了http的什么问题

https解决了http请求中传输信息被篡改的问题，因为https内容传输，全部是密文，即使被拦截，篡改也没用。

#### 2.2.5 https请求流程

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/60762b9ea8314117a303f8a3df0efffc~tplv-k3u1fbpfcp-zoom-in-crop-mark:4536:0:0:0.awebp)

1、客户端发起请求，例如在浏览器输入`https://www/baidu.com`，请求服务器443端口

2、服务器收到请求后将数字证书和公钥返给客户端

3、客户端收到证书和公钥之后，请求证书生成机构，验证证书有效性，主要验证：

- 证书是否过期
- 发行证书的机构是否可靠
- 返回的公钥是否能正确解开返回证书中的数字签名
- 证书域名和请求的域名是否匹配

4、证书无效浏览器提示证书验证不通过，风险提示。
 证书有效，客户端生成一个随机秘钥

5、客户端将生成的随机秘钥，通过上面的公钥加密，发给服务器

6、服务器收到客户端用公钥加密过的随机秘钥之后，用私钥解密出秘钥

7、服务器用解出来的客户端秘钥，将要响应的内容用秘钥对称加密，响应给客户端

8、客户端将得到的内容，用刚刚自己生成的秘钥解密出内容


参考链接：https://juejin.cn/post/6996959281312432136

### 2.3 https里加密相关

#### 2.3.1 对称加密

简单说就是有一个密钥，它可以加密一段信息，也可以对加密后的信息进行解密，和我们日常生活中用的钥匙作用差不多。非对称加密算法非常耗时，而对称加密快很多。

#### 2.3.2 非对称加密

简单说就是有两把密钥，通常一把叫做公钥、一把叫私钥，用公钥加密的内容必须用私钥才能解开，同样，私钥加密的内容只有公钥能解开。非对称加密算法非常耗时，而对称加密快很多。

大概流程：

服务器先把公钥以明文方式传输给浏览器，之后浏览器向服务器传数据前都先用这个公钥加密好再传，这条数据的安全似乎可以保障了！**因为只有服务器有相应的私钥能解开公钥加密的数据**。

如果服务器用它的私钥加密数据传给浏览器，那么浏览器用公钥可以解密它，而这个公钥是一开始通过明文传输给浏览器的，若这个公钥被中间人劫持到了，那他也能用该公钥解密服务器传来的信息了。所以**目前似乎只能保证由浏览器向服务器传输数据的安全性**



#### 2.3.3 非对称加密+对称加密

既然非对称加密耗时，那非对称加密+对称加密结合可以吗？而且得尽量减少非对称加密的次数。当然是可以的，且非对称加密、解密各只需用一次即可。

过程：

1. 某网站拥有用于非对称加密的公钥A、私钥A’。
2. 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。
3. 浏览器随机生成一个用于对称加密的密钥X，用公钥A加密后传给服务器。
4. 服务器拿到后用私钥A’解密得到密钥X。
5. 这样双方就都拥有密钥X了，且别人无法知道它。之后双方所有数据都通过密钥X加密解密即可。

弊端：

根本原因是浏览器无法确认收到的公钥是不是网站自己的。

如果在数据传输过程中，中间人劫持到了数据，此时他的确无法得到浏览器生成的密钥X，这个密钥本身被公钥A加密了，只有服务器才有私钥A’解开它，然而中间人却完全不需要拿到私钥A’就能干坏事了。请看：

1. 某网站有用于非对称加密的公钥A、私钥A’。
2. 浏览器向网站服务器请求，服务器把公钥A明文给传输浏览器。
3. **中间人劫持到公钥A，保存下来，把数据包中的公钥A替换成自己伪造的公钥B（它当然也拥有公钥B对应的私钥B’）**。
4. 浏览器生成一个用于对称加密的密钥X，用**公钥B**（浏览器无法得知公钥被替换了）加密后传给服务器。
5. **中间人劫持后用私钥B’解密得到密钥X，再用公钥A加密后传给服务器**。
6. 服务器拿到后用私钥A’解密得到密钥X。

#### 2.3.4 数字证书

网站在使用HTTPS前，需要向**CA机构**申领一份**数字证书**，数字证书里含有证书持有者信息、公钥信息等。服务器把证书传输给浏览器，浏览器从证书里获取公钥就行了，证书就如身份证，证明“该公钥对应该网站”。

**如何放防止数字证书被篡改？**

我们把证书原本的内容生成一份“签名”，比对证书内容和签名是否一致就能判别是否被篡改。这就是数字证书的“防伪技术”，这里的“签名”就叫`数字签名`：

#### 2.3.5 数字签名

这部分内容建议看下图并结合后面的文字理解，图中左侧是数字签名的制作过程，右侧是验证过程：

![img](https://pic2.zhimg.com/80/v2-7c78935389af46e197e96d9cd91c06dd_1440w.webp)

数字签名的生成与验证（https://cheapsslsecurity.com/blog/digital-signature-vs-digital-certificate-the-difference-explained/）


数字签名的制作过程：

1. CA机构拥有非对称加密的私钥和公钥。
2. CA机构对证书明文数据T进行hash。
3. 对hash后的值用私钥加密，得到数字签名S。

明文和数字签名共同组成了数字证书，这样一份数字证书就可以颁发给网站了。
那浏览器拿到服务器传来的数字证书后，如何验证它是不是真的？（有没有被篡改、掉包）



浏览器验证过程：

1. 拿到证书，得到明文T，签名S。
2. 用CA机构的公钥对S解密（由于是浏览器信任的机构，所以浏览器保有它的公钥。详情见下文），得到S’。
3. 用证书里指明的hash算法对明文T进行hash得到T’。
4. 显然通过以上步骤，T’应当等于S‘，除非明文或签名被篡改。所以此时比较S’是否等于T’，等于则表明证书可信。





#### 2.3.6 中间人有可能把证书掉包吗？

假设有另一个网站B也拿到了CA机构认证的证书，它想劫持网站A的信息。于是它成为中间人拦截到了A传给浏览器的证书，然后替换成自己的证书，传给浏览器，之后浏览器就会错误地拿到B的证书里的公钥了，这确实会导致上文“中间人攻击”那里提到的漏洞？

其实这并不会发生，因为证书里包含了网站A的信息，包括域名，浏览器把证书里的域名与自己请求的域名比对一下就知道有没有被掉包了。

#### 2.3.7 为什么制作数字签名时需要hash一次？

我初识HTTPS的时候就有这个疑问，因为似乎那里的hash有点多余，把hash过程去掉也能保证证书没有被篡改。

最显然的是性能问题，前面我们已经说了非对称加密效率较差，证书信息一般较长，比较耗时。而hash后得到的是固定长度的信息（比如用md5算法hash后可以得到固定的128位的值），这样加解密就快很多。



#### 2.3.8 怎么证明CA机构的公钥是可信的？

你们可能会发现上文中说到CA机构的公钥，我几乎一笔带过，“浏览器保有它的公钥”，这是个什么保有法？怎么证明这个公钥是否可信？

让我们回想一下数字证书到底是干啥的？没错，为了证明某公钥是可信的，即“该公钥是否对应该网站”，那CA机构的公钥是否也可以用数字证书来证明？没错，操作系统、浏览器本身会预装一些它们信任的根证书，如果其中会有CA机构的根证书，这样就可以拿到它对应的可信公钥了。

实际上证书之间的认证也可以不止一层，可以A信任B，B信任C，以此类推，我们把它叫做`信任链`或`数字证书链`。也就是一连串的数字证书，由根证书为起点，透过层层信任，使终端实体证书的持有者可以获得转授的信任，以证明身份。

另外，不知你们是否遇到过网站访问不了、提示需安装证书的情况？这里安装的就是根证书。说明浏览器不认给这个网站颁发证书的机构，那么你就得手动下载安装该机构的根证书（风险自己承担XD）。安装后，你就有了它的公钥，就可以用它验证服务器发来的证书是否可信了。



#### 2.3.9 每次进行HTTPS请求时都必须在SSL/TLS层进行握手传输密钥吗？

这也是我当时的困惑之一，显然每次请求都经历一次密钥传输过程非常耗时，那怎么达到只传输一次呢？

服务器会为每个浏览器（或客户端软件）维护一个session ID，在TLS握手阶段传给浏览器，浏览器生成好密钥传给服务器后，服务器会把该密钥存到相应的session ID下，之后浏览器每次请求都会携带session ID，服务器会根据session ID找到相应的密钥并进行解密加密操作，这样就不必要每次重新制作、传输密钥了！



参考链接：https://zhuanlan.zhihu.com/p/43789231



### 2.4 tcp与udp特点，区别

- 链路层：负责封装和解封装IP报文，发送和接受ARP/RARP报文等。
- 网络层：负责路由以及把分组报文发送给目标网络或主机。
- 传输层：负责对报文进行分组和重组，并以TCP或UDP协议格式封装报文。
- 应用层：负责向用户提供应用程序，比如HTTP、FTP、Telnet、DNS、SMTP等。

#### 2.4.1 UDP

UDP协议全称是用户数据报协议，在网络中它与TCP协议一样用于处理数据包，是一种无连接的协议。在OSI模型中，在第四层——传输层，处于IP协议的上一层。UDP有不提供数据包分组、组装和不能对数据包进行排序的缺点，也就是说，当报文发送之后，是无法得知其是否安全完整到达的。

它有以下几个特点：

##### 1. 面向无连接

首先 UDP想发数据就可以开始发送了。并且也只是数据报文的搬运工，不会对数据报文进行任何拆分和拼接操作。

具体来说就是：

- 在发送端，应用层将数据传递给传输层的 UDP 协议，UDP 只会给数据增加一个 UDP 头标识下是 UDP 协议，然后就传递给网络层了
- 在接收端，网络层将数据传递给传输层，UDP 只去除 IP 报文头就传递给应用层，不会任何拼接操作

##### 2. 有单播，多播，广播的功能

UDP 不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 UDP 提供了单播，多播，广播的功能。

##### 3. UDP是面向报文的

发送方的UDP对应用程序交下来的报文，在添加首部后就向下交付IP层。UDP对应用层交下来的报文，既不合并，也不拆分，而是保留这些报文的边界。因此，应用程序必须选择合适大小的报文

##### 4. 不可靠性

首先不可靠性体现在无连接上，通信都不需要建立连接，想发就发，这样的情况肯定不可靠。

并且收到什么数据就传递什么数据，并且也不会备份数据，发送数据也不会关心对方是否已经正确接收到数据了。

再者网络环境时好时坏，但是 UDP 因为没有拥塞控制，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景（比如电话会议）就需要使用 UDP 而不是 TCP。

##### 5. 头部开销小，传输数据报文时是很高效的。

![img](https://image.fundebug.com/2019-03-21-03.png)

UDP 头部包含了以下几个数据：

- 两个十六位的端口号，分别为源端口（可选字段）和目标端口
- 整个数据报文的长度
- 整个数据报文的检验和（IPv4 可选 字段），该字段用于发现头部信息和数据中的错误

因此 UDP 的头部开销小，只有八字节，相比 TCP 的至少二十字节要少得多，在传输数据报文时是很高效的



#### 2.4.2 TCP

TCP协议全称是传输控制协议是一种面向连接的、可靠的、基于字节流的传输层通信协议，由 IETF 的RFC 793定义。TCP 是面向连接的、可靠的流协议。流就是指不间断的数据结构，你可以把它想象成排水管中的水流。

##### 1. 面向连接

面向连接，是指发送数据之前必须在两端建立连接。建立连接的方法是“三次握手”，这样能建立可靠的连接。建立连接，是为数据的可靠传输打下了基础。

##### 2. 仅支持单播传输

每条TCP传输连接只能有两个端点，只能进行点对点的数据传输，不支持多播和广播传输方式。

##### 3. 面向字节流

TCP不像UDP一样那样一个个报文独立地传输，而是在不保留报文边界的情况下以字节流方式进行传输。

##### 4. 可靠传输

对于可靠传输，判断丢包，误码靠的是TCP的段编号以及确认号。TCP为了保证报文传输的可靠，就给每个包一个序号，同时序号也保证了传送到接收端实体的包的按序接收。然后接收端实体对已成功收到的字节发回一个相应的确认(ACK)；如果发送端实体在合理的往返时延(RTT)内未收到确认，那么对应的数据（假设丢失了）将会被重传。

##### 5. 提供拥塞控制

当网络出现拥塞的时候，TCP能够减小向网络注入数据的速率和数量，缓解拥塞

##### 6. TCP提供全双工通信

TCP允许通信双方的应用程序在任何时候都能发送数据，因为TCP连接的两端都设有缓存，用来临时存放双向通信的数据。当然，TCP可以立即发送一个数据段，也可以缓存一段时间以便一次发送更多的数据段（最大的数据段大小取决于MSS）

参考链接：https://www.cnblogs.com/fundebug/p/differences-of-tcp-and-udp.html







### 2.5 http网页，从请求到响应

- 1、输入地址
- 2、浏览器查找域名的 IP 地址
- 3、浏览器向 web 服务器发送一个 HTTP 请求
- 4、服务器的永久重定向响应
- 6、服务器处理请求
- 7、服务器返回一个 HTTP 响应
- 8、浏览器显示 HTML
- 9、浏览器发送请求获取嵌入在 HTML 中的资源（如图片、音频、视频、CSS、JS等等）

#### 2.5.1 dns知识

##### 1. 查询详细过程

1、请求一旦发起，浏览器首先要做的事情就是解析这个域名，一般来说，浏览器会首先查看本地硬盘的 hosts 文件，看看其中有没有和这个域名对应的规则，如果有的话就直接使用 hosts 文件里面的 ip 地址。

2、如果在本地的 hosts 文件没有能够找到对应的 ip 地址，浏览器会发出一个 DNS请求到本地DNS服务器 。本地DNS服务器一般都是你的网络接入服务器商提供，比如中国电信，中国移动。

3、查询你输入的网址的DNS请求到达本地DNS服务器之后，本地DNS服务器会首先查询它的缓存记录，如果缓存中有此条记录，就可以直接返回结果，此过程是递归的方式进行查询。如果没有，本地DNS服务器还要向DNS根服务器进行查询。

4、根DNS服务器没有记录具体的域名和IP地址的对应关系，而是告诉本地DNS服务器，你可以到域服务器上去继续查询，并给出域服务器的地址。这种过程是迭代的过程。

5、本地DNS服务器继续向域服务器发出请求，在这个例子中，请求的对象是.com域服务器。.com域服务器收到请求之后，也不会直接返回域名和IP地址的对应关系，而是告诉本地DNS服务器，你的域名的解析服务器的地址。

6、最后，本地DNS服务器向域名的解析服务器发出请求，这时就能收到一个域名和IP地址对应关系，本地DNS服务器不仅要把IP地址返回给用户电脑，还要把这个对应关系保存在缓存中，以备下次别的用户查询时，可以直接返回结果，加快网络访问。 



##### 2. dns两种查询方式

**1、递归解析**

当局部DNS服务器自己不能回答客户机的DNS查询时，它就需要向其他DNS服务器进行查询。此时有两种方式，如图所示的是递归方式。局部DNS服务器自己负责向其他DNS服务器进行查询，一般是先向该域名的根域服务器查询，再由根域名服务器一级级向下查询。最后得到的查询结果返回给局部DNS服务器，再由局部DNS服务器返回给客户端。

![img](https://pic3.zhimg.com/80/v2-4415eab38ab3774f85663197b3559942_1440w.webp)

**2、迭代解析**

当局部DNS服务器自己不能回答客户机的DNS查询时，也可以通过迭代查询的方式进行解析，如图所示。局部DNS服务器不是自己向其他DNS服务器进行查询，而是把能解析该域名的其他DNS服务器的IP地址返回给客户端DNS程序，客户端DNS程序再继续向这些DNS服务器进行查询，直到得到查询结果为止。也就是说，迭代解析只是帮你找到相关的服务器而已，而不会帮你去查。比如说：[http://baidu.com](https://link.zhihu.com/?target=http%3A//baidu.com)的服务器ip地址在192.168.4.5这里，你自己去查吧，本人比较忙，只能帮你到这里了。

![img](https://pic2.zhimg.com/80/v2-1d2ec667390081157834a69f5a17445d_1440w.webp)

#### 2.5.2 重定向

服务器给浏览器响应一个301永久重定向响应，这样浏览器就会访问`http://www.google.com/`而非`http://google.com/`。

为什么服务器一定要重定向而不是直接发送用户想看的网页内容呢？其中一个原因跟搜索引擎排名有关。如果一个页面有两个地址，就像[http://www.yy.com/](https://link.zhihu.com/?target=http%3A//www.yy.com/)和[http://yy.com/](https://link.zhihu.com/?target=http%3A//yy.com/)，搜索引擎会认为它们是两个网站，结果造成每个搜索链接都减少从而降低排名。而搜索引擎知道301永久重定向是什么意思，这样就会把访问带www的和不带www的地址归到同一个网站排名下。还有就是用不同的地址会造成缓存友好性变差，当一个页面有好几个名字时，它可能会在缓存里出现好几次。

301和302状态码都表示重定向，就是说浏览器在拿到服务器返回的这个状态码后会自动跳转到一个新的URL地址，这个地址可以从响应的Location首部中获取（用户看到的效果就是他输入的地址A瞬间变成了另一个地址B）——这是它们的共同点。

他们的不同在于：301表示旧地址A的资源已经被永久地移除了（这个资源不可访问了），搜索引擎在抓取新内容的同时也将旧的网址交换为重定向之后的网址；

302表示旧地址A的资源还在（仍然可以访问），这个重定向只是临时地从旧地址A跳转到地址B，搜索引擎会抓取新的内容而保存旧的网址。SEO302好于301

 重定向原因：

- 网站调整（如改变网页目录结构）；
- 网页被移到一个新地址；
- 网页扩展名改变(如应用需要把.php改成.Html或.shtml)。



使用场景：

当一个网站或者网页24—48小时内临时移动到一个新的位置，这时候就要进行302跳转，而使用301跳转的场景就是之前的网站因为某种原因需要移除掉，然后要到新的地址访问，是永久性的。

清晰明确而言：使用301跳转的大概场景如下：

- 域名到期不想续费（或者发现了更适合网站的域名），想换个域名。
- 在搜索引擎的搜索结果中出现了不带www的域名，而带www的域名却没有收录，这个时候可以用301重定向来告诉搜索引擎我们目标的域名是哪一个。
- 空间服务器不稳定，换空间的时候。



#### 2.5.3 响应

经过前面的6个步骤，服务器收到了我们的请求，也处理我们的请求，到这一步，它会把它的处理结果返回，也就是返回一个HTPP响应。

HTTP响应与HTTP请求相似，HTTP响应也由3个部分构成，分别是：

- 状态行
- 响应头(Response Header)
- 响应正文

```text
HTTP/1.1 200 OK
Date: Sat, 31 Dec 2005 23:59:59 GMT
Content-Type: text/html;charset=ISO-8859-1
Content-Length: 122

＜html＞
＜head＞
＜title＞http＜/title＞
＜/head＞
＜body＞
＜!-- body goes here --＞
＜/body＞
＜/html＞
```

**状态行：**

状态行由协议版本、数字形式的状态代码、及相应的状态描述，各元素之间以空格分隔。

> 格式: `HTTP-Version Status-Code Reason-Phrase CRLF`例如: `HTTP/1.1 200 OK`

**协议版本：** 是用http1.0还是其他版本

**状态描述：** 状态描述给出了关于状态代码的简短的文字描述。比如状态代码为200时的描述为 ok

**状态码：** 状态代码由三位数字组成，第一个数字定义了响应的类别，且有五种可能取值，如下：

1xx：信息性状态码，表示服务器已接收了客户端请求，客户端可继续发送请求。

- 100 Continue
- 101 Switching Protocols
- 2xx：成功状态码，表示服务器已成功接收到请求并进行处理。

200 OK 表示客户端请求成功

- 204 No Content 成功，但不返回任何实体的主体部分
- 206 Partial Content 成功执行了一个范围（Range）请求

3xx：重定向状态码，表示服务器要求客户端重定向。

- 301 Moved Permanently 永久性重定向，响应报文的Location首部应该有该资源的新URL
- 302 Found 临时性重定向，响应报文的Location首部给出的URL用来临时定位资源
- 303 See Other 请求的资源存在着另一个URI，客户端应使用GET方法定向获取请求的资源
- 304 Not Modified 服务器内容没有更新，可以直接读取浏览器缓存
- 307 Temporary Redirect 临时重定向。与302 Found含义一样。302禁止POST变换为GET，但实际使用时并不一定，307则更多浏览器可能会遵循这一标准，但也依赖于浏览器具体实现

4xx：客户端错误状态码，表示客户端的请求有非法内容。

- 400 Bad Request 表示客户端请求有语法错误，不能被服务器所理解
- 401 Unauthonzed 表示请求未经授权，该状态代码必须与 WWW-Authenticate 报头域一起使用
- 403 Forbidden 表示服务器收到请求，但是拒绝提供服务，通常会在响应正文中给出不提供服务的原因
- 404 Not Found 请求的资源不存在，例如，输入了错误的URL

5xx：服务器错误状态码，表示服务器未能正常处理客户端的请求而出现意外错误。

- 500 Internel Server Error 表示服务器发生不可预期的错误，导致无法完成客户端的请求
- 503 Service Unavailable 表示服务器当前不能够处理客户端的请求，在一段时间之后，服务器可能会恢复正常









### 2.6 http keep-alive 和 tcp  keepalive



HTTP中是keep-alive，TCP中是keepalive，HTTP中是带中划线的。大小写无所谓。

**HTTP协议**是Hyper Text Transfer Protocol（超文本传输协议）的缩写。HTTP是万维网的数据通信的基础。HTTP是一个应用层协议，**通常**运行在TCP协议之上。它由请求和响应构成，是一个标准的客户端服务器模型（C/S模型）。HTTP是一个**无状态**的协议。

**TCP协议**也叫传输控制协议（TCP，Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传输层通信协议。使用TCP的两个程序（客户端和服务端）在交换数据前，通过三次握手来建立TCP连接，建立连接后就可以进行基于字节流的双工通讯，由TCP内部实现保证通讯的可靠性，完全通讯完成后，通过四次挥手断开连接。



#### 2.6.1 http的keep-alive

在早期的http1.0中，默认就是上述介绍的这种“请求-应答”模式。这种方式频繁的创建连接和销毁连接无疑是有一定性能损耗的。

所以引入了**keep-alive**机制。http1.0默认是关闭的，**在HTTP/1.0中，默认使用的是短连接**。通过http请求头设置“connection: keep-alive”进行开启；http1.1中默认开启，通过http请求头设置“connection: close”关闭，**HTTP/1.1起，默认使用长连接**，。

**keep-alive**机制：若开启后，在一次http请求中，服务器进行响应后，不再直接断开TCP连接，而是将TCP连接维持一段时间。在这段时间内，如果同一客户端再次向服务端发起http请求，便可以复用此TCP连接，向服务端发起请求，并重置timeout时间计数器，在接下来一段时间内还可以继续复用。这样无疑省略了反复创建和销毁TCP连接的损耗。



#### 2.6.2 tcp的keepalive

TCP的保活机制就是用来解决此类问题，这个机制我们也可以称作：keepalive。保活机制默认是关闭的，TCP连接的任何一方都可打开此功能。有三个主要配置参数用来控制保活功能。

如果在一段时间（**保活时间：tcp_keepalive_time**）内此连接都不活跃，开启保活功能的一端会向对端发送一个保活探测报文。

- 若对端正常存活，且连接有效，对端必然能收到探测报文并进行响应。此时，发送端收到响应报文则证明TCP连接正常，重置保活时间计数器即可。
- 若由于网络原因或其他原因导致，发送端无法正常收到保活探测报文的响应。那么在一定**探测时间间隔（tcp_keepalive_intvl）**后，将继续发送保活探测报文。直到收到对端的响应，或者达到配置的**探测循环次数上限（tcp_keepalive_probes）**都没有收到对端响应，这时对端会被认为不可达，TCP连接随存在但已失效，需要将连接做中断处理。

在探测过程中，对端主机会处于以下四种状态之一：

![img](https://pic4.zhimg.com/80/v2-837ba2a1eb7beb10c036ca468f7db69f_1440w.webp)



这三个参数，在linux上可以在`/proc/sys/net/ipv4/`路径下找到，或者通过`sysctl -a | grep keepalive`命令查看当前内核运行参数。

```bash
[root@vm01 ~]# cd /proc/sys/net/ipv4
[root@vm01 ipv4]# pwd
/proc/sys/net/ipv4
[root@vm01 ipv4]# cat /proc/sys/net/ipv4/tcp_keepalive_time
7200
[root@vm01 ipv4]# cat /proc/sys/net/ipv4/tcp_keepalive_probes
9
[root@vm01 ipv4]# cat /proc/sys/net/ipv4/tcp_keepalive_intvl
75
[root@vm01 ipv4]# sysctl -a | grep keepalive
net.ipv4.tcp_keepalive_time = 7200
net.ipv4.tcp_keepalive_probes = 9
net.ipv4.tcp_keepalive_intvl = 75
```

- 保活时间（tcp_keepalive_time）默认：7200秒
- 保活时间间隔（tcp_keepalive_intvl）默认：75秒
- 探测循环次数（tcp_keepalive_probes）默认：9次

也就是默认情况下一条TCP连接在2小时（7200秒）都没有报文交换后，会开始进行保活探测，若再经过9*75秒=11分钟15秒的循环探测都未收到探测响应，即共计：2小时11分钟15秒后会自动断开TCP连接。



上面介绍的三个参数**tcp_keepalive_time、tcp_keepalive_intvl、tcp_keepalive_probes**都是系统级别的，针对整个系统生效。下面介绍针对单条Socket连接细粒度设置的三个选项参数：**保活时间：TCP_KEEPIDLE、保活探测时间间隔：TCP_KEEPINTVL、探测循环次数：TCP_KEEPCNT**

参考链接：https://zhuanlan.zhihu.com/p/224595048







syn攻击、半连接



进程间如何通信



python的底层网络交互模块有哪些



OSI七层协议



## 三、数据库相关

### mysql



mysql引擎，各个引擎之间有什么区别



数据库事务，及其特性



数据库事务隔离级别有哪些、区别与特点



死锁发生的情况，如何解决



索引的原理

mysql  B+索引、优缺点

mysql索引类型

聚簇索引和非聚簇索引

唯一索引和普通索引区别，使用索引有哪些优缺点

myql索引什么情况下会失效





mysql主从同步机制



数据库的ACID



如何开启慢查询日志



数据库的脏读、幻读、幻行的原理、发生场景，及解决方式





serializable 序列化、最好的事务级别



#### 乐观锁、悲观锁

悲观锁, 每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

乐观锁，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制，乐观锁适用于多读的应用类型，这样可以提高吞吐量。





#### sql注入原理，

SQL注入（SQL Injection）是一种常见的Web应用程序安全漏洞，攻击者通过对Web应用程序的输入参数或其他可控制的变量注入恶意的SQL代码，从而达到非法获取、篡改、删除敏感数据等目的。

具体来说，SQL注入是指攻击者在提交的请求中，通过构造特定的字符串，欺骗服务器，使其将命令当作SQL语句来执行。比如，攻击者可以通过在表单中输入特殊字符，从而改变SQL查询的含义，使查询返回所有用户信息，而不仅仅是当前用户的信息。

```
如果用户搜索字符串为 Tom，则在后台生成的SQL查询语句为：
SELECT * FROM users WHERE name = 'Tom'
然而，如果黑客输入字符串：' or '1'='1 这就是一个典型的SQL注入攻击，这个字符串会被拼接到原始的SQL查询中，构造出下面的恶意查询语句：
SELECT * FROM users WHERE name = '' or '1'='1'
```

在 Python 中使用特殊的函数将用户输入值进行转义或对用户输入值中的引号等进行转义作为字符串而不是符号达到要求，可以使用一些库的方法，如 MySQLdb 库的 `escape_string()` 方法或 psycopg2 库的 `sql.Identifier()` 和 `sql.Literal()` 方法。







数据库的优化













### 3.2 redis

#### 3.2.1 redis单线程

Redis采用单线程，那么它是如何处理多个客户端连接请求呢？

Linux 中的 IO 多路复用机制是指一个线程处理多个 IO 流，就是我们经常听到的 select/epoll 机制。简单来说，在 Redis 只运行单线程的情况下，该机制允许内核中，同时存在多个监听套接字和已连接套接字。内核会一直监听这些套接字上的连接请求或数据请求。一旦有请求到达，就会交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

下图就是基于多路复用的 Redis IO 模型。图中的多个 FD 就是刚才所说的多个套接字。Redis 网络框架调用 epoll 机制，让内核监听这些套接字。此时，Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性。

![img](./redis-io.png)

参考链接：https://www.cnblogs.com/databasepub/p/16691115.html



Redis使用单线程模型，没有了线程上下文切换和访问共享资源加锁的性能损耗，配合IO多路复用技术，可以完成多个连接的请求处理。而且正是由于它的使用定位是内存数据库，这样几乎所有的操作都在内存中完成，它的性能可以达到非常之高。

**Redis 6.0 版本为什么又引入了多线程，这里也解释下。**

Redis 的性能瓶颈不在 CPU ，而在内存和网络，内存不够可以增加内存或通过数据结构等进行优化；但 Redis 的网络 IO 的读写占用了大部分 CPU 的时间，如果可以把网络处理改成多线程的方式，性能会有很大提升。所以总结下 Redis 6.0 版本引入多线程有两个原因：1.充分利用服务器的多核资源 2.多线程分摊 Redis 同步 IO 读写负荷

**注意：执行命令还是由单线程顺序执行，只是处理网络数据读写采用了多线程，而且 IO 线程要么同时读 Socket ，要么同时写 Socket ，不会同时读写。**











redis如何解决雪崩、缓存击穿、



redis 持久化中rdb和 aof方案的优缺点











## 四、python相关



### 交集差集并集

```
python
list1 = [1, 2, 3, 4, 5]
list2 = [4, 5, 6, 7, 8]


# 求交集
set1 = set(list1)
set2 = set(list2)
intersection = set1 & set2  # 或者使用 set1.intersection(set2)
print(intersection)  # 输出 {4, 5}


# 求差集
difference = set1 - set2  # 或者使用 set1.difference(set2)
print(difference)  # 输出 {1, 2, 3}


# 求对称差集
result = set1 ^ set2
print(result)  # {1, 2, 3, 6, 7, 8}
# 使用 symmetric_difference() 方法
# result = set1.symmetric_difference(set2)


# 求并集
union = set1 | set2  # 或者使用 set1.union(set2)
print(union)  # 输出 {1, 2, 3, 4, 5, 6, 7, 8}
```



### python垃圾回收机制

Python 的垃圾回收机制主要是基于引用计数和循环垃圾收集两种方式。

#### 引用计数

 在 Python 中，每个对象都有一个整数计数器，表示该对象的引用数。当对象被引用时，引用数加1；当引用被删除时，引用数减1。当引用数归零时，Python 会自动回收这个对象的内存空间。



引用的含义：在 Python 中，引用是一个指向对象的指针。当您创建一个变量并将其赋值给某个对象时，实际上是创建了一个指针，该指针指向该对象的内存位置。通过在变量中保留对该内存位置的引用，您可以在程序的其他部分使用对象。

python垃圾回收主要以引用计数为主，标记-清除和分代清除为辅的机制，其中标记-清除和分代回收主要是为了处理循环引用的难题。

#### 循环垃圾收集

引用计数虽然简单高效，但并不能完全解决内存泄漏的问题。

两个对象相互引用的情况是一种循环引用（Circular Reference）的情形。在这种情况下，每个对象的引用计数都不为零，因为它们相互引用对方，无法被垃圾回收机制回收。

为了解决这个问题，Python 还提供了一种循环垃圾收集机制。

标记-清除（Mark and Sweep）和分代清除（Generational Collection）都是常见的垃圾回收算法，用于在编程语言中自动释放内存空间，保证程序的稳定性和可靠性。

标记-清除算法通过遍历对象图，标记所有活动对象，并清除所有未被标记的垃圾对象。该算法消耗的时间较长，但可以处理任意形式的内存分配，适合于垃圾散布比较均匀的情况。缺点是在清除垃圾后可能会产生大量的碎片，导致内存利用率降低。

分代清除算法则将内存分成几个不同的区域，根据对象的存活时间和垃圾回收的频度将其分为不同的代。通常，只有在经过多次垃圾回收仍然存活的对象才会升级到更高的代。这样，对于不同代的对象，采取不同的垃圾回收策略，可以极大地提高垃圾回收效率。例如，对于生命周期较短的对象，可以采用标记-清除算法进行回收；对于生命周期较长的对象，则通过移动、整理等方式进行回收。该算法相对于标记-清除算法来说，具有更好的性能和空间利用率。

在 Python 中，所有的对象都有一个内部计数器，记录着当前被多少个变量引用着。在循环垃圾回收机制中，它会从一些特殊的地方开始扫描对象，这些地方称为“根”。比如，全局变量、当前执行代码的函数等都是根。然后，从这些根开始，回收机制会递归地访问所有能够访问到的对象，将它们标记为活动对象，也就是正在使用中的对象。而对于那些没有被标记的对象，则说明它们不再被使用，可以被清理掉。

在遍历对象图的过程中，当循环垃圾回收机制发现两个或多个对象之间相互引用，形成了一个环形结构时，就会将它们都标记为活动对象，不会被清理掉。同时，在后续的标记-清除过程中，如果回收机制发现某个对象被标记为垃圾，但它引用着其他的活动对象，那么就可以推断出这是一个循环引用，可以采取特殊的回收策略将其处理掉。

总之，在 Python 中，垃圾回收机制是通过引用计数和循环垃圾收集两种方式实现的，它们共同工作，确保内存空间被有效地回收和管理。



### with

在 Python 中，`with` 是一种上下文管理器，它可以在代码块开始之前执行一些操作，在结束时做一些清理工作。`with` 语句的语法格式如下：

```
pythonCopy Codewith context_expression [as target(s)]:
    with-block
```

其中 `context_expression` 表示一个上下文管理器对象，该对象必须实现 `__enter__()` 和 `__exit__()` 方法，这两个方法分别在进入和离开 `with` 块时被调用。 `as target(s)` 可选，表示将 `context_expression.__enter__()` 方法返回的值绑定到某个变量或元组上。

`with` 语句可以帮助程序员避免对资源的手动管理和释放，例如打开一个文件、建立一个数据库连接等。相应的代码可以写成如下形式：

```
pythonCopy Code# 1. 使用 with 打开文件
with open("hello.txt", "w") as f:
    f.write("Hello, World!")

# 2. 使用 with 建立数据库连接
import psycopg2

with psycopg2.connect(database="mydb", user="myuser", password="mypassword") as conn:
    cursor = conn.cursor()
    cursor.execute("SELECT * FROM mytable")
```

在上述示例中，使用 `with` 打开文件时，当代码块执行结束时，Python 会自动关闭文件，无需手动调用 `close()` 方法；使用 `with` 建立数据库连接也类似，当程序执行完毕，Python 会自动关闭数据库连接。







### restfull和rpc区别与联系

RESTful 和 RPC（Remote Procedure Call）都是常用的网络通信协议，但它们有一些区别和联系。

首先，RESTful 是建立在 HTTP 协议之上的一种软件架构风格，它使用 URL 来标识资源，通过 HTTP 方法来对资源进行操作，包括 GET、POST、PUT、DELETE 等。RESTful 的设计思想是基于客户端和服务器之间的无状态通信，服务器不保存客户端的状态并且以资源为中心，充分利用 HTTP 的缓存、代理等机制，提高网络效率。RESTful 通常被用于 Web API 的开发，其良好的可读性和可扩展性使其逐渐成为 Web 应用程序的主要开发模式。

RPC 是远程过程调用协议，它允许程序在本地或远程系统上调用一个函数或方法，就像本地调用一样，屏蔽了底层通信细节，使得网络通信透明化、简化化。RPC 协议传输的是请求和响应的数据，可以通过多种传输协议实现，如 TCP、HTTP、UDP 等。RPC 协议具有更高的效率和更小的网络开销，因此多被用于传输大型数据和复杂的计算任务。

下面是 RESTful 和 RPC 的区别和联系：

1. RESTful 和 RPC 的通信方式不同。RESTful 是面向资源的，客户端使用 HTTP 方法（如 GET、POST、PUT、DELETE 等）来对服务器上的资源进行操作。RPC 是面向函数的，客户端通过调用远程函数来实现通信。
2. RESTful 和 RPC 的网络传输协议不同。RESTful 使用 HTTP 协议来传输数据，而 RPC 可以使用 TCP、HTTP、UDP 等多种协议来传输数据。
3. RESTful 和 RPC 的数据传输格式不同。RESTful 通常使用 JSON 或 XML 格式来传输数据，而 RPC 可以使用多种格式来传输数据，如二进制流、JSON、XML、Protobuf 等。
4. RESTful 和 RPC 的适用场景不同。RESTful 适用于大量资源的处理和 Web API 的开发，RPC 适用于需要高效传输数据和复杂计算任务时的应用场景。

综上所述，RESTful 和 RPC 都是常用的网络通信协议，它们在通信方式、网络传输协议、数据传输格式和适用场景等方面有区别和联系，具体选择哪种协议应根据实际情况来考虑。



### is 和 ==区别

在 Python 中，`is` 和 `==` 都是比较运算符，但它们的含义不同。

`is` 比较的是两个对象的身份标识，即它们**是否是同一个对象**。如果两个对象的身份标识相同，则返回 `True`，否则返回 `False`。

`==` 比较的是两个对象的**值是否相等**。如果两个对象的值相同，则返回 `True`，否则返回 `False`。

以下是示例代码，演示了 `is` 和 `==` 的不同：

```
pythonCopy Codea = [1, 2, 3] # 创建一个列表对象 a
b = [1, 2, 3] # 创建另一个列表对象 b

print(a == b) # 输出 True，因为 a 和 b 的值相等
print(a is b) # 输出 False，因为 a 和 b 是不同的对象

c = a # 创建一个对象 c，将其引用指向 a 指向的对象
print(a is c) # 输出 True，因为 a 和 c 引用同一个对象
```

需要注意的是，在 Python 中，一些常用的对象（如数值、字符串等）会被缓存起来供重用，因此可能会出现一些意外的结果。例如，对于整数值 `-5` 到 `256`，它们会被缓存起来，因此使用 `is` 比较同样的整数值时，会得到 `True` 的结果：

```
a = 1
b = 1
print(a is b) # 输出 True，因为 a 和 b 引用同一个整数对象
```



### 装饰器实现单例模式

```
def singleton(cls):
    instances = {}

    def getinstance(*args, **kwargs):
        if cls not in instances:
            instances[cls] = cls(*args, **kwargs)
        return instances[cls]
    return getinstance
    

@singleton
class MyClass:
    pass
```



### python内置的数据结构



Python 提供了多种内置的数据结构，以下是一些常用的数据结构：

列表（List）: 基于序列的动态数组，可以包含任意数量的元素，支持索引、切片、增加、删除等操作。
元组（Tuple）: 也是基于序列的不可变有序集合，可以包含任意数量的元素，一旦创建就不能修改。
集合（Set）: 无序的不重复元素的集合，可以进行交集、并集、差集等操作。
字典（Dictionary）: 一种映射类型，由键值对组成，支持通过键获取值，添加、删除、修改键值对等操作。
栈（Stack）: 后进先出的数据结构，只能从栈顶插入和删除元素。
队列（Queue）: 先进先出的数据结构，可以在队尾插入元素，在队头删除元素。
堆（Heap）: 一种特殊的树形数据结构，通常具有最小堆和最大堆两种形式。
链表（Linked List）: 通过指针连接各个节点的线性数据结构，可以分为单向链表、双向链表和循环链表。
以上是 Python 中常用的一些数据结构，不同的数据结构适用于不同的应用场景，掌握这些数据结构能够帮助我们更好地解决各种问题。



### 栈的使用

一个字符串，里面只有左括号和右括号元素，但是不确定都有多少，python如何实现判断是否里面的括号是闭合的，并计算最大深度

```
def max_depth(s):
    stack = []
    max_depth = 0
    depth = 0

    for c in s:
        if c == '(':
            stack.append(c)
            depth += 1
            if depth > max_depth:
                max_depth = depth
        elif c == ')':
            if not stack or stack[-1] != '(':
                return False
            stack.pop()
            depth -= 1

    return depth == 0, max_depth

在上述代码中，我们遍历字符串 s 中的每个字符，如果字符是左括号，则将其压入栈 stack 中，并更新当前深度 depth。如果当前深度大于最大深度，则更新最大深度。如果字符是右括号，则判定该字符是否与栈顶元素匹配，并同时更新当前深度。如果栈为空或者栈顶元素与当前右括号不匹配，则返回 False。最后，检查栈是否为空，如果为空说明该字符串是合法的闭合括号序列，返回 True 和最大深度；否则返回 False 和 0。
```



读取一个文件然后文件里面内容找合法的ip地址并并做去重

```
import re

# 读取文件
with open('file.txt', 'r') as f:
    s = f.read()

# 定义 IP 地址的正则表达式模式
pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'

# 使用正则表达式匹配 IP 地址，并存储到 set 集合中实现去重
ips = set(re.findall(pattern, s))

# 打印去重后的 IP 地址集合
print(ips)
```









字典按值排序（sorted(dict.iterms(), key=lambda x: x[1],）



翻转字符串  s = "w3423", s[::-1]



list1中age按由大到小排序（list1=[{"age": 5}, {"age": 67}, {"age": 56}],    sorted(list1, key=lambda x:x['age'], reverse=True)）



lista=[1,2,43,7],  lista[10:]



两个列表，找出相同元素和不同元素

list1= [1,2 ,4,6, 67],  list2=[3, 2, 43, 76]

set1=set(list1) , set2=set(list2), set1&set2,  set1^set2





### 什么是反射，反射应用场景

在 Python 中，反射是指程序可以访问、检查和修改其本身状态或行为的能力。通过反射，我们可以在运行时动态地获取对象的类型信息、属性、方法等，并且可以在不知道对象类型的情况下对其进行操作。

Python 提供了一些内置函数，例如 `getattr()`、`setattr()`、`hasattr()` 等，用于实现反射相关的功能。这些函数接收一个对象和一个属性名作为参数，然后进行相应的操作。例如，可以使用 `getattr(obj, "attr_name")` 来获取对象中的指定属性值，如果不存在则返回默认值；可以使用 `hasattr(obj, "attr_name")` 来检查对象是否存在指定的属性。

反射在 Python 中的应用场景比较广泛，下面列举几个典型的例子：

1. 动态导入模块：使用 `__import__(module_name)` 函数可以在运行时动态地导入指定模块，实现动态加载扩展功能的功能。
2. 插件架构：通过在程序运行时动态加载插件，实现程序功能的可扩展性。
3. 序列化和反序列化：当我们需要将对象序列化成字节流或 JSON 格式时，可以使用反射获取对象的属性列表和值列表，然后将它们转换为序列化格式；当我们需要从字节流或 JSON 中反序列化出对象时，可以使用反射创建对象，并为其设置属性值。
4. 测试框架：测试框架需要动态地加载测试用例，并对其进行执行和验证，可以使用反射实现动态加载并运行函数或方法。

总之，反射在 Python 中的应用非常广泛，可以大大提高程序的灵活性和可扩展性。但是，在使用反射时也需要注意一些安全性问题，例如可能会导致属性/方法访问不当、属性名字符串拼写错误等问题。因此，反射建议在必要时谨慎使用。





### 深拷贝和浅拷贝

浅拷贝会创建一个新的对象，但是这个新的对象还是会引用原始对象中的子对象。也就是说，浅拷贝只会复制原始对象的顶层结构，而其中的嵌套对象则会继续被共享。浅拷贝可以使用 `copy()` 方法或者切片来实现。

与之不同的是，深拷贝会创建一个新的对象，并递归地复制原始对象中所有的子对象。也就是说，深拷贝会完全独立于原始对象，不会共享其中的任何对象。深拷贝可以使用 `copy.deepcopy()` 方法来实现。





### `new和init`的区别



`__new__` 和 `__init__` 都是 Python 中用于创建对象的内置方法。它们在对象创建过程中具有不同的职责，因此二者之间具有一些区别。

`__new__` 是用于返回一个新的实例对象的方法，它是一个类级别的方法，在对象实例化之前调用。`__new__` 方法接收到的第一个参数是它所属的类，后续参数是用户传递的参数，返回值是创建的实例对象。在使用 `super().__new__(cls)` 时，它调用的是父类的 `__new__` 方法，从而创建了一个新的实例对象。

`__init__` 是用于初始化已经创建的实例对象的方法，它是一个实例级别的方法，在 `__new__` 方法返回实例对象之后调用。`__init__` 方法接收到的第一个参数是它所属的实例对象，后续参数是用户传递的参数。该方法不会返回任何值，它通过修改已经生成的对象的属性来对其进行初始化。







### GIL对python性能的影响

GIL（Global Interpreter Lock）是 Python 解释器中的一种机制，它的作用是确保同一时间只有一个线程在执行 Python 代码。这个机制是出于对解释器内部资源的保护和简化 C 拓展模块的设计而提出的。

虽然 GIL 的存在可以确保 Python 程序的安全性和稳定性，但同时也会对其性能产生一定的影响。由于 GIL 的存在，多线程的 Python 程序实际上是以并发的方式运行的，而不是真正的并行。因为在任何时刻都只有一个线程在执行 Python 代码，所以多个线程不能同时利用多核处理器的计算能力，从而限制了程序的性能和处理能力。

另外，由于 GIL 的存在，一个线程在持有解释器锁的时候，其他线程无法执行Python代码，只能等待当前线程释放锁。这就会导致CPU的利用率较低，从而降低程序的执行效率。

虽然 GIL 的存在是一种权衡，但是一些计算密集型任务、CPU 密集型的多线程程序以及高并发的网络应用程序等需要充分利用多核处理器的场景，都可能会受到 GIL 的限制，从而导致程序性能下降。针对这种情况，开发者可以考虑使用多进程、协程等替代方案，以便更好地发挥硬件的计算能力。





### 双下划线和单下划线

在 Python 中，双下划线和单下划线都有特殊的含义。

双下划线（__variable）表示私有变量，在类的内部指代使用，外部不可访问。在 Python 中，没有真正意义上的私有属性，但是使用双下划线可以让属性变成“伪私有”，因为 Python 解释器会将双下划线开头的变量名重命名，变成 _classname__variable 的形式，从而使得该变量在外部无法直接访问。例如，在一个类中定义了 __name 变量，在外部不能直接使用 obj.__name 访问，而应该使用 obj._classname__name 的方式来访问。需要注意的是，Python 中的私有变量只是一种约定俗成的规范，并不是强制性的。

单下划线（_variable）表示命名约定，表示该变量是“内部使用”的，不应该被外部直接访问。它主要用于区分临时变量和公共变量，也可以用于避免名称冲突。使用单下划线并不会改变变量的实际功能或访问权限，只是提醒开发者遵循良好的编程习惯。通常情况下，单下划线变量的功能与普通变量没有区别。

需要注意的是，单下划线和双下划线只是一种约定，不是关键字或保留字，因此在实际使用时需要注意遵循惯例。



with语句，如何构造，原理



单例模式，优缺点，如何实现







json序列化时，会遇到中文转unicode，想保留中文如何做（json.dumps({"dd", "你好"}， ensure_ascii=False)）



mro



C3算法



判断邮箱合法，re使用





python函数调用时候参数的传递是值传递还是引用传递







### python递归

#### 最大层数

在 Python 中，递归调用的最大深度由解释器的堆栈大小限制。默认情况下，Python 解释器限制递归深度不超过 1000 层。如果递归深度超过了这个值，会触发 `RecursionError` 异常，表示递归调用过深。

可以通过 `sys.setrecursionlimit()` 函数来修改递归调用的最大深度，但是不建议设置太大的值，因为过深的递归可能导致栈溢出等问题。

#### 停止条件

1. 达到指定的深度或层数：可以设置一个计数器或者参数来记录当前的递归层数或深度，当达到指定层数或深度时，不再继续调用自身，而是返回一个值或执行其他操作。
2. 达到特定的条件：可以根据具体的问题设置一些特定的条件，例如在查找树形结构中的某个节点时，当找到该节点时就不再继续递归。
3. 输入参数不符合要求：可以在函数开头对输入参数进行一些判断和筛选，当参数不符合要求时，直接返回一个错误信息或默认值。





### 列表推导式和生成器表达式

 输出结果分别是什么

```
[i % 2 for i in range(10)]    # 列表

(i % 2 for i in range(10))   # 迭代器
```



### 闭包

在 Python 中，闭包（Closure）是指一个函数对象和该函数所引用的外部变量组合而成的整体。

换句话说，闭包就是通过在一个函数内部定义另一个函数，并返回该函数对象，使得内部函数可以访问外部函数的变量和参数。这样做可以将函数和它所需的数据打包在一起，形成一个特殊的对象，具有不同于普通函数的行为。

常见的例子是利用闭包实现装饰器



### 正则表达式 

`re.search(pattern, string, flags=0)`：在字符串 `string` 中搜索匹配正则表达式 `pattern` 的第一个位置，并返回匹配的结果对象。如果匹配成功，则返回 MatchObject 对象，否则返回 None。

```
import re

# 在字符串中查找是否包含字母 a
str = "Hello World!"
match_result = re.search(r'a', str)
if match_result:
    print("Match found: ", match_result.group())
else:
    print("Match not found")
```



`re.findall(pattern, string, flags=0)`：在字符串 `string` 中查找所有满足正则表达式 `pattern` 的非重叠匹配，并以列表形式返回匹配的结果。如果没有匹配成功，则返回空列表。



```
import re

# 查找字符串中所有数字
str = "The price of the book is $20.99 and the weight is 2.5kg"
num_list = re.findall(r'\d+', str)
print(num_list)
```



`re.match(pattern, string, flags=0)`：从字符串 `string` 的开头开始匹配正则表达式 `pattern`，如果匹配成功，则返回匹配的结果对象，否则返回 None。与 `re.search()` 不同的是，`re.match()` 必须从字符串的开头开始匹配。

示例代码：

```
import re

# 匹配字符串是否以 Hello 开头
str = "Hello World!"
match_result = re.match(r'Hello', str)
if match_result:
    print("Match found: ", match_result.group())
else:
    print("Match not found")
```



`re.compile(pattern, flags=0)` 方法用于将正则表达式模式 `pattern` 编译成一个正则表达式对象，并返回该对象。这个编译过程可以提高正则表达式的执行效率，因为编译后的正则表达式对象可以重复使用。

示例代码如下：

```
import re

pattern = r"\d+"  # 匹配任意数字
text = "hello 123 world 456"
regex = re.compile(pattern)  # 将正则表达式编译为正则对象

match_obj = regex.search(text)  # 直接调用正则对象的方法进行匹配

if match_obj:
    print("Match found: ", match_obj.group())
else:
    print("Match not found")
```





```
import re

# 读取文件
with open('file.txt', 'r') as f:
    s = f.read()

# 定义 IP 地址的正则表达式模式 #结果不对
pattern = r'\b(?:\d{1,3}\.){3}\d{1,3}\b'

# 使用正则表达式匹配 IP 地址，并存储到 set 集合中实现去重
ips = set(re.findall(pattern, s))

# 打印去重后的 IP 地址集合
print(ips)


该正则表达式无法正确匹配符合 IPv4 标准的 IP 地址，原因是 [] 中的点号.只是一个普通字符，表示匹配任意一个字符。正确匹配 IPv4 地址的正则表达式应该是\b(?:\d{1,3}\.){3}\d{1,3}\b。

这个正则表达式具体含义如下：

\b 表示单词边界，避免匹配到 IP 地址的一部分。
(?:\d{1,3}\.){3} 表示匹配 3 个数字（每个数字长度为 1~3），并以点号.结尾的字符串，由于使用了非捕获分组 (?:)，所以匹配结果中不包含点号。
\d{1,3} 表示匹配一个长度为 1~3 的数字。
\b 表示单词边界，确保匹配到完整的 IP 地址。
```





### python面试题

https://juejin.cn/post/7067744227127459871





## 五、框架相关（django）



python三大框架各自应用场景



uWSGI 和nginx的理解

uwsgi  区别uWSGI



### 5.1 django



手动删除了表，导致，django迁移失败原因及解决办法

django中 Model    ForeignKey字段的on_delete参数作用



基于django使用ajax发送post请求时，有哪种方法携带csrftoken



django  FBV  CBV



django的request对象是什么时候创建的



django请求的生命周期



django中如何在model保存前做一定的固定操作，比如写一句日志（signal Dispatcher）



django中间件的使用



django  ORM查询中  select_related和prefetch_related的区别





cookie和session的区别





celery分布式队列





## 六、其他



自学python最大的困难



